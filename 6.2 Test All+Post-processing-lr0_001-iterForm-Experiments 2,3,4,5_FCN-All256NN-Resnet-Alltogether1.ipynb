{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "----------\n",
    "DNN with 1 frame (on batching on All of the datasets)\n",
    "----------\n",
    "___________________________________________________________________________________________________\n",
    "* This Script contains the changes made to 4.1 which are the following ones:\n",
    "\n",
    "    1. Number of iterations changed from a fixed number to the formula:\n",
    "            \n",
    "        total_num_iterations = (num_train_samples / batch_size) * num_of_epochs, \n",
    "            where num_iterations_per_epoch = Number of times same example is presented to the network\n",
    "            (num_train_samples / batch_size)\n",
    "    \n",
    "    2. A time counter is used in order to tell how long an experiment takes \n",
    "    \n",
    "    3. The following experiments were executed here:\n",
    "    \n",
    "       * Experiment 1 =  CNN, FCN, FCN, Y\n",
    "       * Experiment 2 =  CNN, FCN, Y \n",
    "       * Experiment 3 =  CNN, FCN, FCN, FCN, Y\n",
    "       * Experiment 4 =  CNN, FCN, FCN, FCN, FCN, Y\n",
    "___________________________________________________________________________________________________\n",
    "* This script contains the NN used to train windows of just 1 frame (other ones won't work).\n",
    "* There is no maxpooling applied into this NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Accuracy calculated using post processing\n",
    "----\n",
    "\n",
    "Next session will evaluate the results (without softmax) of the whole sequence. The procedure will be like this:\n",
    "\n",
    "1) The whole data will be sent (even with the zero row separators) it will return a (i x 12 ) data results (no softmax)\n",
    "\n",
    "2) Using the original test (which has zeros) look for those zero rows and once one is found, then make a sub-array (from the last initial position (first one=0) and make last position the one of the zeros) of the data results from the initial till end position\n",
    "\n",
    "3) Send the sub_array created to the function giveResult(subArray,labels) which will average the data and evaluate whether the softmax result of the averaged data, produces the label result, returning a true/false result\n",
    "\n",
    "4) Do a comparative of true/(true+false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we go...\n",
    "import datetime\n",
    "global_start = datetime.datetime.utcnow()\n",
    "import dataWindows_pp as data\n",
    "import dataWindows as dataAvg\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Pre, in & Post-Processing functions\n",
    "----\n",
    "* Functions used related to data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Find sequences of zeros \n",
    "def find_sequences(dataTest,labelTest):\n",
    "    pos = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    data = np.array([0,0,0])\n",
    "    erased = 0\n",
    "    i=0\n",
    "    while(i<len(dataTest)):\n",
    "        #print(not np.any(test_data[i]))\n",
    "        if(not np.any(dataTest[i])):\n",
    "            labl = np.argmax(labelTest[pos])\n",
    "            end = pos-1-erased        \n",
    "            data = np.vstack((data,[start,end,labl]))\n",
    "            start = end+1\n",
    "            erased+=1\n",
    "        pos+=1\n",
    "        i+=1\n",
    "    data = data[1:]\n",
    "    return data\n",
    "\n",
    "#2. Erases zeros from dataTest and labelTest\n",
    "def erase_zeros(dataTest,labelTest):\n",
    "    pos = 0    \n",
    "    while (pos < len(dataTest)):        \n",
    "        if(not np.any(dataTest[pos])):\n",
    "            dataTest = np.delete(dataTest,pos,0)\n",
    "            labelTest = np.delete(labelTest,pos,0)\n",
    "        else:\n",
    "            pos+=1        \n",
    "    return dataTest,labelTest\n",
    "\n",
    "def define_num_iterations(num_train_samples, batch_size,num_epochs=25):\n",
    "    total_iterations = (num_train_samples/batch_size)* num_epochs\n",
    "    print('The number of iterations for in this split is:',total_iterations)    \n",
    "    return int(total_iterations)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading the data function (used in a loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ----------  Functions which make test sequences and define number of iterations per training ---------- '''\n",
    "\n",
    "def read_data(number):\n",
    "    \n",
    "    #Preparing the data structure\n",
    "    \n",
    "    if(number==0):\n",
    "        data_dir, label_dir, tData, tLabels,data_avg,label_avg,tDataAvg,tLabelsAvg = [[None] for i in range(8)] #a=b=c points to same object\n",
    "        size = 1    \n",
    "    elif(number==1 or number==2):\n",
    "        data_dir, label_dir, tData, tLabels,data_avg,label_avg,tDataAvg,tLabelsAvg = [[None]*3 for i in range(8)] #a=b=c points to same object\n",
    "        size = 3        \n",
    "    elif(number==3 or number==4):\n",
    "        #change 3 here in case wanted to use the 10 datasets\n",
    "        data_dir, label_dir, tData, tLabels,data_avg,label_avg,tDataAvg,tLabelsAvg = [[None]*3 for i in range(8)] #a=b=c points to same object\n",
    "        size = 3        \n",
    "    \n",
    "    #Directories where the data can be found\n",
    "    \n",
    "    if(number==0):\n",
    "        #Penn_Action Load data        \n",
    "        data_dir[0] ='/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/penn_action/1_window/shuffled_training_components/data.mat'\n",
    "        label_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/penn_action/1_window/shuffled_training_components/labels.mat'\n",
    "        \n",
    "    elif(number==1):\n",
    "        #Sub-Jhmdb Load data        \n",
    "        data_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/sub-Jhmdb/1_window/shuffled_training_components/data1.mat'\n",
    "        label_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/sub-Jhmdb/1_window/shuffled_training_components/labels1.mat'\n",
    "        data_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/sub-Jhmdb/1_window/shuffled_training_components/data2.mat'\n",
    "        label_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/sub-Jhmdb/1_window/shuffled_training_components/labels2.mat'\n",
    "        data_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/sub-Jhmdb/1_window/shuffled_training_components/data3.mat'\n",
    "        label_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/sub-Jhmdb/1_window/shuffled_training_components/labels3.mat'\n",
    "        \n",
    "    elif(number==2):\n",
    "        #Jhmdb Load data        \n",
    "        data_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/Jhmdb/1_window/shuffled_training_components/data1.mat'\n",
    "        label_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/Jhmdb/1_window/shuffled_training_components/labels1.mat'\n",
    "        data_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/Jhmdb/1_window/shuffled_training_components/data2.mat'\n",
    "        label_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/Jhmdb/1_window/shuffled_training_components/labels2.mat'\n",
    "        data_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/Jhmdb/1_window/shuffled_training_components/data3.mat'\n",
    "        label_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/Jhmdb/1_window/shuffled_training_components/labels3.mat'        \n",
    "        \n",
    "    elif(number==3):\n",
    "        #Florence 3d\n",
    "        data_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data1.mat'\n",
    "        label_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels1.mat'\n",
    "        data_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data2.mat'\n",
    "        label_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels2.mat'\n",
    "        data_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data3.mat'\n",
    "        label_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels3.mat'\n",
    "        '''\n",
    "        data_dir[3] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data4.mat'\n",
    "        label_dir[3] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels4.mat'\n",
    "        data_dir[4] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data5.mat'\n",
    "        label_dir[4] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels5.mat'\n",
    "        data_dir[5] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data6.mat'\n",
    "        label_dir[5] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels6.mat'\n",
    "        data_dir[6] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data7.mat'\n",
    "        label_dir[6] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels7.mat'\n",
    "        data_dir[7] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data8.mat'\n",
    "        label_dir[7] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels8.mat'\n",
    "        data_dir[8] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data9.mat'\n",
    "        label_dir[8] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels9.mat'\n",
    "        data_dir[9] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/data10.mat'\n",
    "        label_dir[9] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/florence_3d/1_window/shuffled_training_components/labels10.mat'\n",
    "        '''                \n",
    "        \n",
    "    elif(number==4):\n",
    "        #Bn_mocap\n",
    "        data_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data1.mat'\n",
    "        label_dir[0] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels1.mat'\n",
    "        data_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data2.mat'\n",
    "        label_dir[1] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels2.mat'\n",
    "        data_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data3.mat'\n",
    "        label_dir[2] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels3.mat'\n",
    "        '''\n",
    "        data_dir[3] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data4.mat'\n",
    "        label_dir[3] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels4.mat'\n",
    "        data_dir[4] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data5.mat'\n",
    "        label_dir[4] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels5.mat'\n",
    "        data_dir[5] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data6.mat'\n",
    "        label_dir[5] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels6.mat'\n",
    "        data_dir[6] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data7.mat'\n",
    "        label_dir[6] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels7.mat'\n",
    "        data_dir[7] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data8.mat'\n",
    "        label_dir[7] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels8.mat'\n",
    "        data_dir[8] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data9.mat'\n",
    "        label_dir[8] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels9.mat'\n",
    "        data_dir[9] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/data10.mat'\n",
    "        label_dir[9] = '/media/data/gomez/(DATA_HERE)_Action_data_poses_windows/bn_mocap/1_window/shuffled_training_components/labels10.mat'\n",
    "        '''        \n",
    "   \n",
    "    for i in range(size):\n",
    "        (tData[i], tLabels[i])= data.loadAll(data_dir[i],label_dir[i])    \n",
    "\n",
    "    train_data,test_data,train_labels,test_labels = np.array([[None]*size for i in range(4)])\n",
    "    data_zeros = [None]*size\n",
    "\n",
    "    for i in range(size):\n",
    "        train_data[i] = tData[i]['trainD']\n",
    "        test_data[i] = tData[i]['testD']    \n",
    "        train_labels[i] = tLabels[i]['trainL']\n",
    "        test_labels[i] = tLabels[i]['testL']\n",
    "        data_zeros[i] = find_sequences(test_data[i],test_labels[i])\n",
    "        (test_data[i],test_labels[i]) = erase_zeros(test_data[i],test_labels[i])\n",
    "        print('The number of sequences found in split',i+1,'are:',data_zeros[i].shape[0])\n",
    "\n",
    "    #Erase data to keep more free space \n",
    "    del tData,tLabels, data_dir,label_dir\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels, data_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensorflow functions used during the creation of the architecture of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' -------------------------- TF Functions about weights,biases and convolution --------------------------'''\n",
    "\n",
    "#Weight initialization\n",
    "\n",
    "def weight_variable(shape, name, var_type): #Change the type in order to specify the variable to use\n",
    "    with tf.name_scope('weight_' + name):\n",
    "        initial = tf.random_uniform(shape)\n",
    "        if(var_type == 'normal'):\n",
    "            initial = tf.random_normal(shape, stddev=0.1)\n",
    "        elif(var_type == 'trunc'): #As seen in the beginning\n",
    "            initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        w_variable = tf.Variable(initial)\n",
    "        #tf.scalar_summary('_weight_' + name, w_variable)\n",
    "    return w_variable\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    with tf.name_scope('bias_' + name):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        b_variable = tf.Variable(initial)\n",
    "        #tf.scalar_summary('_bias_' + name,b_variable)\n",
    "    return b_variable\n",
    "\n",
    "#Convolution and pooling (Martin: stride 30 for convolution, article: max_pooling of 7 with stride 7)\n",
    "\n",
    "'''Change in the convolution from 30 to 3 (since size of input = 30) stride remains equal'''\n",
    "def conv1d(x,w):\n",
    "    with tf.name_scope('Conv1d'):        \n",
    "        #padding = SAME (leaves the same size of the padding), Valid (reduces the size of the output according to the filter size)\n",
    "        convolution = tf.nn.conv1d(x,w,stride=1, padding='VALID') \n",
    "        #tf.scalar_summary('_Conv1d_',convolution)\n",
    "    return convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Global Parameters of training\n",
    "----\n",
    "\n",
    "Hyperparameters used in all of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "drop_out_prob = 0.5\n",
    "display_step = 10\n",
    "#iterations = 12000 Changed to use it independently in each split\n",
    "learning_rate = 0.001\n",
    "\n",
    "convNum = 256\n",
    "FulCon1Num = 256\n",
    "FulCon2Num = 256\n",
    "\n",
    "# MODIFY THIS IF YOU CHANGED THE NUMBER OF SPLITS\n",
    "num_splits = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------\n",
    "-------------------------\n",
    "Default experiment (CN-FC1-FC2-FC3)\n",
    "-------------------------\n",
    "---------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp1_start = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sequences found in split 1 are: 1068\n",
      "The number of iterations for in this split is: 8754.300000000001\n",
      "Starting training of penn_Action \n",
      "\n",
      "loaded data 0 well\n",
      "shape of the data 30 number of labels 15 size of train data ( 87543 87543 ) \n",
      "\n",
      "\n",
      "layer 1 operation results\n",
      "h_conv is: Tensor(\"Relu:0\", shape=(?, 1, 256), dtype=float32)\n",
      "h_conv_ to FCN is: Tensor(\"Reshape_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 2 operation results\n",
      "h_fc1 is: Tensor(\"Relu_1:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc1_drop is: Tensor(\"dropout/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 3 operation results\n",
      "h_fc2 is: Tensor(\"Relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc2_drop is: Tensor(\"dropout_1/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 4 operation results\n",
      "h_fc3 is: Tensor(\"add_3:0\", shape=(?, 15), dtype=float32)\n",
      "y_conv is: Tensor(\"add_4:0\", shape=(?, 15), dtype=float32)\n",
      "\n",
      " Optimization of Split 1 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.701014 Accuracy: 0.084000\n",
      "The postprocessing average accuracy is: 0.03651685393258427 and the number of correct results is: 39\n",
      " Iteration: 10 , loss: 2.621899 Accuracy: 0.264000\n",
      " Iteration: 20 , loss: 2.590653 Accuracy: 0.364000\n",
      " Iteration: 30 , loss: 2.549984 Accuracy: 0.368000\n",
      " Iteration: 40 , loss: 2.512916 Accuracy: 0.432000\n",
      " Iteration: 50 , loss: 2.498263 Accuracy: 0.424000\n",
      "The postprocessing average accuracy is: 0.49625468164794007 and the number of correct results is: 530\n",
      " Iteration: 60 , loss: 2.450201 Accuracy: 0.508000\n",
      " Iteration: 70 , loss: 2.419840 Accuracy: 0.504000\n",
      " Iteration: 80 , loss: 2.390124 Accuracy: 0.540000\n",
      " Iteration: 90 , loss: 2.368197 Accuracy: 0.588000\n",
      " Iteration: 100 , loss: 2.394871 Accuracy: 0.540000\n",
      "The postprocessing average accuracy is: 0.5945692883895131 and the number of correct results is: 635\n",
      " Iteration: 110 , loss: 2.358800 Accuracy: 0.564000\n",
      " Iteration: 120 , loss: 2.341690 Accuracy: 0.596000\n",
      " Iteration: 130 , loss: 2.315406 Accuracy: 0.644000\n",
      " Iteration: 140 , loss: 2.273143 Accuracy: 0.676000\n",
      " Iteration: 150 , loss: 2.329267 Accuracy: 0.584000\n",
      "The postprocessing average accuracy is: 0.651685393258427 and the number of correct results is: 696\n",
      " Iteration: 160 , loss: 2.330225 Accuracy: 0.596000\n",
      " Iteration: 170 , loss: 2.306374 Accuracy: 0.604000\n",
      " Iteration: 180 , loss: 2.295394 Accuracy: 0.640000\n",
      " Iteration: 190 , loss: 2.275380 Accuracy: 0.668000\n",
      " Iteration: 200 , loss: 2.281793 Accuracy: 0.616000\n",
      "The postprocessing average accuracy is: 0.6835205992509363 and the number of correct results is: 730\n",
      " Iteration: 210 , loss: 2.263898 Accuracy: 0.656000\n",
      " Iteration: 220 , loss: 2.215050 Accuracy: 0.700000\n",
      " Iteration: 230 , loss: 2.206867 Accuracy: 0.696000\n",
      " Iteration: 240 , loss: 2.196736 Accuracy: 0.688000\n",
      " Iteration: 250 , loss: 2.245054 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.702247191011236 and the number of correct results is: 750\n",
      " Iteration: 260 , loss: 2.229455 Accuracy: 0.676000\n",
      " Iteration: 270 , loss: 2.169600 Accuracy: 0.760000\n",
      " Iteration: 280 , loss: 2.176482 Accuracy: 0.764000\n",
      " Iteration: 290 , loss: 2.225866 Accuracy: 0.688000\n",
      " Iteration: 300 , loss: 2.191908 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.7191011235955056 and the number of correct results is: 768\n",
      " Iteration: 310 , loss: 2.219781 Accuracy: 0.728000\n",
      " Iteration: 320 , loss: 2.175860 Accuracy: 0.740000\n",
      " Iteration: 330 , loss: 2.206354 Accuracy: 0.708000\n",
      " Iteration: 340 , loss: 2.178717 Accuracy: 0.756000\n",
      " Iteration: 350 , loss: 2.162780 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.7453183520599251 and the number of correct results is: 796\n",
      " Iteration: 360 , loss: 2.163419 Accuracy: 0.752000\n",
      " Iteration: 370 , loss: 2.121433 Accuracy: 0.804000\n",
      " Iteration: 380 , loss: 2.150200 Accuracy: 0.744000\n",
      " Iteration: 390 , loss: 2.114659 Accuracy: 0.808000\n",
      " Iteration: 400 , loss: 2.140011 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.7528089887640449 and the number of correct results is: 804\n",
      " Iteration: 410 , loss: 2.168033 Accuracy: 0.744000\n",
      " Iteration: 420 , loss: 2.140510 Accuracy: 0.780000\n",
      " Iteration: 430 , loss: 2.137496 Accuracy: 0.764000\n",
      " Iteration: 440 , loss: 2.164156 Accuracy: 0.720000\n",
      " Iteration: 450 , loss: 2.156266 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.7602996254681648 and the number of correct results is: 812\n",
      " Iteration: 460 , loss: 2.136389 Accuracy: 0.760000\n",
      " Iteration: 470 , loss: 2.132719 Accuracy: 0.776000\n",
      " Iteration: 480 , loss: 2.110761 Accuracy: 0.824000\n",
      " Iteration: 490 , loss: 2.080104 Accuracy: 0.812000\n",
      " Iteration: 500 , loss: 2.159721 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.7911985018726592 and the number of correct results is: 845\n",
      " Iteration: 510 , loss: 2.127212 Accuracy: 0.756000\n",
      " Iteration: 520 , loss: 2.144135 Accuracy: 0.744000\n",
      " Iteration: 530 , loss: 2.130801 Accuracy: 0.764000\n",
      " Iteration: 540 , loss: 2.126586 Accuracy: 0.768000\n",
      " Iteration: 550 , loss: 2.112272 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8267790262172284 and the number of correct results is: 883\n",
      " Iteration: 560 , loss: 2.112781 Accuracy: 0.780000\n",
      " Iteration: 570 , loss: 2.086907 Accuracy: 0.812000\n",
      " Iteration: 580 , loss: 2.069476 Accuracy: 0.808000\n",
      " Iteration: 590 , loss: 2.075764 Accuracy: 0.828000\n",
      " Iteration: 600 , loss: 2.115615 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8211610486891385 and the number of correct results is: 877\n",
      " Iteration: 610 , loss: 2.078773 Accuracy: 0.808000\n",
      " Iteration: 620 , loss: 2.091216 Accuracy: 0.800000\n",
      " Iteration: 630 , loss: 2.087982 Accuracy: 0.820000\n",
      " Iteration: 640 , loss: 2.117286 Accuracy: 0.776000\n",
      " Iteration: 650 , loss: 2.089160 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8155430711610487 and the number of correct results is: 871\n",
      " Iteration: 660 , loss: 2.103655 Accuracy: 0.800000\n",
      " Iteration: 670 , loss: 2.064966 Accuracy: 0.844000\n",
      " Iteration: 680 , loss: 2.114034 Accuracy: 0.764000\n",
      " Iteration: 690 , loss: 2.083502 Accuracy: 0.816000\n",
      " Iteration: 700 , loss: 2.092347 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8146067415730337 and the number of correct results is: 870\n",
      " Iteration: 710 , loss: 2.082588 Accuracy: 0.808000\n",
      " Iteration: 720 , loss: 2.072462 Accuracy: 0.820000\n",
      " Iteration: 730 , loss: 2.030707 Accuracy: 0.848000\n",
      " Iteration: 740 , loss: 2.066437 Accuracy: 0.816000\n",
      " Iteration: 750 , loss: 2.049150 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.8436329588014981 and the number of correct results is: 901\n",
      " Iteration: 760 , loss: 2.101788 Accuracy: 0.760000\n",
      " Iteration: 770 , loss: 2.068092 Accuracy: 0.832000\n",
      " Iteration: 780 , loss: 2.064507 Accuracy: 0.804000\n",
      " Iteration: 790 , loss: 2.080042 Accuracy: 0.776000\n",
      " Iteration: 800 , loss: 2.053760 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.8267790262172284 and the number of correct results is: 883\n",
      " Iteration: 810 , loss: 2.055589 Accuracy: 0.828000\n",
      " Iteration: 820 , loss: 2.062321 Accuracy: 0.848000\n",
      " Iteration: 830 , loss: 2.014648 Accuracy: 0.864000\n",
      " Iteration: 840 , loss: 2.001658 Accuracy: 0.872000\n",
      " Iteration: 850 , loss: 2.045589 Accuracy: 0.848000\n",
      "The postprocessing average accuracy is: 0.8539325842696629 and the number of correct results is: 912\n",
      " Iteration: 860 , loss: 2.046855 Accuracy: 0.852000\n",
      " Iteration: 870 , loss: 2.078030 Accuracy: 0.812000\n",
      " Iteration: 880 , loss: 2.065841 Accuracy: 0.812000\n",
      " Iteration: 890 , loss: 2.051805 Accuracy: 0.848000\n",
      " Iteration: 900 , loss: 2.066929 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.8604868913857678 and the number of correct results is: 919\n",
      " Iteration: 910 , loss: 2.050293 Accuracy: 0.836000\n",
      " Iteration: 920 , loss: 2.039964 Accuracy: 0.844000\n",
      " Iteration: 930 , loss: 2.009916 Accuracy: 0.880000\n",
      " Iteration: 940 , loss: 2.012913 Accuracy: 0.864000\n",
      " Iteration: 950 , loss: 2.052581 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.8398876404494382 and the number of correct results is: 897\n",
      " Iteration: 960 , loss: 2.010594 Accuracy: 0.884000\n",
      " Iteration: 970 , loss: 2.023790 Accuracy: 0.856000\n",
      " Iteration: 980 , loss: 2.023978 Accuracy: 0.856000\n",
      " Iteration: 990 , loss: 2.048621 Accuracy: 0.848000\n",
      " Iteration: 1000 , loss: 2.052134 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.8455056179775281 and the number of correct results is: 903\n",
      " Iteration: 1010 , loss: 2.035163 Accuracy: 0.872000\n",
      " Iteration: 1020 , loss: 1.998682 Accuracy: 0.884000\n",
      " Iteration: 1030 , loss: 2.027996 Accuracy: 0.844000\n",
      " Iteration: 1040 , loss: 2.006820 Accuracy: 0.884000\n",
      " Iteration: 1050 , loss: 2.054930 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.8417602996254682 and the number of correct results is: 899\n",
      " Iteration: 1060 , loss: 2.011789 Accuracy: 0.900000\n",
      " Iteration: 1070 , loss: 2.029393 Accuracy: 0.840000\n",
      " Iteration: 1080 , loss: 2.000394 Accuracy: 0.892000\n",
      " Iteration: 1090 , loss: 2.017513 Accuracy: 0.872000\n",
      " Iteration: 1100 , loss: 2.016291 Accuracy: 0.868000\n",
      "The postprocessing average accuracy is: 0.8717228464419475 and the number of correct results is: 931\n",
      " Iteration: 1110 , loss: 2.028488 Accuracy: 0.836000\n",
      " Iteration: 1120 , loss: 2.037137 Accuracy: 0.840000\n",
      " Iteration: 1130 , loss: 2.029280 Accuracy: 0.840000\n",
      " Iteration: 1140 , loss: 2.020229 Accuracy: 0.860000\n",
      " Iteration: 1150 , loss: 2.018008 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.851123595505618 and the number of correct results is: 909\n",
      " Iteration: 1160 , loss: 1.981092 Accuracy: 0.908000\n",
      " Iteration: 1170 , loss: 2.021059 Accuracy: 0.880000\n",
      " Iteration: 1180 , loss: 2.004786 Accuracy: 0.856000\n",
      " Iteration: 1190 , loss: 1.988946 Accuracy: 0.860000\n",
      " Iteration: 1200 , loss: 2.019595 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.8614232209737828 and the number of correct results is: 920\n",
      " Iteration: 1210 , loss: 2.003510 Accuracy: 0.856000\n",
      " Iteration: 1220 , loss: 2.022853 Accuracy: 0.856000\n",
      " Iteration: 1230 , loss: 2.015049 Accuracy: 0.852000\n",
      " Iteration: 1240 , loss: 2.025847 Accuracy: 0.884000\n",
      " Iteration: 1250 , loss: 2.008481 Accuracy: 0.856000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 1260 , loss: 2.005398 Accuracy: 0.880000\n",
      " Iteration: 1270 , loss: 2.005753 Accuracy: 0.860000\n",
      " Iteration: 1280 , loss: 1.977205 Accuracy: 0.888000\n",
      " Iteration: 1290 , loss: 2.001923 Accuracy: 0.876000\n",
      " Iteration: 1300 , loss: 2.016766 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.8586142322097379 and the number of correct results is: 917\n",
      " Iteration: 1310 , loss: 1.983110 Accuracy: 0.892000\n",
      " Iteration: 1320 , loss: 1.990333 Accuracy: 0.884000\n",
      " Iteration: 1330 , loss: 1.996990 Accuracy: 0.868000\n",
      " Iteration: 1340 , loss: 2.034268 Accuracy: 0.832000\n",
      " Iteration: 1350 , loss: 2.015320 Accuracy: 0.860000\n",
      "The postprocessing average accuracy is: 0.8586142322097379 and the number of correct results is: 917\n",
      " Iteration: 1360 , loss: 2.024557 Accuracy: 0.848000\n",
      " Iteration: 1370 , loss: 1.975834 Accuracy: 0.896000\n",
      " Iteration: 1380 , loss: 2.024003 Accuracy: 0.844000\n",
      " Iteration: 1390 , loss: 1.973738 Accuracy: 0.888000\n",
      " Iteration: 1400 , loss: 1.997464 Accuracy: 0.880000\n",
      "The postprocessing average accuracy is: 0.850187265917603 and the number of correct results is: 908\n",
      " Iteration: 1410 , loss: 1.993051 Accuracy: 0.884000\n",
      " Iteration: 1420 , loss: 1.993711 Accuracy: 0.884000\n",
      " Iteration: 1430 , loss: 1.981002 Accuracy: 0.884000\n",
      " Iteration: 1440 , loss: 1.967842 Accuracy: 0.892000\n",
      " Iteration: 1450 , loss: 1.992125 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 1460 , loss: 1.999453 Accuracy: 0.872000\n",
      " Iteration: 1470 , loss: 2.012729 Accuracy: 0.856000\n",
      " Iteration: 1480 , loss: 1.998247 Accuracy: 0.868000\n",
      " Iteration: 1490 , loss: 1.987574 Accuracy: 0.884000\n",
      " Iteration: 1500 , loss: 1.974351 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.8595505617977528 and the number of correct results is: 918\n",
      " Iteration: 1510 , loss: 1.989427 Accuracy: 0.884000\n",
      " Iteration: 1520 , loss: 1.984734 Accuracy: 0.876000\n",
      " Iteration: 1530 , loss: 1.997849 Accuracy: 0.852000\n",
      " Iteration: 1540 , loss: 1.950512 Accuracy: 0.916000\n",
      " Iteration: 1550 , loss: 1.977061 Accuracy: 0.912000\n",
      "The postprocessing average accuracy is: 0.8670411985018727 and the number of correct results is: 926\n",
      " Iteration: 1560 , loss: 1.955604 Accuracy: 0.936000\n",
      " Iteration: 1570 , loss: 1.998298 Accuracy: 0.876000\n",
      " Iteration: 1580 , loss: 1.968187 Accuracy: 0.888000\n",
      " Iteration: 1590 , loss: 1.993486 Accuracy: 0.868000\n",
      " Iteration: 1600 , loss: 1.984640 Accuracy: 0.868000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 1610 , loss: 1.952296 Accuracy: 0.932000\n",
      " Iteration: 1620 , loss: 1.991964 Accuracy: 0.876000\n",
      " Iteration: 1630 , loss: 1.981714 Accuracy: 0.864000\n",
      " Iteration: 1640 , loss: 1.986369 Accuracy: 0.876000\n",
      " Iteration: 1650 , loss: 1.976306 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 1660 , loss: 1.972071 Accuracy: 0.888000\n",
      " Iteration: 1670 , loss: 1.967935 Accuracy: 0.876000\n",
      " Iteration: 1680 , loss: 1.975622 Accuracy: 0.896000\n",
      " Iteration: 1690 , loss: 2.007439 Accuracy: 0.872000\n",
      " Iteration: 1700 , loss: 1.971144 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n",
      " Iteration: 1710 , loss: 1.975073 Accuracy: 0.888000\n",
      " Iteration: 1720 , loss: 1.972038 Accuracy: 0.896000\n",
      " Iteration: 1730 , loss: 1.993870 Accuracy: 0.876000\n",
      " Iteration: 1740 , loss: 1.971379 Accuracy: 0.896000\n",
      " Iteration: 1750 , loss: 1.995080 Accuracy: 0.876000\n",
      "The postprocessing average accuracy is: 0.8689138576779026 and the number of correct results is: 928\n",
      " Iteration: 1760 , loss: 1.960153 Accuracy: 0.916000\n",
      " Iteration: 1770 , loss: 1.991616 Accuracy: 0.860000\n",
      " Iteration: 1780 , loss: 1.963366 Accuracy: 0.888000\n",
      " Iteration: 1790 , loss: 1.950967 Accuracy: 0.904000\n",
      " Iteration: 1800 , loss: 1.972090 Accuracy: 0.892000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 1810 , loss: 1.966518 Accuracy: 0.892000\n",
      " Iteration: 1820 , loss: 1.971928 Accuracy: 0.888000\n",
      " Iteration: 1830 , loss: 1.991624 Accuracy: 0.868000\n",
      " Iteration: 1840 , loss: 1.975707 Accuracy: 0.880000\n",
      " Iteration: 1850 , loss: 1.968571 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.8848314606741573 and the number of correct results is: 945\n",
      " Iteration: 1860 , loss: 1.951293 Accuracy: 0.924000\n",
      " Iteration: 1870 , loss: 1.975397 Accuracy: 0.876000\n",
      " Iteration: 1880 , loss: 1.986477 Accuracy: 0.864000\n",
      " Iteration: 1890 , loss: 1.961773 Accuracy: 0.900000\n",
      " Iteration: 1900 , loss: 1.959583 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 1910 , loss: 1.954832 Accuracy: 0.904000\n",
      " Iteration: 1920 , loss: 1.964772 Accuracy: 0.912000\n",
      " Iteration: 1930 , loss: 1.956378 Accuracy: 0.904000\n",
      " Iteration: 1940 , loss: 1.977505 Accuracy: 0.868000\n",
      " Iteration: 1950 , loss: 1.934915 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.8848314606741573 and the number of correct results is: 945\n",
      " Iteration: 1960 , loss: 1.952211 Accuracy: 0.916000\n",
      " Iteration: 1970 , loss: 1.931489 Accuracy: 0.940000\n",
      " Iteration: 1980 , loss: 1.978227 Accuracy: 0.892000\n",
      " Iteration: 1990 , loss: 1.958837 Accuracy: 0.912000\n",
      " Iteration: 2000 , loss: 1.960320 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 2010 , loss: 1.963249 Accuracy: 0.892000\n",
      " Iteration: 2020 , loss: 1.950821 Accuracy: 0.908000\n",
      " Iteration: 2030 , loss: 1.955481 Accuracy: 0.904000\n",
      " Iteration: 2040 , loss: 1.964560 Accuracy: 0.884000\n",
      " Iteration: 2050 , loss: 1.939713 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.8764044943820225 and the number of correct results is: 936\n",
      " Iteration: 2060 , loss: 1.982998 Accuracy: 0.876000\n",
      " Iteration: 2070 , loss: 1.951421 Accuracy: 0.920000\n",
      " Iteration: 2080 , loss: 1.977169 Accuracy: 0.884000\n",
      " Iteration: 2090 , loss: 1.941765 Accuracy: 0.916000\n",
      " Iteration: 2100 , loss: 1.963306 Accuracy: 0.896000\n",
      "The postprocessing average accuracy is: 0.8792134831460674 and the number of correct results is: 939\n",
      " Iteration: 2110 , loss: 1.948034 Accuracy: 0.920000\n",
      " Iteration: 2120 , loss: 1.981991 Accuracy: 0.892000\n",
      " Iteration: 2130 , loss: 1.952957 Accuracy: 0.912000\n",
      " Iteration: 2140 , loss: 1.939398 Accuracy: 0.944000\n",
      " Iteration: 2150 , loss: 1.943158 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 2160 , loss: 1.959298 Accuracy: 0.896000\n",
      " Iteration: 2170 , loss: 1.962282 Accuracy: 0.888000\n",
      " Iteration: 2180 , loss: 1.960685 Accuracy: 0.908000\n",
      " Iteration: 2190 , loss: 1.951321 Accuracy: 0.900000\n",
      " Iteration: 2200 , loss: 1.954668 Accuracy: 0.912000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 2210 , loss: 1.978621 Accuracy: 0.880000\n",
      " Iteration: 2220 , loss: 1.936092 Accuracy: 0.920000\n",
      " Iteration: 2230 , loss: 1.962695 Accuracy: 0.888000\n",
      " Iteration: 2240 , loss: 1.928394 Accuracy: 0.924000\n",
      " Iteration: 2250 , loss: 1.944672 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.8689138576779026 and the number of correct results is: 928\n",
      " Iteration: 2260 , loss: 1.944805 Accuracy: 0.908000\n",
      " Iteration: 2270 , loss: 1.954548 Accuracy: 0.908000\n",
      " Iteration: 2280 , loss: 1.952544 Accuracy: 0.896000\n",
      " Iteration: 2290 , loss: 1.964354 Accuracy: 0.880000\n",
      " Iteration: 2300 , loss: 1.938027 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 2310 , loss: 1.922914 Accuracy: 0.936000\n",
      " Iteration: 2320 , loss: 1.920248 Accuracy: 0.960000\n",
      " Iteration: 2330 , loss: 1.981814 Accuracy: 0.852000\n",
      " Iteration: 2340 , loss: 1.945251 Accuracy: 0.920000\n",
      " Iteration: 2350 , loss: 1.955685 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 2360 , loss: 1.958471 Accuracy: 0.900000\n",
      " Iteration: 2370 , loss: 1.927714 Accuracy: 0.940000\n",
      " Iteration: 2380 , loss: 1.939434 Accuracy: 0.920000\n",
      " Iteration: 2390 , loss: 1.958268 Accuracy: 0.900000\n",
      " Iteration: 2400 , loss: 1.911014 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 2410 , loss: 1.957133 Accuracy: 0.900000\n",
      " Iteration: 2420 , loss: 1.960405 Accuracy: 0.888000\n",
      " Iteration: 2430 , loss: 1.951334 Accuracy: 0.900000\n",
      " Iteration: 2440 , loss: 1.931771 Accuracy: 0.940000\n",
      " Iteration: 2450 , loss: 1.949040 Accuracy: 0.896000\n",
      "The postprocessing average accuracy is: 0.8764044943820225 and the number of correct results is: 936\n",
      " Iteration: 2460 , loss: 1.927570 Accuracy: 0.940000\n",
      " Iteration: 2470 , loss: 1.953311 Accuracy: 0.916000\n",
      " Iteration: 2480 , loss: 1.927099 Accuracy: 0.932000\n",
      " Iteration: 2490 , loss: 1.927627 Accuracy: 0.928000\n",
      " Iteration: 2500 , loss: 1.954533 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n",
      " Iteration: 2510 , loss: 1.936164 Accuracy: 0.924000\n",
      " Iteration: 2520 , loss: 1.948411 Accuracy: 0.908000\n",
      " Iteration: 2530 , loss: 1.953078 Accuracy: 0.916000\n",
      " Iteration: 2540 , loss: 1.953105 Accuracy: 0.888000\n",
      " Iteration: 2550 , loss: 1.926764 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 2560 , loss: 1.937950 Accuracy: 0.924000\n",
      " Iteration: 2570 , loss: 1.939716 Accuracy: 0.932000\n",
      " Iteration: 2580 , loss: 1.943280 Accuracy: 0.912000\n",
      " Iteration: 2590 , loss: 1.924229 Accuracy: 0.912000\n",
      " Iteration: 2600 , loss: 1.948299 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.8679775280898876 and the number of correct results is: 927\n",
      " Iteration: 2610 , loss: 1.946152 Accuracy: 0.916000\n",
      " Iteration: 2620 , loss: 1.945056 Accuracy: 0.916000\n",
      " Iteration: 2630 , loss: 1.935532 Accuracy: 0.932000\n",
      " Iteration: 2640 , loss: 1.928738 Accuracy: 0.928000\n",
      " Iteration: 2650 , loss: 1.930244 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 2660 , loss: 1.939666 Accuracy: 0.908000\n",
      " Iteration: 2670 , loss: 1.913109 Accuracy: 0.956000\n",
      " Iteration: 2680 , loss: 1.975854 Accuracy: 0.892000\n",
      " Iteration: 2690 , loss: 1.936575 Accuracy: 0.924000\n",
      " Iteration: 2700 , loss: 1.917203 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 2710 , loss: 1.956914 Accuracy: 0.888000\n",
      " Iteration: 2720 , loss: 1.908601 Accuracy: 0.936000\n",
      " Iteration: 2730 , loss: 1.902984 Accuracy: 0.972000\n",
      " Iteration: 2740 , loss: 1.930710 Accuracy: 0.908000\n",
      " Iteration: 2750 , loss: 1.915484 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 2760 , loss: 1.942181 Accuracy: 0.920000\n",
      " Iteration: 2770 , loss: 1.935220 Accuracy: 0.920000\n",
      " Iteration: 2780 , loss: 1.928277 Accuracy: 0.916000\n",
      " Iteration: 2790 , loss: 1.928232 Accuracy: 0.920000\n",
      " Iteration: 2800 , loss: 1.935596 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 2810 , loss: 1.930694 Accuracy: 0.936000\n",
      " Iteration: 2820 , loss: 1.955915 Accuracy: 0.900000\n",
      " Iteration: 2830 , loss: 1.915929 Accuracy: 0.928000\n",
      " Iteration: 2840 , loss: 1.937154 Accuracy: 0.916000\n",
      " Iteration: 2850 , loss: 1.936031 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.8735955056179775 and the number of correct results is: 933\n",
      " Iteration: 2860 , loss: 1.930484 Accuracy: 0.940000\n",
      " Iteration: 2870 , loss: 1.949376 Accuracy: 0.900000\n",
      " Iteration: 2880 , loss: 1.947897 Accuracy: 0.928000\n",
      " Iteration: 2890 , loss: 1.939465 Accuracy: 0.908000\n",
      " Iteration: 2900 , loss: 1.914686 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 2910 , loss: 1.917665 Accuracy: 0.940000\n",
      " Iteration: 2920 , loss: 1.929324 Accuracy: 0.932000\n",
      " Iteration: 2930 , loss: 1.948128 Accuracy: 0.896000\n",
      " Iteration: 2940 , loss: 1.917946 Accuracy: 0.924000\n",
      " Iteration: 2950 , loss: 1.926453 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 2960 , loss: 1.933693 Accuracy: 0.920000\n",
      " Iteration: 2970 , loss: 1.916086 Accuracy: 0.932000\n",
      " Iteration: 2980 , loss: 1.931114 Accuracy: 0.908000\n",
      " Iteration: 2990 , loss: 1.925874 Accuracy: 0.912000\n",
      " Iteration: 3000 , loss: 1.920729 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 3010 , loss: 1.917309 Accuracy: 0.912000\n",
      " Iteration: 3020 , loss: 1.921905 Accuracy: 0.944000\n",
      " Iteration: 3030 , loss: 1.959112 Accuracy: 0.900000\n",
      " Iteration: 3040 , loss: 1.906386 Accuracy: 0.944000\n",
      " Iteration: 3050 , loss: 1.915917 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.8764044943820225 and the number of correct results is: 936\n",
      " Iteration: 3060 , loss: 1.943948 Accuracy: 0.904000\n",
      " Iteration: 3070 , loss: 1.900691 Accuracy: 0.960000\n",
      " Iteration: 3080 , loss: 1.890521 Accuracy: 0.968000\n",
      " Iteration: 3090 , loss: 1.921923 Accuracy: 0.928000\n",
      " Iteration: 3100 , loss: 1.910055 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 3110 , loss: 1.934136 Accuracy: 0.924000\n",
      " Iteration: 3120 , loss: 1.932514 Accuracy: 0.912000\n",
      " Iteration: 3130 , loss: 1.915441 Accuracy: 0.944000\n",
      " Iteration: 3140 , loss: 1.909519 Accuracy: 0.940000\n",
      " Iteration: 3150 , loss: 1.926440 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n",
      " Iteration: 3160 , loss: 1.916711 Accuracy: 0.932000\n",
      " Iteration: 3170 , loss: 1.937578 Accuracy: 0.908000\n",
      " Iteration: 3180 , loss: 1.904505 Accuracy: 0.956000\n",
      " Iteration: 3190 , loss: 1.916600 Accuracy: 0.960000\n",
      " Iteration: 3200 , loss: 1.922890 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 3210 , loss: 1.914697 Accuracy: 0.940000\n",
      " Iteration: 3220 , loss: 1.937993 Accuracy: 0.916000\n",
      " Iteration: 3230 , loss: 1.931132 Accuracy: 0.928000\n",
      " Iteration: 3240 , loss: 1.900720 Accuracy: 0.948000\n",
      " Iteration: 3250 , loss: 1.917672 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 3260 , loss: 1.925834 Accuracy: 0.932000\n",
      " Iteration: 3270 , loss: 1.923485 Accuracy: 0.936000\n",
      " Iteration: 3280 , loss: 1.913654 Accuracy: 0.940000\n",
      " Iteration: 3290 , loss: 1.901529 Accuracy: 0.952000\n",
      " Iteration: 3300 , loss: 1.926133 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.8707865168539326 and the number of correct results is: 930\n",
      " Iteration: 3310 , loss: 1.908866 Accuracy: 0.936000\n",
      " Iteration: 3320 , loss: 1.897648 Accuracy: 0.952000\n",
      " Iteration: 3330 , loss: 1.921587 Accuracy: 0.932000\n",
      " Iteration: 3340 , loss: 1.908517 Accuracy: 0.940000\n",
      " Iteration: 3350 , loss: 1.909988 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 3360 , loss: 1.909294 Accuracy: 0.932000\n",
      " Iteration: 3370 , loss: 1.909855 Accuracy: 0.948000\n",
      " Iteration: 3380 , loss: 1.924093 Accuracy: 0.936000\n",
      " Iteration: 3390 , loss: 1.917064 Accuracy: 0.932000\n",
      " Iteration: 3400 , loss: 1.900620 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8632958801498127 and the number of correct results is: 922\n",
      " Iteration: 3410 , loss: 1.947132 Accuracy: 0.892000\n",
      " Iteration: 3420 , loss: 1.900207 Accuracy: 0.936000\n",
      " Iteration: 3430 , loss: 1.884043 Accuracy: 0.968000\n",
      " Iteration: 3440 , loss: 1.918054 Accuracy: 0.944000\n",
      " Iteration: 3450 , loss: 1.894509 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 3460 , loss: 1.918176 Accuracy: 0.936000\n",
      " Iteration: 3470 , loss: 1.925394 Accuracy: 0.912000\n",
      " Iteration: 3480 , loss: 1.903331 Accuracy: 0.944000\n",
      " Iteration: 3490 , loss: 1.908060 Accuracy: 0.952000\n",
      " Iteration: 3500 , loss: 1.909326 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 3510 , loss: 1.905256 Accuracy: 0.948000\n",
      " Iteration: 3520 , loss: 1.934753 Accuracy: 0.908000\n",
      " Iteration: 3530 , loss: 1.892675 Accuracy: 0.964000\n",
      " Iteration: 3540 , loss: 1.897657 Accuracy: 0.948000\n",
      " Iteration: 3550 , loss: 1.902087 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8913857677902621 and the number of correct results is: 952\n",
      " Iteration: 3560 , loss: 1.916703 Accuracy: 0.940000\n",
      " Iteration: 3570 , loss: 1.926797 Accuracy: 0.932000\n",
      " Iteration: 3580 , loss: 1.936230 Accuracy: 0.908000\n",
      " Iteration: 3590 , loss: 1.908540 Accuracy: 0.932000\n",
      " Iteration: 3600 , loss: 1.909069 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 3610 , loss: 1.904664 Accuracy: 0.948000\n",
      " Iteration: 3620 , loss: 1.915682 Accuracy: 0.936000\n",
      " Iteration: 3630 , loss: 1.918685 Accuracy: 0.940000\n",
      " Iteration: 3640 , loss: 1.876109 Accuracy: 0.968000\n",
      " Iteration: 3650 , loss: 1.897390 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 3660 , loss: 1.914606 Accuracy: 0.932000\n",
      " Iteration: 3670 , loss: 1.885946 Accuracy: 0.952000\n",
      " Iteration: 3680 , loss: 1.912022 Accuracy: 0.916000\n",
      " Iteration: 3690 , loss: 1.929770 Accuracy: 0.908000\n",
      " Iteration: 3700 , loss: 1.914020 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.8764044943820225 and the number of correct results is: 936\n",
      " Iteration: 3710 , loss: 1.899713 Accuracy: 0.956000\n",
      " Iteration: 3720 , loss: 1.903334 Accuracy: 0.932000\n",
      " Iteration: 3730 , loss: 1.913435 Accuracy: 0.940000\n",
      " Iteration: 3740 , loss: 1.909871 Accuracy: 0.948000\n",
      " Iteration: 3750 , loss: 1.892749 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 3760 , loss: 1.935604 Accuracy: 0.916000\n",
      " Iteration: 3770 , loss: 1.903700 Accuracy: 0.940000\n",
      " Iteration: 3780 , loss: 1.891065 Accuracy: 0.956000\n",
      " Iteration: 3790 , loss: 1.915922 Accuracy: 0.924000\n",
      " Iteration: 3800 , loss: 1.887635 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 3810 , loss: 1.907392 Accuracy: 0.948000\n",
      " Iteration: 3820 , loss: 1.915048 Accuracy: 0.932000\n",
      " Iteration: 3830 , loss: 1.905449 Accuracy: 0.932000\n",
      " Iteration: 3840 , loss: 1.916677 Accuracy: 0.916000\n",
      " Iteration: 3850 , loss: 1.906713 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8698501872659176 and the number of correct results is: 929\n",
      " Iteration: 3860 , loss: 1.899098 Accuracy: 0.944000\n",
      " Iteration: 3870 , loss: 1.905353 Accuracy: 0.964000\n",
      " Iteration: 3880 , loss: 1.892420 Accuracy: 0.964000\n",
      " Iteration: 3890 , loss: 1.919462 Accuracy: 0.940000\n",
      " Iteration: 3900 , loss: 1.907381 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8726591760299626 and the number of correct results is: 932\n",
      " Iteration: 3910 , loss: 1.901690 Accuracy: 0.948000\n",
      " Iteration: 3920 , loss: 1.916343 Accuracy: 0.932000\n",
      " Iteration: 3930 , loss: 1.899400 Accuracy: 0.936000\n",
      " Iteration: 3940 , loss: 1.892777 Accuracy: 0.956000\n",
      " Iteration: 3950 , loss: 1.894016 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 3960 , loss: 1.897599 Accuracy: 0.952000\n",
      " Iteration: 3970 , loss: 1.904967 Accuracy: 0.960000\n",
      " Iteration: 3980 , loss: 1.906900 Accuracy: 0.948000\n",
      " Iteration: 3990 , loss: 1.895826 Accuracy: 0.940000\n",
      " Iteration: 4000 , loss: 1.911958 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 4010 , loss: 1.879455 Accuracy: 0.968000\n",
      " Iteration: 4020 , loss: 1.892297 Accuracy: 0.956000\n",
      " Iteration: 4030 , loss: 1.906791 Accuracy: 0.920000\n",
      " Iteration: 4040 , loss: 1.927641 Accuracy: 0.928000\n",
      " Iteration: 4050 , loss: 1.907125 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 4060 , loss: 1.902963 Accuracy: 0.936000\n",
      " Iteration: 4070 , loss: 1.909301 Accuracy: 0.924000\n",
      " Iteration: 4080 , loss: 1.909571 Accuracy: 0.932000\n",
      " Iteration: 4090 , loss: 1.895309 Accuracy: 0.956000\n",
      " Iteration: 4100 , loss: 1.890565 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8726591760299626 and the number of correct results is: 932\n",
      " Iteration: 4110 , loss: 1.906781 Accuracy: 0.932000\n",
      " Iteration: 4120 , loss: 1.912546 Accuracy: 0.936000\n",
      " Iteration: 4130 , loss: 1.887307 Accuracy: 0.960000\n",
      " Iteration: 4140 , loss: 1.894107 Accuracy: 0.952000\n",
      " Iteration: 4150 , loss: 1.891993 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 4160 , loss: 1.888249 Accuracy: 0.960000\n",
      " Iteration: 4170 , loss: 1.914094 Accuracy: 0.932000\n",
      " Iteration: 4180 , loss: 1.902391 Accuracy: 0.952000\n",
      " Iteration: 4190 , loss: 1.906444 Accuracy: 0.928000\n",
      " Iteration: 4200 , loss: 1.895065 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/__main__.py:196: RuntimeWarning: overflow encountered in exp\n",
      "/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/__main__.py:196: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration: 4210 , loss: 1.924397 Accuracy: 0.920000\n",
      " Iteration: 4220 , loss: 1.897871 Accuracy: 0.952000\n",
      " Iteration: 4230 , loss: 1.889543 Accuracy: 0.960000\n",
      " Iteration: 4240 , loss: 1.905812 Accuracy: 0.928000\n",
      " Iteration: 4250 , loss: 1.898522 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 4260 , loss: 1.883683 Accuracy: 0.960000\n",
      " Iteration: 4270 , loss: 1.903365 Accuracy: 0.932000\n",
      " Iteration: 4280 , loss: 1.896431 Accuracy: 0.940000\n",
      " Iteration: 4290 , loss: 1.876988 Accuracy: 0.956000\n",
      " Iteration: 4300 , loss: 1.897822 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 4310 , loss: 1.888964 Accuracy: 0.944000\n",
      " Iteration: 4320 , loss: 1.916746 Accuracy: 0.924000\n",
      " Iteration: 4330 , loss: 1.906587 Accuracy: 0.940000\n",
      " Iteration: 4340 , loss: 1.879249 Accuracy: 0.956000\n",
      " Iteration: 4350 , loss: 1.886254 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 4360 , loss: 1.900374 Accuracy: 0.948000\n",
      " Iteration: 4370 , loss: 1.879821 Accuracy: 0.956000\n",
      " Iteration: 4380 , loss: 1.894088 Accuracy: 0.944000\n",
      " Iteration: 4390 , loss: 1.913850 Accuracy: 0.944000\n",
      " Iteration: 4400 , loss: 1.902821 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.8689138576779026 and the number of correct results is: 928\n",
      " Iteration: 4410 , loss: 1.891130 Accuracy: 0.952000\n",
      " Iteration: 4420 , loss: 1.896339 Accuracy: 0.944000\n",
      " Iteration: 4430 , loss: 1.914538 Accuracy: 0.944000\n",
      " Iteration: 4440 , loss: 1.919513 Accuracy: 0.924000\n",
      " Iteration: 4450 , loss: 1.893506 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8735955056179775 and the number of correct results is: 933\n",
      " Iteration: 4460 , loss: 1.911624 Accuracy: 0.916000\n",
      " Iteration: 4470 , loss: 1.913459 Accuracy: 0.916000\n",
      " Iteration: 4480 , loss: 1.891722 Accuracy: 0.940000\n",
      " Iteration: 4490 , loss: 1.891667 Accuracy: 0.948000\n",
      " Iteration: 4500 , loss: 1.881551 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8717228464419475 and the number of correct results is: 931\n",
      " Iteration: 4510 , loss: 1.902748 Accuracy: 0.932000\n",
      " Iteration: 4520 , loss: 1.902061 Accuracy: 0.948000\n",
      " Iteration: 4530 , loss: 1.888685 Accuracy: 0.956000\n",
      " Iteration: 4540 , loss: 1.905656 Accuracy: 0.920000\n",
      " Iteration: 4550 , loss: 1.879895 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8867041198501873 and the number of correct results is: 947\n",
      " Iteration: 4560 , loss: 1.911898 Accuracy: 0.936000\n",
      " Iteration: 4570 , loss: 1.877658 Accuracy: 0.964000\n",
      " Iteration: 4580 , loss: 1.876140 Accuracy: 0.964000\n",
      " Iteration: 4590 , loss: 1.892958 Accuracy: 0.960000\n",
      " Iteration: 4600 , loss: 1.891919 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8867041198501873 and the number of correct results is: 947\n",
      " Iteration: 4610 , loss: 1.895188 Accuracy: 0.952000\n",
      " Iteration: 4620 , loss: 1.884372 Accuracy: 0.960000\n",
      " Iteration: 4630 , loss: 1.887442 Accuracy: 0.952000\n",
      " Iteration: 4640 , loss: 1.872321 Accuracy: 0.984000\n",
      " Iteration: 4650 , loss: 1.893087 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 4660 , loss: 1.898975 Accuracy: 0.944000\n",
      " Iteration: 4670 , loss: 1.928725 Accuracy: 0.920000\n",
      " Iteration: 4680 , loss: 1.888010 Accuracy: 0.956000\n",
      " Iteration: 4690 , loss: 1.888937 Accuracy: 0.960000\n",
      " Iteration: 4700 , loss: 1.884700 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8895131086142322 and the number of correct results is: 950\n",
      " Iteration: 4710 , loss: 1.897053 Accuracy: 0.936000\n",
      " Iteration: 4720 , loss: 1.882995 Accuracy: 0.952000\n",
      " Iteration: 4730 , loss: 1.898747 Accuracy: 0.940000\n",
      " Iteration: 4740 , loss: 1.924117 Accuracy: 0.924000\n",
      " Iteration: 4750 , loss: 1.892876 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n",
      " Iteration: 4760 , loss: 1.907090 Accuracy: 0.932000\n",
      " Iteration: 4770 , loss: 1.887902 Accuracy: 0.956000\n",
      " Iteration: 4780 , loss: 1.906894 Accuracy: 0.928000\n",
      " Iteration: 4790 , loss: 1.879330 Accuracy: 0.976000\n",
      " Iteration: 4800 , loss: 1.888029 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 4810 , loss: 1.900525 Accuracy: 0.936000\n",
      " Iteration: 4820 , loss: 1.892562 Accuracy: 0.952000\n",
      " Iteration: 4830 , loss: 1.887722 Accuracy: 0.948000\n",
      " Iteration: 4840 , loss: 1.880203 Accuracy: 0.968000\n",
      " Iteration: 4850 , loss: 1.889976 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8876404494382022 and the number of correct results is: 948\n",
      " Iteration: 4860 , loss: 1.899333 Accuracy: 0.956000\n",
      " Iteration: 4870 , loss: 1.901807 Accuracy: 0.940000\n",
      " Iteration: 4880 , loss: 1.896000 Accuracy: 0.932000\n",
      " Iteration: 4890 , loss: 1.877433 Accuracy: 0.960000\n",
      " Iteration: 4900 , loss: 1.866571 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 4910 , loss: 1.908267 Accuracy: 0.944000\n",
      " Iteration: 4920 , loss: 1.868152 Accuracy: 0.968000\n",
      " Iteration: 4930 , loss: 1.897034 Accuracy: 0.940000\n",
      " Iteration: 4940 , loss: 1.890972 Accuracy: 0.960000\n",
      " Iteration: 4950 , loss: 1.894028 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8876404494382022 and the number of correct results is: 948\n",
      " Iteration: 4960 , loss: 1.886824 Accuracy: 0.952000\n",
      " Iteration: 4970 , loss: 1.887026 Accuracy: 0.952000\n",
      " Iteration: 4980 , loss: 1.881055 Accuracy: 0.944000\n",
      " Iteration: 4990 , loss: 1.876114 Accuracy: 0.964000\n",
      " Iteration: 5000 , loss: 1.902097 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8792134831460674 and the number of correct results is: 939\n",
      " Iteration: 5010 , loss: 1.884677 Accuracy: 0.956000\n",
      " Iteration: 5020 , loss: 1.891353 Accuracy: 0.952000\n",
      " Iteration: 5030 , loss: 1.894592 Accuracy: 0.940000\n",
      " Iteration: 5040 , loss: 1.878818 Accuracy: 0.960000\n",
      " Iteration: 5050 , loss: 1.886496 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 5060 , loss: 1.876050 Accuracy: 0.956000\n",
      " Iteration: 5070 , loss: 1.862014 Accuracy: 0.976000\n",
      " Iteration: 5080 , loss: 1.886357 Accuracy: 0.956000\n",
      " Iteration: 5090 , loss: 1.905966 Accuracy: 0.940000\n",
      " Iteration: 5100 , loss: 1.913762 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.8885767790262172 and the number of correct results is: 949\n",
      " Iteration: 5110 , loss: 1.909527 Accuracy: 0.932000\n",
      " Iteration: 5120 , loss: 1.906972 Accuracy: 0.936000\n",
      " Iteration: 5130 , loss: 1.883982 Accuracy: 0.960000\n",
      " Iteration: 5140 , loss: 1.880700 Accuracy: 0.956000\n",
      " Iteration: 5150 , loss: 1.889941 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 5160 , loss: 1.898933 Accuracy: 0.940000\n",
      " Iteration: 5170 , loss: 1.892660 Accuracy: 0.936000\n",
      " Iteration: 5180 , loss: 1.885085 Accuracy: 0.960000\n",
      " Iteration: 5190 , loss: 1.897161 Accuracy: 0.948000\n",
      " Iteration: 5200 , loss: 1.900089 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 5210 , loss: 1.885132 Accuracy: 0.956000\n",
      " Iteration: 5220 , loss: 1.900628 Accuracy: 0.944000\n",
      " Iteration: 5230 , loss: 1.884467 Accuracy: 0.960000\n",
      " Iteration: 5240 , loss: 1.883000 Accuracy: 0.956000\n",
      " Iteration: 5250 , loss: 1.901769 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 5260 , loss: 1.902787 Accuracy: 0.928000\n",
      " Iteration: 5270 , loss: 1.882405 Accuracy: 0.956000\n",
      " Iteration: 5280 , loss: 1.891019 Accuracy: 0.952000\n",
      " Iteration: 5290 , loss: 1.900319 Accuracy: 0.944000\n",
      " Iteration: 5300 , loss: 1.901663 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8904494382022472 and the number of correct results is: 951\n",
      " Iteration: 5310 , loss: 1.871829 Accuracy: 0.964000\n",
      " Iteration: 5320 , loss: 1.879480 Accuracy: 0.964000\n",
      " Iteration: 5330 , loss: 1.887832 Accuracy: 0.948000\n",
      " Iteration: 5340 , loss: 1.867889 Accuracy: 0.984000\n",
      " Iteration: 5350 , loss: 1.876005 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.8876404494382022 and the number of correct results is: 948\n",
      " Iteration: 5360 , loss: 1.886390 Accuracy: 0.956000\n",
      " Iteration: 5370 , loss: 1.900693 Accuracy: 0.936000\n",
      " Iteration: 5380 , loss: 1.873067 Accuracy: 0.960000\n",
      " Iteration: 5390 , loss: 1.892268 Accuracy: 0.944000\n",
      " Iteration: 5400 , loss: 1.893463 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8867041198501873 and the number of correct results is: 947\n",
      " Iteration: 5410 , loss: 1.879015 Accuracy: 0.948000\n",
      " Iteration: 5420 , loss: 1.868284 Accuracy: 0.964000\n",
      " Iteration: 5430 , loss: 1.883411 Accuracy: 0.948000\n",
      " Iteration: 5440 , loss: 1.899488 Accuracy: 0.936000\n",
      " Iteration: 5450 , loss: 1.864987 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 5460 , loss: 1.894595 Accuracy: 0.944000\n",
      " Iteration: 5470 , loss: 1.881925 Accuracy: 0.960000\n",
      " Iteration: 5480 , loss: 1.893282 Accuracy: 0.948000\n",
      " Iteration: 5490 , loss: 1.878669 Accuracy: 0.960000\n",
      " Iteration: 5500 , loss: 1.889745 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 5510 , loss: 1.889401 Accuracy: 0.952000\n",
      " Iteration: 5520 , loss: 1.884732 Accuracy: 0.952000\n",
      " Iteration: 5530 , loss: 1.894468 Accuracy: 0.936000\n",
      " Iteration: 5540 , loss: 1.886271 Accuracy: 0.964000\n",
      " Iteration: 5550 , loss: 1.876877 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8848314606741573 and the number of correct results is: 945\n",
      " Iteration: 5560 , loss: 1.884286 Accuracy: 0.948000\n",
      " Iteration: 5570 , loss: 1.886933 Accuracy: 0.952000\n",
      " Iteration: 5580 , loss: 1.899544 Accuracy: 0.940000\n",
      " Iteration: 5590 , loss: 1.901547 Accuracy: 0.928000\n",
      " Iteration: 5600 , loss: 1.895414 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 5610 , loss: 1.898243 Accuracy: 0.936000\n",
      " Iteration: 5620 , loss: 1.875807 Accuracy: 0.960000\n",
      " Iteration: 5630 , loss: 1.902534 Accuracy: 0.940000\n",
      " Iteration: 5640 , loss: 1.888867 Accuracy: 0.960000\n",
      " Iteration: 5650 , loss: 1.899682 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 5660 , loss: 1.904938 Accuracy: 0.924000\n",
      " Iteration: 5670 , loss: 1.888412 Accuracy: 0.940000\n",
      " Iteration: 5680 , loss: 1.892812 Accuracy: 0.944000\n",
      " Iteration: 5690 , loss: 1.865280 Accuracy: 0.976000\n",
      " Iteration: 5700 , loss: 1.876716 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 5710 , loss: 1.881806 Accuracy: 0.960000\n",
      " Iteration: 5720 , loss: 1.893401 Accuracy: 0.948000\n",
      " Iteration: 5730 , loss: 1.871184 Accuracy: 0.972000\n",
      " Iteration: 5740 , loss: 1.867192 Accuracy: 0.960000\n",
      " Iteration: 5750 , loss: 1.888519 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 5760 , loss: 1.879855 Accuracy: 0.952000\n",
      " Iteration: 5770 , loss: 1.873077 Accuracy: 0.956000\n",
      " Iteration: 5780 , loss: 1.903437 Accuracy: 0.936000\n",
      " Iteration: 5790 , loss: 1.883602 Accuracy: 0.960000\n",
      " Iteration: 5800 , loss: 1.868054 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8867041198501873 and the number of correct results is: 947\n",
      " Iteration: 5810 , loss: 1.885425 Accuracy: 0.960000\n",
      " Iteration: 5820 , loss: 1.891625 Accuracy: 0.936000\n",
      " Iteration: 5830 , loss: 1.900901 Accuracy: 0.944000\n",
      " Iteration: 5840 , loss: 1.871709 Accuracy: 0.964000\n",
      " Iteration: 5850 , loss: 1.879060 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8792134831460674 and the number of correct results is: 939\n",
      " Iteration: 5860 , loss: 1.882137 Accuracy: 0.948000\n",
      " Iteration: 5870 , loss: 1.879804 Accuracy: 0.956000\n",
      " Iteration: 5880 , loss: 1.897628 Accuracy: 0.936000\n",
      " Iteration: 5890 , loss: 1.896372 Accuracy: 0.936000\n",
      " Iteration: 5900 , loss: 1.888150 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.8792134831460674 and the number of correct results is: 939\n",
      " Iteration: 5910 , loss: 1.885386 Accuracy: 0.956000\n",
      " Iteration: 5920 , loss: 1.894338 Accuracy: 0.936000\n",
      " Iteration: 5930 , loss: 1.883486 Accuracy: 0.956000\n",
      " Iteration: 5940 , loss: 1.884807 Accuracy: 0.952000\n",
      " Iteration: 5950 , loss: 1.888867 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 5960 , loss: 1.897657 Accuracy: 0.940000\n",
      " Iteration: 5970 , loss: 1.866842 Accuracy: 0.972000\n",
      " Iteration: 5980 , loss: 1.896231 Accuracy: 0.936000\n",
      " Iteration: 5990 , loss: 1.880391 Accuracy: 0.952000\n",
      " Iteration: 6000 , loss: 1.891374 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 6010 , loss: 1.896849 Accuracy: 0.948000\n",
      " Iteration: 6020 , loss: 1.882336 Accuracy: 0.964000\n",
      " Iteration: 6030 , loss: 1.896940 Accuracy: 0.944000\n",
      " Iteration: 6040 , loss: 1.863820 Accuracy: 0.976000\n",
      " Iteration: 6050 , loss: 1.871726 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 6060 , loss: 1.884587 Accuracy: 0.952000\n",
      " Iteration: 6070 , loss: 1.886568 Accuracy: 0.944000\n",
      " Iteration: 6080 , loss: 1.872876 Accuracy: 0.956000\n",
      " Iteration: 6090 , loss: 1.875378 Accuracy: 0.960000\n",
      " Iteration: 6100 , loss: 1.888623 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 6110 , loss: 1.878369 Accuracy: 0.956000\n",
      " Iteration: 6120 , loss: 1.870100 Accuracy: 0.956000\n",
      " Iteration: 6130 , loss: 1.879465 Accuracy: 0.948000\n",
      " Iteration: 6140 , loss: 1.879435 Accuracy: 0.960000\n",
      " Iteration: 6150 , loss: 1.864602 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8735955056179775 and the number of correct results is: 933\n",
      " Iteration: 6160 , loss: 1.884948 Accuracy: 0.948000\n",
      " Iteration: 6170 , loss: 1.883244 Accuracy: 0.944000\n",
      " Iteration: 6180 , loss: 1.882713 Accuracy: 0.964000\n",
      " Iteration: 6190 , loss: 1.876811 Accuracy: 0.952000\n",
      " Iteration: 6200 , loss: 1.877818 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.8735955056179775 and the number of correct results is: 933\n",
      " Iteration: 6210 , loss: 1.882947 Accuracy: 0.960000\n",
      " Iteration: 6220 , loss: 1.891087 Accuracy: 0.944000\n",
      " Iteration: 6230 , loss: 1.897486 Accuracy: 0.940000\n",
      " Iteration: 6240 , loss: 1.877772 Accuracy: 0.960000\n",
      " Iteration: 6250 , loss: 1.876367 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 6260 , loss: 1.875154 Accuracy: 0.960000\n",
      " Iteration: 6270 , loss: 1.886384 Accuracy: 0.960000\n",
      " Iteration: 6280 , loss: 1.877916 Accuracy: 0.944000\n",
      " Iteration: 6290 , loss: 1.886682 Accuracy: 0.948000\n",
      " Iteration: 6300 , loss: 1.874646 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 6310 , loss: 1.890235 Accuracy: 0.944000\n",
      " Iteration: 6320 , loss: 1.876368 Accuracy: 0.960000\n",
      " Iteration: 6330 , loss: 1.886400 Accuracy: 0.948000\n",
      " Iteration: 6340 , loss: 1.875911 Accuracy: 0.964000\n",
      " Iteration: 6350 , loss: 1.884993 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 6360 , loss: 1.892018 Accuracy: 0.944000\n",
      " Iteration: 6370 , loss: 1.868679 Accuracy: 0.976000\n",
      " Iteration: 6380 , loss: 1.870807 Accuracy: 0.972000\n",
      " Iteration: 6390 , loss: 1.853745 Accuracy: 0.976000\n",
      " Iteration: 6400 , loss: 1.878800 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n",
      " Iteration: 6410 , loss: 1.865752 Accuracy: 0.984000\n",
      " Iteration: 6420 , loss: 1.863820 Accuracy: 0.968000\n",
      " Iteration: 6430 , loss: 1.858336 Accuracy: 0.980000\n",
      " Iteration: 6440 , loss: 1.877317 Accuracy: 0.964000\n",
      " Iteration: 6450 , loss: 1.891818 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 6460 , loss: 1.869086 Accuracy: 0.972000\n",
      " Iteration: 6470 , loss: 1.861406 Accuracy: 0.980000\n",
      " Iteration: 6480 , loss: 1.885599 Accuracy: 0.952000\n",
      " Iteration: 6490 , loss: 1.887058 Accuracy: 0.968000\n",
      " Iteration: 6500 , loss: 1.866272 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8698501872659176 and the number of correct results is: 929\n",
      " Iteration: 6510 , loss: 1.871456 Accuracy: 0.976000\n",
      " Iteration: 6520 , loss: 1.884659 Accuracy: 0.960000\n",
      " Iteration: 6530 , loss: 1.872272 Accuracy: 0.964000\n",
      " Iteration: 6540 , loss: 1.875186 Accuracy: 0.964000\n",
      " Iteration: 6550 , loss: 1.875277 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 6560 , loss: 1.879631 Accuracy: 0.952000\n",
      " Iteration: 6570 , loss: 1.886245 Accuracy: 0.952000\n",
      " Iteration: 6580 , loss: 1.888656 Accuracy: 0.952000\n",
      " Iteration: 6590 , loss: 1.897335 Accuracy: 0.944000\n",
      " Iteration: 6600 , loss: 1.864596 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8904494382022472 and the number of correct results is: 951\n",
      " Iteration: 6610 , loss: 1.871218 Accuracy: 0.956000\n",
      " Iteration: 6620 , loss: 1.864903 Accuracy: 0.956000\n",
      " Iteration: 6630 , loss: 1.886783 Accuracy: 0.952000\n",
      " Iteration: 6640 , loss: 1.866471 Accuracy: 0.960000\n",
      " Iteration: 6650 , loss: 1.870903 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8820224719101124 and the number of correct results is: 942\n",
      " Iteration: 6660 , loss: 1.892729 Accuracy: 0.956000\n",
      " Iteration: 6670 , loss: 1.873559 Accuracy: 0.968000\n",
      " Iteration: 6680 , loss: 1.888594 Accuracy: 0.944000\n",
      " Iteration: 6690 , loss: 1.868061 Accuracy: 0.968000\n",
      " Iteration: 6700 , loss: 1.864454 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 6710 , loss: 1.871337 Accuracy: 0.968000\n",
      " Iteration: 6720 , loss: 1.882078 Accuracy: 0.960000\n",
      " Iteration: 6730 , loss: 1.889462 Accuracy: 0.944000\n",
      " Iteration: 6740 , loss: 1.848674 Accuracy: 0.984000\n",
      " Iteration: 6750 , loss: 1.871798 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 6760 , loss: 1.876083 Accuracy: 0.960000\n",
      " Iteration: 6770 , loss: 1.859477 Accuracy: 0.980000\n",
      " Iteration: 6780 , loss: 1.874265 Accuracy: 0.964000\n",
      " Iteration: 6790 , loss: 1.878190 Accuracy: 0.968000\n",
      " Iteration: 6800 , loss: 1.878408 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8876404494382022 and the number of correct results is: 948\n",
      " Iteration: 6810 , loss: 1.873673 Accuracy: 0.952000\n",
      " Iteration: 6820 , loss: 1.869684 Accuracy: 0.960000\n",
      " Iteration: 6830 , loss: 1.878192 Accuracy: 0.964000\n",
      " Iteration: 6840 , loss: 1.873442 Accuracy: 0.968000\n",
      " Iteration: 6850 , loss: 1.852795 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 6860 , loss: 1.884588 Accuracy: 0.952000\n",
      " Iteration: 6870 , loss: 1.885994 Accuracy: 0.944000\n",
      " Iteration: 6880 , loss: 1.879182 Accuracy: 0.952000\n",
      " Iteration: 6890 , loss: 1.853584 Accuracy: 0.988000\n",
      " Iteration: 6900 , loss: 1.860696 Accuracy: 0.976000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 6910 , loss: 1.877425 Accuracy: 0.952000\n",
      " Iteration: 6920 , loss: 1.873471 Accuracy: 0.964000\n",
      " Iteration: 6930 , loss: 1.880800 Accuracy: 0.956000\n",
      " Iteration: 6940 , loss: 1.886853 Accuracy: 0.936000\n",
      " Iteration: 6950 , loss: 1.862177 Accuracy: 0.976000\n",
      "The postprocessing average accuracy is: 0.8838951310861424 and the number of correct results is: 944\n",
      " Iteration: 6960 , loss: 1.869742 Accuracy: 0.964000\n",
      " Iteration: 6970 , loss: 1.885207 Accuracy: 0.944000\n",
      " Iteration: 6980 , loss: 1.893710 Accuracy: 0.932000\n",
      " Iteration: 6990 , loss: 1.890020 Accuracy: 0.940000\n",
      " Iteration: 7000 , loss: 1.885141 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 7010 , loss: 1.885571 Accuracy: 0.952000\n",
      " Iteration: 7020 , loss: 1.871389 Accuracy: 0.964000\n",
      " Iteration: 7030 , loss: 1.864777 Accuracy: 0.972000\n",
      " Iteration: 7040 , loss: 1.867806 Accuracy: 0.968000\n",
      " Iteration: 7050 , loss: 1.855366 Accuracy: 0.984000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 7060 , loss: 1.873899 Accuracy: 0.976000\n",
      " Iteration: 7070 , loss: 1.873521 Accuracy: 0.968000\n",
      " Iteration: 7080 , loss: 1.878587 Accuracy: 0.948000\n",
      " Iteration: 7090 , loss: 1.858149 Accuracy: 0.976000\n",
      " Iteration: 7100 , loss: 1.894361 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 7110 , loss: 1.872863 Accuracy: 0.960000\n",
      " Iteration: 7120 , loss: 1.878976 Accuracy: 0.964000\n",
      " Iteration: 7130 , loss: 1.874032 Accuracy: 0.964000\n",
      " Iteration: 7140 , loss: 1.869819 Accuracy: 0.972000\n",
      " Iteration: 7150 , loss: 1.877638 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.8848314606741573 and the number of correct results is: 945\n",
      " Iteration: 7160 , loss: 1.854276 Accuracy: 0.984000\n",
      " Iteration: 7170 , loss: 1.863609 Accuracy: 0.960000\n",
      " Iteration: 7180 , loss: 1.876364 Accuracy: 0.952000\n",
      " Iteration: 7190 , loss: 1.870331 Accuracy: 0.976000\n",
      " Iteration: 7200 , loss: 1.861639 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8885767790262172 and the number of correct results is: 949\n",
      " Iteration: 7210 , loss: 1.885789 Accuracy: 0.940000\n",
      " Iteration: 7220 , loss: 1.881423 Accuracy: 0.952000\n",
      " Iteration: 7230 , loss: 1.894495 Accuracy: 0.936000\n",
      " Iteration: 7240 , loss: 1.870545 Accuracy: 0.964000\n",
      " Iteration: 7250 , loss: 1.875867 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8876404494382022 and the number of correct results is: 948\n",
      " Iteration: 7260 , loss: 1.875200 Accuracy: 0.956000\n",
      " Iteration: 7270 , loss: 1.878581 Accuracy: 0.964000\n",
      " Iteration: 7280 , loss: 1.859800 Accuracy: 0.964000\n",
      " Iteration: 7290 , loss: 1.881517 Accuracy: 0.948000\n",
      " Iteration: 7300 , loss: 1.852906 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 7310 , loss: 1.861789 Accuracy: 0.976000\n",
      " Iteration: 7320 , loss: 1.872808 Accuracy: 0.960000\n",
      " Iteration: 7330 , loss: 1.881602 Accuracy: 0.952000\n",
      " Iteration: 7340 , loss: 1.871235 Accuracy: 0.964000\n",
      " Iteration: 7350 , loss: 1.875829 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8792134831460674 and the number of correct results is: 939\n",
      " Iteration: 7360 , loss: 1.869231 Accuracy: 0.968000\n",
      " Iteration: 7370 , loss: 1.865834 Accuracy: 0.964000\n",
      " Iteration: 7380 , loss: 1.884065 Accuracy: 0.940000\n",
      " Iteration: 7390 , loss: 1.859786 Accuracy: 0.968000\n",
      " Iteration: 7400 , loss: 1.864337 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8707865168539326 and the number of correct results is: 930\n",
      " Iteration: 7410 , loss: 1.866780 Accuracy: 0.972000\n",
      " Iteration: 7420 , loss: 1.869145 Accuracy: 0.964000\n",
      " Iteration: 7430 , loss: 1.870277 Accuracy: 0.964000\n",
      " Iteration: 7440 , loss: 1.841675 Accuracy: 0.988000\n",
      " Iteration: 7450 , loss: 1.858710 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 7460 , loss: 1.859307 Accuracy: 0.976000\n",
      " Iteration: 7470 , loss: 1.856337 Accuracy: 0.976000\n",
      " Iteration: 7480 , loss: 1.872318 Accuracy: 0.964000\n",
      " Iteration: 7490 , loss: 1.864639 Accuracy: 0.968000\n",
      " Iteration: 7500 , loss: 1.865434 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8867041198501873 and the number of correct results is: 947\n",
      " Iteration: 7510 , loss: 1.857257 Accuracy: 0.988000\n",
      " Iteration: 7520 , loss: 1.878025 Accuracy: 0.952000\n",
      " Iteration: 7530 , loss: 1.872876 Accuracy: 0.964000\n",
      " Iteration: 7540 , loss: 1.868390 Accuracy: 0.972000\n",
      " Iteration: 7550 , loss: 1.866197 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8670411985018727 and the number of correct results is: 926\n",
      " Iteration: 7560 , loss: 1.877285 Accuracy: 0.952000\n",
      " Iteration: 7570 , loss: 1.873805 Accuracy: 0.968000\n",
      " Iteration: 7580 , loss: 1.893451 Accuracy: 0.948000\n",
      " Iteration: 7590 , loss: 1.864597 Accuracy: 0.960000\n",
      " Iteration: 7600 , loss: 1.868711 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 7610 , loss: 1.897375 Accuracy: 0.932000\n",
      " Iteration: 7620 , loss: 1.895788 Accuracy: 0.940000\n",
      " Iteration: 7630 , loss: 1.892737 Accuracy: 0.936000\n",
      " Iteration: 7640 , loss: 1.873954 Accuracy: 0.964000\n",
      " Iteration: 7650 , loss: 1.860997 Accuracy: 0.976000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 7660 , loss: 1.873329 Accuracy: 0.956000\n",
      " Iteration: 7670 , loss: 1.870998 Accuracy: 0.960000\n",
      " Iteration: 7680 , loss: 1.876971 Accuracy: 0.948000\n",
      " Iteration: 7690 , loss: 1.881104 Accuracy: 0.952000\n",
      " Iteration: 7700 , loss: 1.879376 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8801498127340824 and the number of correct results is: 940\n",
      " Iteration: 7710 , loss: 1.868546 Accuracy: 0.972000\n",
      " Iteration: 7720 , loss: 1.880455 Accuracy: 0.968000\n",
      " Iteration: 7730 , loss: 1.861346 Accuracy: 0.972000\n",
      " Iteration: 7740 , loss: 1.861807 Accuracy: 0.976000\n",
      " Iteration: 7750 , loss: 1.849413 Accuracy: 0.988000\n",
      "The postprocessing average accuracy is: 0.8848314606741573 and the number of correct results is: 945\n",
      " Iteration: 7760 , loss: 1.884997 Accuracy: 0.944000\n",
      " Iteration: 7770 , loss: 1.871151 Accuracy: 0.952000\n",
      " Iteration: 7780 , loss: 1.866601 Accuracy: 0.964000\n",
      " Iteration: 7790 , loss: 1.860174 Accuracy: 0.964000\n",
      " Iteration: 7800 , loss: 1.867176 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 7810 , loss: 1.877457 Accuracy: 0.960000\n",
      " Iteration: 7820 , loss: 1.854444 Accuracy: 0.980000\n",
      " Iteration: 7830 , loss: 1.875454 Accuracy: 0.968000\n",
      " Iteration: 7840 , loss: 1.852371 Accuracy: 0.980000\n",
      " Iteration: 7850 , loss: 1.859972 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 7860 , loss: 1.856328 Accuracy: 0.972000\n",
      " Iteration: 7870 , loss: 1.876327 Accuracy: 0.960000\n",
      " Iteration: 7880 , loss: 1.856036 Accuracy: 0.980000\n",
      " Iteration: 7890 , loss: 1.864375 Accuracy: 0.968000\n",
      " Iteration: 7900 , loss: 1.859850 Accuracy: 0.976000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 7910 , loss: 1.873459 Accuracy: 0.968000\n",
      " Iteration: 7920 , loss: 1.863250 Accuracy: 0.980000\n",
      " Iteration: 7930 , loss: 1.871398 Accuracy: 0.956000\n",
      " Iteration: 7940 , loss: 1.855814 Accuracy: 0.992000\n",
      " Iteration: 7950 , loss: 1.863548 Accuracy: 0.976000\n",
      "The postprocessing average accuracy is: 0.8885767790262172 and the number of correct results is: 949\n",
      " Iteration: 7960 , loss: 1.874212 Accuracy: 0.964000\n",
      " Iteration: 7970 , loss: 1.884696 Accuracy: 0.944000\n",
      " Iteration: 7980 , loss: 1.868611 Accuracy: 0.972000\n",
      " Iteration: 7990 , loss: 1.876286 Accuracy: 0.976000\n",
      " Iteration: 8000 , loss: 1.855150 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8764044943820225 and the number of correct results is: 936\n",
      " Iteration: 8010 , loss: 1.861949 Accuracy: 0.968000\n",
      " Iteration: 8020 , loss: 1.875830 Accuracy: 0.956000\n",
      " Iteration: 8030 , loss: 1.879642 Accuracy: 0.948000\n",
      " Iteration: 8040 , loss: 1.883252 Accuracy: 0.948000\n",
      " Iteration: 8050 , loss: 1.875679 Accuracy: 0.960000\n",
      "The postprocessing average accuracy is: 0.8895131086142322 and the number of correct results is: 950\n",
      " Iteration: 8060 , loss: 1.864430 Accuracy: 0.964000\n",
      " Iteration: 8070 , loss: 1.872172 Accuracy: 0.952000\n",
      " Iteration: 8080 , loss: 1.856541 Accuracy: 0.968000\n",
      " Iteration: 8090 , loss: 1.866848 Accuracy: 0.968000\n",
      " Iteration: 8100 , loss: 1.841178 Accuracy: 0.992000\n",
      "The postprocessing average accuracy is: 0.8698501872659176 and the number of correct results is: 929\n",
      " Iteration: 8110 , loss: 1.862620 Accuracy: 0.964000\n",
      " Iteration: 8120 , loss: 1.864877 Accuracy: 0.968000\n",
      " Iteration: 8130 , loss: 1.870121 Accuracy: 0.960000\n",
      " Iteration: 8140 , loss: 1.854205 Accuracy: 0.980000\n",
      " Iteration: 8150 , loss: 1.862387 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8848314606741573 and the number of correct results is: 945\n",
      " Iteration: 8160 , loss: 1.868187 Accuracy: 0.960000\n",
      " Iteration: 8170 , loss: 1.853894 Accuracy: 0.988000\n",
      " Iteration: 8180 , loss: 1.874743 Accuracy: 0.968000\n",
      " Iteration: 8190 , loss: 1.863301 Accuracy: 0.972000\n",
      " Iteration: 8200 , loss: 1.864926 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 8210 , loss: 1.859885 Accuracy: 0.972000\n",
      " Iteration: 8220 , loss: 1.863313 Accuracy: 0.968000\n",
      " Iteration: 8230 , loss: 1.857681 Accuracy: 0.976000\n",
      " Iteration: 8240 , loss: 1.876266 Accuracy: 0.968000\n",
      " Iteration: 8250 , loss: 1.859731 Accuracy: 0.976000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 8260 , loss: 1.852537 Accuracy: 0.980000\n",
      " Iteration: 8270 , loss: 1.886599 Accuracy: 0.940000\n",
      " Iteration: 8280 , loss: 1.869219 Accuracy: 0.956000\n",
      " Iteration: 8290 , loss: 1.876688 Accuracy: 0.948000\n",
      " Iteration: 8300 , loss: 1.866823 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.8782771535580525 and the number of correct results is: 938\n",
      " Iteration: 8310 , loss: 1.876810 Accuracy: 0.956000\n",
      " Iteration: 8320 , loss: 1.868453 Accuracy: 0.968000\n",
      " Iteration: 8330 , loss: 1.882755 Accuracy: 0.960000\n",
      " Iteration: 8340 , loss: 1.866319 Accuracy: 0.964000\n",
      " Iteration: 8350 , loss: 1.849407 Accuracy: 0.984000\n",
      "The postprocessing average accuracy is: 0.8773408239700374 and the number of correct results is: 937\n",
      " Iteration: 8360 , loss: 1.884633 Accuracy: 0.948000\n",
      " Iteration: 8370 , loss: 1.865618 Accuracy: 0.968000\n",
      " Iteration: 8380 , loss: 1.857723 Accuracy: 0.984000\n",
      " Iteration: 8390 , loss: 1.860398 Accuracy: 0.968000\n",
      " Iteration: 8400 , loss: 1.863084 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8745318352059925 and the number of correct results is: 934\n",
      " Iteration: 8410 , loss: 1.862858 Accuracy: 0.964000\n",
      " Iteration: 8420 , loss: 1.866786 Accuracy: 0.976000\n",
      " Iteration: 8430 , loss: 1.852057 Accuracy: 0.980000\n",
      " Iteration: 8440 , loss: 1.874848 Accuracy: 0.968000\n",
      " Iteration: 8450 , loss: 1.849980 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 8460 , loss: 1.858396 Accuracy: 0.976000\n",
      " Iteration: 8470 , loss: 1.854573 Accuracy: 0.980000\n",
      " Iteration: 8480 , loss: 1.862884 Accuracy: 0.980000\n",
      " Iteration: 8490 , loss: 1.864889 Accuracy: 0.976000\n",
      " Iteration: 8500 , loss: 1.869345 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8829588014981273 and the number of correct results is: 943\n",
      " Iteration: 8510 , loss: 1.882591 Accuracy: 0.948000\n",
      " Iteration: 8520 , loss: 1.849723 Accuracy: 0.992000\n",
      " Iteration: 8530 , loss: 1.876081 Accuracy: 0.960000\n",
      " Iteration: 8540 , loss: 1.853403 Accuracy: 0.984000\n",
      " Iteration: 8550 , loss: 1.857713 Accuracy: 0.972000\n",
      "The postprocessing average accuracy is: 0.8857677902621723 and the number of correct results is: 946\n",
      " Iteration: 8560 , loss: 1.850489 Accuracy: 0.988000\n",
      " Iteration: 8570 , loss: 1.867022 Accuracy: 0.952000\n",
      " Iteration: 8580 , loss: 1.847015 Accuracy: 0.984000\n",
      " Iteration: 8590 , loss: 1.890943 Accuracy: 0.936000\n",
      " Iteration: 8600 , loss: 1.874650 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.8754681647940075 and the number of correct results is: 935\n",
      " Iteration: 8610 , loss: 1.873071 Accuracy: 0.956000\n",
      " Iteration: 8620 , loss: 1.868976 Accuracy: 0.960000\n",
      " Iteration: 8630 , loss: 1.861165 Accuracy: 0.976000\n",
      " Iteration: 8640 , loss: 1.867633 Accuracy: 0.960000\n",
      " Iteration: 8650 , loss: 1.863697 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.8810861423220974 and the number of correct results is: 941\n",
      " Iteration: 8660 , loss: 1.859966 Accuracy: 0.968000\n",
      " Iteration: 8670 , loss: 1.856771 Accuracy: 0.976000\n",
      " Iteration: 8680 , loss: 1.864570 Accuracy: 0.968000\n",
      " Iteration: 8690 , loss: 1.871089 Accuracy: 0.968000\n",
      " Iteration: 8700 , loss: 1.843497 Accuracy: 0.980000\n",
      "The postprocessing average accuracy is: 0.8876404494382022 and the number of correct results is: 948\n",
      " Iteration: 8710 , loss: 1.883309 Accuracy: 0.956000\n",
      " Iteration: 8720 , loss: 1.858928 Accuracy: 0.976000\n",
      " Iteration: 8730 , loss: 1.850460 Accuracy: 0.984000\n",
      " Iteration: 8740 , loss: 1.874748 Accuracy: 0.956000\n",
      " Iteration: 8750 , loss: 1.872979 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.8885767790262172 and the number of correct results is: 949\n",
      "\n",
      "Optimization of Split 1 Finished\n",
      "\n",
      "\n",
      "The number of sequences found in split 1 are: 89\n",
      "The number of sequences found in split 2 are: 80\n",
      "The number of sequences found in split 3 are: 92\n",
      "The number of iterations for in this split is: 803.9\n",
      "Starting training of Sub_Jhmdb \n",
      "\n",
      "loaded data 1 well\n",
      "shape of the data 30 number of labels 12 size of train data ( 8039 8039 ) \n",
      "\n",
      "\n",
      "layer 1 operation results\n",
      "h_conv is: Tensor(\"Relu:0\", shape=(?, 1, 256), dtype=float32)\n",
      "h_conv_ to FCN is: Tensor(\"Reshape_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 2 operation results\n",
      "h_fc1 is: Tensor(\"Relu_1:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc1_drop is: Tensor(\"dropout/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 3 operation results\n",
      "h_fc2 is: Tensor(\"Relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc2_drop is: Tensor(\"dropout_1/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 4 operation results\n",
      "h_fc3 is: Tensor(\"add_3:0\", shape=(?, 12), dtype=float32)\n",
      "y_conv is: Tensor(\"add_4:0\", shape=(?, 12), dtype=float32)\n",
      "\n",
      " Optimization of Split 1 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.485236 Accuracy: 0.108000\n",
      "The postprocessing average accuracy is: 0.2696629213483146 and the number of correct results is: 24\n",
      " Iteration: 10 , loss: 2.396415 Accuracy: 0.284000\n",
      " Iteration: 20 , loss: 2.340176 Accuracy: 0.396000\n",
      " Iteration: 30 , loss: 2.239600 Accuracy: 0.516000\n",
      " Iteration: 40 , loss: 2.264441 Accuracy: 0.440000\n",
      " Iteration: 50 , loss: 2.205700 Accuracy: 0.520000\n",
      "The postprocessing average accuracy is: 0.47191011235955055 and the number of correct results is: 42\n",
      " Iteration: 60 , loss: 2.205935 Accuracy: 0.532000\n",
      " Iteration: 70 , loss: 2.143001 Accuracy: 0.596000\n",
      " Iteration: 80 , loss: 2.142450 Accuracy: 0.560000\n",
      " Iteration: 90 , loss: 2.110379 Accuracy: 0.620000\n",
      " Iteration: 100 , loss: 2.066661 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.5730337078651685 and the number of correct results is: 51\n",
      " Iteration: 110 , loss: 2.051803 Accuracy: 0.680000\n",
      " Iteration: 120 , loss: 2.040755 Accuracy: 0.716000\n",
      " Iteration: 130 , loss: 2.034915 Accuracy: 0.712000\n",
      " Iteration: 140 , loss: 2.036918 Accuracy: 0.664000\n",
      " Iteration: 150 , loss: 2.034977 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.6067415730337079 and the number of correct results is: 54\n",
      " Iteration: 160 , loss: 1.983307 Accuracy: 0.772000\n",
      " Iteration: 170 , loss: 2.028277 Accuracy: 0.712000\n",
      " Iteration: 180 , loss: 2.003129 Accuracy: 0.744000\n",
      " Iteration: 190 , loss: 1.962803 Accuracy: 0.784000\n",
      " Iteration: 200 , loss: 1.953057 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.651685393258427 and the number of correct results is: 58\n",
      " Iteration: 210 , loss: 1.959901 Accuracy: 0.724000\n",
      " Iteration: 220 , loss: 1.943188 Accuracy: 0.780000\n",
      " Iteration: 230 , loss: 1.939525 Accuracy: 0.788000\n",
      " Iteration: 240 , loss: 1.912261 Accuracy: 0.804000\n",
      " Iteration: 250 , loss: 1.958598 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.6292134831460674 and the number of correct results is: 56\n",
      " Iteration: 260 , loss: 1.880795 Accuracy: 0.828000\n",
      " Iteration: 270 , loss: 1.904715 Accuracy: 0.784000\n",
      " Iteration: 280 , loss: 1.885585 Accuracy: 0.820000\n",
      " Iteration: 290 , loss: 1.880840 Accuracy: 0.808000\n",
      " Iteration: 300 , loss: 1.871805 Accuracy: 0.832000\n",
      "The postprocessing average accuracy is: 0.6292134831460674 and the number of correct results is: 56\n",
      " Iteration: 310 , loss: 1.873501 Accuracy: 0.816000\n",
      " Iteration: 320 , loss: 1.854278 Accuracy: 0.864000\n",
      " Iteration: 330 , loss: 1.858121 Accuracy: 0.840000\n",
      " Iteration: 340 , loss: 1.828772 Accuracy: 0.868000\n",
      " Iteration: 350 , loss: 1.844811 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.6629213483146067 and the number of correct results is: 59\n",
      " Iteration: 360 , loss: 1.831322 Accuracy: 0.868000\n",
      " Iteration: 370 , loss: 1.865347 Accuracy: 0.824000\n",
      " Iteration: 380 , loss: 1.815172 Accuracy: 0.876000\n",
      " Iteration: 390 , loss: 1.799125 Accuracy: 0.908000\n",
      " Iteration: 400 , loss: 1.855651 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.6741573033707865 and the number of correct results is: 60\n",
      " Iteration: 410 , loss: 1.833912 Accuracy: 0.840000\n",
      " Iteration: 420 , loss: 1.775157 Accuracy: 0.920000\n",
      " Iteration: 430 , loss: 1.816830 Accuracy: 0.900000\n",
      " Iteration: 440 , loss: 1.819060 Accuracy: 0.896000\n",
      " Iteration: 450 , loss: 1.784558 Accuracy: 0.896000\n",
      "The postprocessing average accuracy is: 0.651685393258427 and the number of correct results is: 58\n",
      " Iteration: 460 , loss: 1.790791 Accuracy: 0.884000\n",
      " Iteration: 470 , loss: 1.820246 Accuracy: 0.856000\n",
      " Iteration: 480 , loss: 1.771988 Accuracy: 0.904000\n",
      " Iteration: 490 , loss: 1.807453 Accuracy: 0.884000\n",
      " Iteration: 500 , loss: 1.794851 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.651685393258427 and the number of correct results is: 58\n",
      " Iteration: 510 , loss: 1.794903 Accuracy: 0.876000\n",
      " Iteration: 520 , loss: 1.767319 Accuracy: 0.920000\n",
      " Iteration: 530 , loss: 1.777631 Accuracy: 0.900000\n",
      " Iteration: 540 , loss: 1.779890 Accuracy: 0.912000\n",
      " Iteration: 550 , loss: 1.760735 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.7078651685393258 and the number of correct results is: 63\n",
      " Iteration: 560 , loss: 1.814217 Accuracy: 0.876000\n",
      " Iteration: 570 , loss: 1.738966 Accuracy: 0.928000\n",
      " Iteration: 580 , loss: 1.756777 Accuracy: 0.920000\n",
      " Iteration: 590 , loss: 1.745935 Accuracy: 0.904000\n",
      " Iteration: 600 , loss: 1.761842 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.6966292134831461 and the number of correct results is: 62\n",
      " Iteration: 610 , loss: 1.736685 Accuracy: 0.932000\n",
      " Iteration: 620 , loss: 1.747234 Accuracy: 0.944000\n",
      " Iteration: 630 , loss: 1.756171 Accuracy: 0.908000\n",
      " Iteration: 640 , loss: 1.745029 Accuracy: 0.908000\n",
      " Iteration: 650 , loss: 1.758323 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.6853932584269663 and the number of correct results is: 61\n",
      " Iteration: 660 , loss: 1.741095 Accuracy: 0.924000\n",
      " Iteration: 670 , loss: 1.745445 Accuracy: 0.924000\n",
      " Iteration: 680 , loss: 1.727255 Accuracy: 0.928000\n",
      " Iteration: 690 , loss: 1.769157 Accuracy: 0.892000\n",
      " Iteration: 700 , loss: 1.750323 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.6966292134831461 and the number of correct results is: 62\n",
      " Iteration: 710 , loss: 1.720726 Accuracy: 0.940000\n",
      " Iteration: 720 , loss: 1.748926 Accuracy: 0.908000\n",
      " Iteration: 730 , loss: 1.732454 Accuracy: 0.940000\n",
      " Iteration: 740 , loss: 1.724657 Accuracy: 0.964000\n",
      " Iteration: 750 , loss: 1.725883 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.6741573033707865 and the number of correct results is: 60\n",
      " Iteration: 760 , loss: 1.724428 Accuracy: 0.948000\n",
      " Iteration: 770 , loss: 1.723728 Accuracy: 0.940000\n",
      " Iteration: 780 , loss: 1.727204 Accuracy: 0.944000\n",
      " Iteration: 790 , loss: 1.711466 Accuracy: 0.928000\n",
      " Iteration: 800 , loss: 1.708727 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.6853932584269663 and the number of correct results is: 61\n",
      "\n",
      "Optimization of Split 1 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 2 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.483185 Accuracy: 0.116000\n",
      "The postprocessing average accuracy is: 0.1375 and the number of correct results is: 11\n",
      " Iteration: 10 , loss: 2.380234 Accuracy: 0.284000\n",
      " Iteration: 20 , loss: 2.329894 Accuracy: 0.368000\n",
      " Iteration: 30 , loss: 2.237777 Accuracy: 0.532000\n",
      " Iteration: 40 , loss: 2.218933 Accuracy: 0.540000\n",
      " Iteration: 50 , loss: 2.134840 Accuracy: 0.592000\n",
      "The postprocessing average accuracy is: 0.5 and the number of correct results is: 40\n",
      " Iteration: 60 , loss: 2.092433 Accuracy: 0.680000\n",
      " Iteration: 70 , loss: 2.154701 Accuracy: 0.600000\n",
      " Iteration: 80 , loss: 2.094988 Accuracy: 0.676000\n",
      " Iteration: 90 , loss: 2.123079 Accuracy: 0.580000\n",
      " Iteration: 100 , loss: 2.053966 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.6125 and the number of correct results is: 49\n",
      " Iteration: 110 , loss: 2.036620 Accuracy: 0.700000\n",
      " Iteration: 120 , loss: 2.060051 Accuracy: 0.664000\n",
      " Iteration: 130 , loss: 2.018936 Accuracy: 0.716000\n",
      " Iteration: 140 , loss: 2.029204 Accuracy: 0.696000\n",
      " Iteration: 150 , loss: 1.996552 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 48\n",
      " Iteration: 160 , loss: 1.963352 Accuracy: 0.772000\n",
      " Iteration: 170 , loss: 1.990350 Accuracy: 0.748000\n",
      " Iteration: 180 , loss: 1.977657 Accuracy: 0.732000\n",
      " Iteration: 190 , loss: 1.949717 Accuracy: 0.764000\n",
      " Iteration: 200 , loss: 1.971178 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.7125 and the number of correct results is: 57\n",
      " Iteration: 210 , loss: 1.955115 Accuracy: 0.768000\n",
      " Iteration: 220 , loss: 1.911744 Accuracy: 0.800000\n",
      " Iteration: 230 , loss: 1.902165 Accuracy: 0.820000\n",
      " Iteration: 240 , loss: 1.900783 Accuracy: 0.832000\n",
      " Iteration: 250 , loss: 1.906938 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.7 and the number of correct results is: 56\n",
      " Iteration: 260 , loss: 1.868849 Accuracy: 0.840000\n",
      " Iteration: 270 , loss: 1.873381 Accuracy: 0.840000\n",
      " Iteration: 280 , loss: 1.842244 Accuracy: 0.852000\n",
      " Iteration: 290 , loss: 1.857297 Accuracy: 0.848000\n",
      " Iteration: 300 , loss: 1.851717 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.7125 and the number of correct results is: 57\n",
      " Iteration: 310 , loss: 1.877279 Accuracy: 0.836000\n",
      " Iteration: 320 , loss: 1.816733 Accuracy: 0.892000\n",
      " Iteration: 330 , loss: 1.869907 Accuracy: 0.808000\n",
      " Iteration: 340 , loss: 1.842610 Accuracy: 0.876000\n",
      " Iteration: 350 , loss: 1.834885 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.7 and the number of correct results is: 56\n",
      " Iteration: 360 , loss: 1.802798 Accuracy: 0.912000\n",
      " Iteration: 370 , loss: 1.824155 Accuracy: 0.860000\n",
      " Iteration: 380 , loss: 1.811539 Accuracy: 0.888000\n",
      " Iteration: 390 , loss: 1.820441 Accuracy: 0.852000\n",
      " Iteration: 400 , loss: 1.820087 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.7125 and the number of correct results is: 57\n",
      " Iteration: 410 , loss: 1.786451 Accuracy: 0.900000\n",
      " Iteration: 420 , loss: 1.787631 Accuracy: 0.916000\n",
      " Iteration: 430 , loss: 1.806334 Accuracy: 0.880000\n",
      " Iteration: 440 , loss: 1.779868 Accuracy: 0.908000\n",
      " Iteration: 450 , loss: 1.751675 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.7 and the number of correct results is: 56\n",
      " Iteration: 460 , loss: 1.780397 Accuracy: 0.888000\n",
      " Iteration: 470 , loss: 1.790185 Accuracy: 0.880000\n",
      " Iteration: 480 , loss: 1.780428 Accuracy: 0.904000\n",
      " Iteration: 490 , loss: 1.769389 Accuracy: 0.916000\n",
      " Iteration: 500 , loss: 1.762200 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.6875 and the number of correct results is: 55\n",
      " Iteration: 510 , loss: 1.773781 Accuracy: 0.904000\n",
      " Iteration: 520 , loss: 1.763687 Accuracy: 0.904000\n",
      " Iteration: 530 , loss: 1.765841 Accuracy: 0.912000\n",
      " Iteration: 540 , loss: 1.771842 Accuracy: 0.896000\n",
      " Iteration: 550 , loss: 1.767014 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.7 and the number of correct results is: 56\n",
      " Iteration: 560 , loss: 1.777911 Accuracy: 0.880000\n",
      " Iteration: 570 , loss: 1.762595 Accuracy: 0.912000\n",
      " Iteration: 580 , loss: 1.741387 Accuracy: 0.924000\n",
      " Iteration: 590 , loss: 1.768308 Accuracy: 0.904000\n",
      " Iteration: 600 , loss: 1.742556 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.675 and the number of correct results is: 54\n",
      " Iteration: 610 , loss: 1.739377 Accuracy: 0.948000\n",
      " Iteration: 620 , loss: 1.753263 Accuracy: 0.920000\n",
      " Iteration: 630 , loss: 1.741570 Accuracy: 0.904000\n",
      " Iteration: 640 , loss: 1.748506 Accuracy: 0.908000\n",
      " Iteration: 650 , loss: 1.727335 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.6875 and the number of correct results is: 55\n",
      " Iteration: 660 , loss: 1.745678 Accuracy: 0.908000\n",
      " Iteration: 670 , loss: 1.732642 Accuracy: 0.940000\n",
      " Iteration: 680 , loss: 1.715021 Accuracy: 0.936000\n",
      " Iteration: 690 , loss: 1.738250 Accuracy: 0.928000\n",
      " Iteration: 700 , loss: 1.707485 Accuracy: 0.968000\n",
      "The postprocessing average accuracy is: 0.65 and the number of correct results is: 52\n",
      " Iteration: 710 , loss: 1.703070 Accuracy: 0.968000\n",
      " Iteration: 720 , loss: 1.733939 Accuracy: 0.924000\n",
      " Iteration: 730 , loss: 1.709222 Accuracy: 0.940000\n",
      " Iteration: 740 , loss: 1.741509 Accuracy: 0.916000\n",
      " Iteration: 750 , loss: 1.711864 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.7125 and the number of correct results is: 57\n",
      " Iteration: 760 , loss: 1.721793 Accuracy: 0.944000\n",
      " Iteration: 770 , loss: 1.718530 Accuracy: 0.940000\n",
      " Iteration: 780 , loss: 1.712545 Accuracy: 0.944000\n",
      " Iteration: 790 , loss: 1.715047 Accuracy: 0.952000\n",
      " Iteration: 800 , loss: 1.706262 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.6875 and the number of correct results is: 55\n",
      "\n",
      "Optimization of Split 2 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 3 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.494734 Accuracy: 0.076000\n",
      "The postprocessing average accuracy is: 0.09782608695652174 and the number of correct results is: 9\n",
      " Iteration: 10 , loss: 2.382261 Accuracy: 0.292000\n",
      " Iteration: 20 , loss: 2.314540 Accuracy: 0.400000\n",
      " Iteration: 30 , loss: 2.258565 Accuracy: 0.500000\n",
      " Iteration: 40 , loss: 2.211522 Accuracy: 0.560000\n",
      " Iteration: 50 , loss: 2.197742 Accuracy: 0.564000\n",
      "The postprocessing average accuracy is: 0.5760869565217391 and the number of correct results is: 53\n",
      " Iteration: 60 , loss: 2.158617 Accuracy: 0.560000\n",
      " Iteration: 70 , loss: 2.122941 Accuracy: 0.604000\n",
      " Iteration: 80 , loss: 2.105032 Accuracy: 0.672000\n",
      " Iteration: 90 , loss: 2.087027 Accuracy: 0.632000\n",
      " Iteration: 100 , loss: 2.070312 Accuracy: 0.644000\n",
      "The postprocessing average accuracy is: 0.6304347826086957 and the number of correct results is: 58\n",
      " Iteration: 110 , loss: 2.015507 Accuracy: 0.704000\n",
      " Iteration: 120 , loss: 2.013459 Accuracy: 0.716000\n",
      " Iteration: 130 , loss: 1.993448 Accuracy: 0.720000\n",
      " Iteration: 140 , loss: 1.976589 Accuracy: 0.740000\n",
      " Iteration: 150 , loss: 2.013098 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.6413043478260869 and the number of correct results is: 59\n",
      " Iteration: 160 , loss: 1.968496 Accuracy: 0.784000\n",
      " Iteration: 170 , loss: 1.964869 Accuracy: 0.728000\n",
      " Iteration: 180 , loss: 1.953783 Accuracy: 0.752000\n",
      " Iteration: 190 , loss: 1.944095 Accuracy: 0.784000\n",
      " Iteration: 200 , loss: 1.889304 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.6086956521739131 and the number of correct results is: 56\n",
      " Iteration: 210 , loss: 1.924056 Accuracy: 0.804000\n",
      " Iteration: 220 , loss: 1.890115 Accuracy: 0.796000\n",
      " Iteration: 230 , loss: 1.871909 Accuracy: 0.832000\n",
      " Iteration: 240 , loss: 1.879098 Accuracy: 0.824000\n",
      " Iteration: 250 , loss: 1.848155 Accuracy: 0.848000\n",
      "The postprocessing average accuracy is: 0.6304347826086957 and the number of correct results is: 58\n",
      " Iteration: 260 , loss: 1.862491 Accuracy: 0.824000\n",
      " Iteration: 270 , loss: 1.895020 Accuracy: 0.804000\n",
      " Iteration: 280 , loss: 1.833205 Accuracy: 0.872000\n",
      " Iteration: 290 , loss: 1.846245 Accuracy: 0.840000\n",
      " Iteration: 300 , loss: 1.813166 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.6195652173913043 and the number of correct results is: 57\n",
      " Iteration: 310 , loss: 1.866616 Accuracy: 0.824000\n",
      " Iteration: 320 , loss: 1.797015 Accuracy: 0.908000\n",
      " Iteration: 330 , loss: 1.783396 Accuracy: 0.924000\n",
      " Iteration: 340 , loss: 1.823978 Accuracy: 0.868000\n",
      " Iteration: 350 , loss: 1.822412 Accuracy: 0.864000\n",
      "The postprocessing average accuracy is: 0.6195652173913043 and the number of correct results is: 57\n",
      " Iteration: 360 , loss: 1.835554 Accuracy: 0.836000\n",
      " Iteration: 370 , loss: 1.797376 Accuracy: 0.900000\n",
      " Iteration: 380 , loss: 1.820558 Accuracy: 0.856000\n",
      " Iteration: 390 , loss: 1.795057 Accuracy: 0.888000\n",
      " Iteration: 400 , loss: 1.774067 Accuracy: 0.904000\n",
      "The postprocessing average accuracy is: 0.5978260869565217 and the number of correct results is: 55\n",
      " Iteration: 410 , loss: 1.785936 Accuracy: 0.892000\n",
      " Iteration: 420 , loss: 1.767940 Accuracy: 0.908000\n",
      " Iteration: 430 , loss: 1.770115 Accuracy: 0.912000\n",
      " Iteration: 440 , loss: 1.795424 Accuracy: 0.888000\n",
      " Iteration: 450 , loss: 1.770313 Accuracy: 0.900000\n",
      "The postprocessing average accuracy is: 0.5978260869565217 and the number of correct results is: 55\n",
      " Iteration: 460 , loss: 1.730365 Accuracy: 0.956000\n",
      " Iteration: 470 , loss: 1.756261 Accuracy: 0.912000\n",
      " Iteration: 480 , loss: 1.745700 Accuracy: 0.924000\n",
      " Iteration: 490 , loss: 1.764512 Accuracy: 0.904000\n",
      " Iteration: 500 , loss: 1.780978 Accuracy: 0.892000\n",
      "The postprocessing average accuracy is: 0.6086956521739131 and the number of correct results is: 56\n",
      " Iteration: 510 , loss: 1.752817 Accuracy: 0.928000\n",
      " Iteration: 520 , loss: 1.735580 Accuracy: 0.932000\n",
      " Iteration: 530 , loss: 1.744282 Accuracy: 0.920000\n",
      " Iteration: 540 , loss: 1.761388 Accuracy: 0.904000\n",
      " Iteration: 550 , loss: 1.748833 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.6086956521739131 and the number of correct results is: 56\n",
      " Iteration: 560 , loss: 1.770447 Accuracy: 0.900000\n",
      " Iteration: 570 , loss: 1.724697 Accuracy: 0.944000\n",
      " Iteration: 580 , loss: 1.725373 Accuracy: 0.940000\n",
      " Iteration: 590 , loss: 1.743608 Accuracy: 0.916000\n",
      " Iteration: 600 , loss: 1.721720 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.6086956521739131 and the number of correct results is: 56\n",
      " Iteration: 610 , loss: 1.724733 Accuracy: 0.932000\n",
      " Iteration: 620 , loss: 1.745564 Accuracy: 0.920000\n",
      " Iteration: 630 , loss: 1.710632 Accuracy: 0.952000\n",
      " Iteration: 640 , loss: 1.723872 Accuracy: 0.944000\n",
      " Iteration: 650 , loss: 1.721926 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.6304347826086957 and the number of correct results is: 58\n",
      " Iteration: 660 , loss: 1.756557 Accuracy: 0.920000\n",
      " Iteration: 670 , loss: 1.724992 Accuracy: 0.944000\n",
      " Iteration: 680 , loss: 1.701403 Accuracy: 0.964000\n",
      " Iteration: 690 , loss: 1.736451 Accuracy: 0.924000\n",
      " Iteration: 700 , loss: 1.707898 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.6195652173913043 and the number of correct results is: 57\n",
      " Iteration: 710 , loss: 1.707728 Accuracy: 0.960000\n",
      " Iteration: 720 , loss: 1.712817 Accuracy: 0.952000\n",
      " Iteration: 730 , loss: 1.737967 Accuracy: 0.928000\n",
      " Iteration: 740 , loss: 1.701257 Accuracy: 0.952000\n",
      " Iteration: 750 , loss: 1.713941 Accuracy: 0.948000\n",
      "The postprocessing average accuracy is: 0.6195652173913043 and the number of correct results is: 57\n",
      " Iteration: 760 , loss: 1.702776 Accuracy: 0.956000\n",
      " Iteration: 770 , loss: 1.699360 Accuracy: 0.964000\n",
      " Iteration: 780 , loss: 1.687660 Accuracy: 0.972000\n",
      " Iteration: 790 , loss: 1.694834 Accuracy: 0.968000\n",
      " Iteration: 800 , loss: 1.702312 Accuracy: 0.964000\n",
      "The postprocessing average accuracy is: 0.6086956521739131 and the number of correct results is: 56\n",
      "\n",
      "Optimization of Split 3 Finished\n",
      "\n",
      "\n",
      "The number of sequences found in split 1 are: 268\n",
      "The number of sequences found in split 2 are: 270\n",
      "The number of sequences found in split 3 are: 265\n",
      "The number of iterations for in this split is: 2271.2\n",
      "Starting training of Jhmdb \n",
      "\n",
      "loaded data 2 well\n",
      "shape of the data 30 number of labels 21 size of train data ( 22712 22712 ) \n",
      "\n",
      "\n",
      "layer 1 operation results\n",
      "h_conv is: Tensor(\"Relu:0\", shape=(?, 1, 256), dtype=float32)\n",
      "h_conv_ to FCN is: Tensor(\"Reshape_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 2 operation results\n",
      "h_fc1 is: Tensor(\"Relu_1:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc1_drop is: Tensor(\"dropout/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 3 operation results\n",
      "h_fc2 is: Tensor(\"Relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc2_drop is: Tensor(\"dropout_1/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 4 operation results\n",
      "h_fc3 is: Tensor(\"add_3:0\", shape=(?, 21), dtype=float32)\n",
      "y_conv is: Tensor(\"add_4:0\", shape=(?, 21), dtype=float32)\n",
      "\n",
      " Optimization of Split 1 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 3.047814 Accuracy: 0.048000\n",
      "The postprocessing average accuracy is: 0.055970149253731345 and the number of correct results is: 15\n",
      " Iteration: 10 , loss: 3.002379 Accuracy: 0.148000\n",
      " Iteration: 20 , loss: 2.961239 Accuracy: 0.276000\n",
      " Iteration: 30 , loss: 2.929139 Accuracy: 0.340000\n",
      " Iteration: 40 , loss: 2.907206 Accuracy: 0.356000\n",
      " Iteration: 50 , loss: 2.856676 Accuracy: 0.408000\n",
      "The postprocessing average accuracy is: 0.44402985074626866 and the number of correct results is: 119\n",
      " Iteration: 60 , loss: 2.901923 Accuracy: 0.300000\n",
      " Iteration: 70 , loss: 2.824804 Accuracy: 0.468000\n",
      " Iteration: 80 , loss: 2.842939 Accuracy: 0.404000\n",
      " Iteration: 90 , loss: 2.780155 Accuracy: 0.492000\n",
      " Iteration: 100 , loss: 2.795997 Accuracy: 0.484000\n",
      "The postprocessing average accuracy is: 0.5074626865671642 and the number of correct results is: 136\n",
      " Iteration: 110 , loss: 2.766956 Accuracy: 0.476000\n",
      " Iteration: 120 , loss: 2.745007 Accuracy: 0.508000\n",
      " Iteration: 130 , loss: 2.727458 Accuracy: 0.556000\n",
      " Iteration: 140 , loss: 2.708286 Accuracy: 0.520000\n",
      " Iteration: 150 , loss: 2.727925 Accuracy: 0.492000\n",
      "The postprocessing average accuracy is: 0.5447761194029851 and the number of correct results is: 146\n",
      " Iteration: 160 , loss: 2.711675 Accuracy: 0.520000\n",
      " Iteration: 170 , loss: 2.692127 Accuracy: 0.576000\n",
      " Iteration: 180 , loss: 2.698277 Accuracy: 0.556000\n",
      " Iteration: 190 , loss: 2.630696 Accuracy: 0.660000\n",
      " Iteration: 200 , loss: 2.669203 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.5932835820895522 and the number of correct results is: 159\n",
      " Iteration: 210 , loss: 2.628220 Accuracy: 0.600000\n",
      " Iteration: 220 , loss: 2.659752 Accuracy: 0.588000\n",
      " Iteration: 230 , loss: 2.635168 Accuracy: 0.600000\n",
      " Iteration: 240 , loss: 2.610620 Accuracy: 0.624000\n",
      " Iteration: 250 , loss: 2.586145 Accuracy: 0.644000\n",
      "The postprocessing average accuracy is: 0.6194029850746269 and the number of correct results is: 166\n",
      " Iteration: 260 , loss: 2.602087 Accuracy: 0.652000\n",
      " Iteration: 270 , loss: 2.575938 Accuracy: 0.684000\n",
      " Iteration: 280 , loss: 2.594553 Accuracy: 0.632000\n",
      " Iteration: 290 , loss: 2.568287 Accuracy: 0.672000\n",
      " Iteration: 300 , loss: 2.580921 Accuracy: 0.644000\n",
      "The postprocessing average accuracy is: 0.5559701492537313 and the number of correct results is: 149\n",
      " Iteration: 310 , loss: 2.607801 Accuracy: 0.648000\n",
      " Iteration: 320 , loss: 2.558216 Accuracy: 0.688000\n",
      " Iteration: 330 , loss: 2.584474 Accuracy: 0.644000\n",
      " Iteration: 340 , loss: 2.559633 Accuracy: 0.672000\n",
      " Iteration: 350 , loss: 2.510193 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.5895522388059702 and the number of correct results is: 158\n",
      " Iteration: 360 , loss: 2.565883 Accuracy: 0.696000\n",
      " Iteration: 370 , loss: 2.535708 Accuracy: 0.720000\n",
      " Iteration: 380 , loss: 2.559524 Accuracy: 0.692000\n",
      " Iteration: 390 , loss: 2.509557 Accuracy: 0.732000\n",
      " Iteration: 400 , loss: 2.495395 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.5671641791044776 and the number of correct results is: 152\n",
      " Iteration: 410 , loss: 2.516545 Accuracy: 0.740000\n",
      " Iteration: 420 , loss: 2.504526 Accuracy: 0.776000\n",
      " Iteration: 430 , loss: 2.517840 Accuracy: 0.720000\n",
      " Iteration: 440 , loss: 2.548719 Accuracy: 0.664000\n",
      " Iteration: 450 , loss: 2.497278 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.6044776119402985 and the number of correct results is: 162\n",
      " Iteration: 460 , loss: 2.518867 Accuracy: 0.732000\n",
      " Iteration: 470 , loss: 2.478506 Accuracy: 0.760000\n",
      " Iteration: 480 , loss: 2.465256 Accuracy: 0.732000\n",
      " Iteration: 490 , loss: 2.487596 Accuracy: 0.712000\n",
      " Iteration: 500 , loss: 2.493320 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.6156716417910447 and the number of correct results is: 165\n",
      " Iteration: 510 , loss: 2.497831 Accuracy: 0.756000\n",
      " Iteration: 520 , loss: 2.484698 Accuracy: 0.764000\n",
      " Iteration: 530 , loss: 2.468153 Accuracy: 0.760000\n",
      " Iteration: 540 , loss: 2.461226 Accuracy: 0.788000\n",
      " Iteration: 550 , loss: 2.472372 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.6119402985074627 and the number of correct results is: 164\n",
      " Iteration: 560 , loss: 2.458214 Accuracy: 0.788000\n",
      " Iteration: 570 , loss: 2.430878 Accuracy: 0.816000\n",
      " Iteration: 580 , loss: 2.493987 Accuracy: 0.724000\n",
      " Iteration: 590 , loss: 2.454546 Accuracy: 0.748000\n",
      " Iteration: 600 , loss: 2.436876 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.5932835820895522 and the number of correct results is: 159\n",
      " Iteration: 610 , loss: 2.484460 Accuracy: 0.736000\n",
      " Iteration: 620 , loss: 2.471534 Accuracy: 0.708000\n",
      " Iteration: 630 , loss: 2.441145 Accuracy: 0.784000\n",
      " Iteration: 640 , loss: 2.402025 Accuracy: 0.808000\n",
      " Iteration: 650 , loss: 2.451783 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.6231343283582089 and the number of correct results is: 167\n",
      " Iteration: 660 , loss: 2.431517 Accuracy: 0.784000\n",
      " Iteration: 670 , loss: 2.414980 Accuracy: 0.792000\n",
      " Iteration: 680 , loss: 2.382578 Accuracy: 0.816000\n",
      " Iteration: 690 , loss: 2.422085 Accuracy: 0.788000\n",
      " Iteration: 700 , loss: 2.461927 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.6231343283582089 and the number of correct results is: 167\n",
      " Iteration: 710 , loss: 2.425959 Accuracy: 0.796000\n",
      " Iteration: 720 , loss: 2.401652 Accuracy: 0.820000\n",
      " Iteration: 730 , loss: 2.393087 Accuracy: 0.828000\n",
      " Iteration: 740 , loss: 2.413599 Accuracy: 0.816000\n",
      " Iteration: 750 , loss: 2.453953 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.6380597014925373 and the number of correct results is: 171\n",
      " Iteration: 760 , loss: 2.402391 Accuracy: 0.828000\n",
      " Iteration: 770 , loss: 2.409311 Accuracy: 0.808000\n",
      " Iteration: 780 , loss: 2.413919 Accuracy: 0.788000\n",
      " Iteration: 790 , loss: 2.418079 Accuracy: 0.792000\n",
      " Iteration: 800 , loss: 2.394367 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.6194029850746269 and the number of correct results is: 166\n",
      " Iteration: 810 , loss: 2.385233 Accuracy: 0.824000\n",
      " Iteration: 820 , loss: 2.415393 Accuracy: 0.800000\n",
      " Iteration: 830 , loss: 2.419613 Accuracy: 0.800000\n",
      " Iteration: 840 , loss: 2.381994 Accuracy: 0.812000\n",
      " Iteration: 850 , loss: 2.337782 Accuracy: 0.868000\n",
      "The postprocessing average accuracy is: 0.6231343283582089 and the number of correct results is: 167\n",
      " Iteration: 860 , loss: 2.405925 Accuracy: 0.816000\n",
      " Iteration: 870 , loss: 2.401079 Accuracy: 0.816000\n",
      " Iteration: 880 , loss: 2.374540 Accuracy: 0.844000\n",
      " Iteration: 890 , loss: 2.392471 Accuracy: 0.824000\n",
      " Iteration: 900 , loss: 2.369689 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.6231343283582089 and the number of correct results is: 167\n",
      " Iteration: 910 , loss: 2.369453 Accuracy: 0.824000\n",
      " Iteration: 920 , loss: 2.374051 Accuracy: 0.844000\n",
      " Iteration: 930 , loss: 2.341950 Accuracy: 0.880000\n",
      " Iteration: 940 , loss: 2.354968 Accuracy: 0.864000\n",
      " Iteration: 950 , loss: 2.372203 Accuracy: 0.820000\n",
      "The postprocessing average accuracy is: 0.5783582089552238 and the number of correct results is: 155\n",
      " Iteration: 960 , loss: 2.386313 Accuracy: 0.820000\n",
      " Iteration: 970 , loss: 2.372247 Accuracy: 0.848000\n",
      " Iteration: 980 , loss: 2.353214 Accuracy: 0.844000\n",
      " Iteration: 990 , loss: 2.348800 Accuracy: 0.860000\n",
      " Iteration: 1000 , loss: 2.368253 Accuracy: 0.856000\n",
      "The postprocessing average accuracy is: 0.6082089552238806 and the number of correct results is: 163\n",
      " Iteration: 1010 , loss: 2.341821 Accuracy: 0.868000\n",
      " Iteration: 1020 , loss: 2.348017 Accuracy: 0.860000\n",
      " Iteration: 1030 , loss: 2.351767 Accuracy: 0.848000\n",
      " Iteration: 1040 , loss: 2.361783 Accuracy: 0.848000\n",
      " Iteration: 1050 , loss: 2.355817 Accuracy: 0.860000\n",
      "The postprocessing average accuracy is: 0.6231343283582089 and the number of correct results is: 167\n",
      " Iteration: 1060 , loss: 2.358210 Accuracy: 0.864000\n",
      " Iteration: 1070 , loss: 2.347376 Accuracy: 0.844000\n",
      " Iteration: 1080 , loss: 2.376966 Accuracy: 0.872000\n",
      " Iteration: 1090 , loss: 2.364259 Accuracy: 0.816000\n",
      " Iteration: 1100 , loss: 2.314429 Accuracy: 0.864000\n",
      "The postprocessing average accuracy is: 0.6044776119402985 and the number of correct results is: 162\n",
      " Iteration: 1110 , loss: 2.329182 Accuracy: 0.880000\n",
      " Iteration: 1120 , loss: 2.376009 Accuracy: 0.812000\n",
      " Iteration: 1130 , loss: 2.322814 Accuracy: 0.872000\n",
      " Iteration: 1140 , loss: 2.326190 Accuracy: 0.888000\n",
      " Iteration: 1150 , loss: 2.400440 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.6156716417910447 and the number of correct results is: 165\n",
      " Iteration: 1160 , loss: 2.316068 Accuracy: 0.900000\n",
      " Iteration: 1170 , loss: 2.366967 Accuracy: 0.856000\n",
      " Iteration: 1180 , loss: 2.360595 Accuracy: 0.828000\n",
      " Iteration: 1190 , loss: 2.352624 Accuracy: 0.844000\n",
      " Iteration: 1200 , loss: 2.342649 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.6119402985074627 and the number of correct results is: 164\n",
      " Iteration: 1210 , loss: 2.320069 Accuracy: 0.884000\n",
      " Iteration: 1220 , loss: 2.337882 Accuracy: 0.868000\n",
      " Iteration: 1230 , loss: 2.329477 Accuracy: 0.860000\n",
      " Iteration: 1240 , loss: 2.372317 Accuracy: 0.828000\n",
      " Iteration: 1250 , loss: 2.336461 Accuracy: 0.848000\n",
      "The postprocessing average accuracy is: 0.6044776119402985 and the number of correct results is: 162\n",
      " Iteration: 1260 , loss: 2.331470 Accuracy: 0.868000\n",
      " Iteration: 1270 , loss: 2.339337 Accuracy: 0.848000\n",
      " Iteration: 1280 , loss: 2.333974 Accuracy: 0.856000\n",
      " Iteration: 1290 , loss: 2.319774 Accuracy: 0.872000\n",
      " Iteration: 1300 , loss: 2.322998 Accuracy: 0.876000\n",
      "The postprocessing average accuracy is: 0.6044776119402985 and the number of correct results is: 162\n",
      " Iteration: 1310 , loss: 2.337749 Accuracy: 0.856000\n",
      " Iteration: 1320 , loss: 2.344970 Accuracy: 0.836000\n",
      " Iteration: 1330 , loss: 2.342757 Accuracy: 0.872000\n",
      " Iteration: 1340 , loss: 2.289442 Accuracy: 0.896000\n",
      " Iteration: 1350 , loss: 2.317122 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.5970149253731343 and the number of correct results is: 160\n",
      " Iteration: 1360 , loss: 2.279255 Accuracy: 0.912000\n",
      " Iteration: 1370 , loss: 2.347558 Accuracy: 0.840000\n",
      " Iteration: 1380 , loss: 2.330197 Accuracy: 0.856000\n",
      " Iteration: 1390 , loss: 2.300697 Accuracy: 0.888000\n",
      " Iteration: 1400 , loss: 2.312674 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.5895522388059702 and the number of correct results is: 158\n",
      " Iteration: 1410 , loss: 2.300334 Accuracy: 0.900000\n",
      " Iteration: 1420 , loss: 2.326218 Accuracy: 0.864000\n",
      " Iteration: 1430 , loss: 2.316602 Accuracy: 0.884000\n",
      " Iteration: 1440 , loss: 2.312585 Accuracy: 0.856000\n",
      " Iteration: 1450 , loss: 2.317453 Accuracy: 0.876000\n",
      "The postprocessing average accuracy is: 0.5895522388059702 and the number of correct results is: 158\n",
      " Iteration: 1460 , loss: 2.310873 Accuracy: 0.884000\n",
      " Iteration: 1470 , loss: 2.348160 Accuracy: 0.828000\n",
      " Iteration: 1480 , loss: 2.274696 Accuracy: 0.908000\n",
      " Iteration: 1490 , loss: 2.281395 Accuracy: 0.896000\n",
      " Iteration: 1500 , loss: 2.289468 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.5970149253731343 and the number of correct results is: 160\n",
      " Iteration: 1510 , loss: 2.309671 Accuracy: 0.876000\n",
      " Iteration: 1520 , loss: 2.300195 Accuracy: 0.876000\n",
      " Iteration: 1530 , loss: 2.304127 Accuracy: 0.892000\n",
      " Iteration: 1540 , loss: 2.288424 Accuracy: 0.900000\n",
      " Iteration: 1550 , loss: 2.315622 Accuracy: 0.892000\n",
      "The postprocessing average accuracy is: 0.6007462686567164 and the number of correct results is: 161\n",
      " Iteration: 1560 , loss: 2.283966 Accuracy: 0.928000\n",
      " Iteration: 1570 , loss: 2.286415 Accuracy: 0.880000\n",
      " Iteration: 1580 , loss: 2.289919 Accuracy: 0.896000\n",
      " Iteration: 1590 , loss: 2.325511 Accuracy: 0.872000\n",
      " Iteration: 1600 , loss: 2.284277 Accuracy: 0.884000\n",
      "The postprocessing average accuracy is: 0.6194029850746269 and the number of correct results is: 166\n",
      " Iteration: 1610 , loss: 2.319162 Accuracy: 0.864000\n",
      " Iteration: 1620 , loss: 2.292194 Accuracy: 0.892000\n",
      " Iteration: 1630 , loss: 2.300872 Accuracy: 0.892000\n",
      " Iteration: 1640 , loss: 2.277486 Accuracy: 0.904000\n",
      " Iteration: 1650 , loss: 2.275026 Accuracy: 0.912000\n",
      "The postprocessing average accuracy is: 0.582089552238806 and the number of correct results is: 156\n",
      " Iteration: 1660 , loss: 2.321081 Accuracy: 0.864000\n",
      " Iteration: 1670 , loss: 2.294155 Accuracy: 0.908000\n",
      " Iteration: 1680 , loss: 2.327927 Accuracy: 0.876000\n",
      " Iteration: 1690 , loss: 2.281431 Accuracy: 0.884000\n",
      " Iteration: 1700 , loss: 2.326651 Accuracy: 0.860000\n",
      "The postprocessing average accuracy is: 0.6417910447761194 and the number of correct results is: 172\n",
      " Iteration: 1710 , loss: 2.295503 Accuracy: 0.884000\n",
      " Iteration: 1720 , loss: 2.281836 Accuracy: 0.904000\n",
      " Iteration: 1730 , loss: 2.288061 Accuracy: 0.868000\n",
      " Iteration: 1740 , loss: 2.309567 Accuracy: 0.876000\n",
      " Iteration: 1750 , loss: 2.293209 Accuracy: 0.880000\n",
      "The postprocessing average accuracy is: 0.6156716417910447 and the number of correct results is: 165\n",
      " Iteration: 1760 , loss: 2.261015 Accuracy: 0.932000\n",
      " Iteration: 1770 , loss: 2.279713 Accuracy: 0.908000\n",
      " Iteration: 1780 , loss: 2.261938 Accuracy: 0.928000\n",
      " Iteration: 1790 , loss: 2.297481 Accuracy: 0.888000\n",
      " Iteration: 1800 , loss: 2.293814 Accuracy: 0.880000\n",
      "The postprocessing average accuracy is: 0.6268656716417911 and the number of correct results is: 168\n",
      " Iteration: 1810 , loss: 2.283591 Accuracy: 0.880000\n",
      " Iteration: 1820 , loss: 2.280527 Accuracy: 0.876000\n",
      " Iteration: 1830 , loss: 2.297525 Accuracy: 0.888000\n",
      " Iteration: 1840 , loss: 2.271950 Accuracy: 0.880000\n",
      " Iteration: 1850 , loss: 2.258098 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.6231343283582089 and the number of correct results is: 167\n",
      " Iteration: 1860 , loss: 2.302838 Accuracy: 0.884000\n",
      " Iteration: 1870 , loss: 2.283437 Accuracy: 0.876000\n",
      " Iteration: 1880 , loss: 2.279542 Accuracy: 0.896000\n",
      " Iteration: 1890 , loss: 2.268169 Accuracy: 0.896000\n",
      " Iteration: 1900 , loss: 2.266685 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.6194029850746269 and the number of correct results is: 166\n",
      " Iteration: 1910 , loss: 2.279563 Accuracy: 0.892000\n",
      " Iteration: 1920 , loss: 2.275317 Accuracy: 0.920000\n",
      " Iteration: 1930 , loss: 2.266583 Accuracy: 0.920000\n",
      " Iteration: 1940 , loss: 2.250531 Accuracy: 0.908000\n",
      " Iteration: 1950 , loss: 2.254476 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.6007462686567164 and the number of correct results is: 161\n",
      " Iteration: 1960 , loss: 2.270872 Accuracy: 0.912000\n",
      " Iteration: 1970 , loss: 2.234662 Accuracy: 0.952000\n",
      " Iteration: 1980 , loss: 2.283937 Accuracy: 0.876000\n",
      " Iteration: 1990 , loss: 2.267121 Accuracy: 0.908000\n",
      " Iteration: 2000 , loss: 2.258528 Accuracy: 0.928000\n",
      "The postprocessing average accuracy is: 0.6044776119402985 and the number of correct results is: 162\n",
      " Iteration: 2010 , loss: 2.272698 Accuracy: 0.920000\n",
      " Iteration: 2020 , loss: 2.260320 Accuracy: 0.896000\n",
      " Iteration: 2030 , loss: 2.242826 Accuracy: 0.936000\n",
      " Iteration: 2040 , loss: 2.243154 Accuracy: 0.940000\n",
      " Iteration: 2050 , loss: 2.258020 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.5634328358208955 and the number of correct results is: 151\n",
      " Iteration: 2060 , loss: 2.270359 Accuracy: 0.904000\n",
      " Iteration: 2070 , loss: 2.250534 Accuracy: 0.920000\n",
      " Iteration: 2080 , loss: 2.261766 Accuracy: 0.928000\n",
      " Iteration: 2090 , loss: 2.268535 Accuracy: 0.920000\n",
      " Iteration: 2100 , loss: 2.243623 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.5671641791044776 and the number of correct results is: 152\n",
      " Iteration: 2110 , loss: 2.250370 Accuracy: 0.908000\n",
      " Iteration: 2120 , loss: 2.256326 Accuracy: 0.920000\n",
      " Iteration: 2130 , loss: 2.268014 Accuracy: 0.904000\n",
      " Iteration: 2140 , loss: 2.272674 Accuracy: 0.896000\n",
      " Iteration: 2150 , loss: 2.293684 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.6194029850746269 and the number of correct results is: 166\n",
      " Iteration: 2160 , loss: 2.250325 Accuracy: 0.924000\n",
      " Iteration: 2170 , loss: 2.267523 Accuracy: 0.920000\n",
      " Iteration: 2180 , loss: 2.284686 Accuracy: 0.872000\n",
      " Iteration: 2190 , loss: 2.263457 Accuracy: 0.900000\n",
      " Iteration: 2200 , loss: 2.219864 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.585820895522388 and the number of correct results is: 157\n",
      " Iteration: 2210 , loss: 2.255926 Accuracy: 0.908000\n",
      " Iteration: 2220 , loss: 2.237782 Accuracy: 0.944000\n",
      " Iteration: 2230 , loss: 2.242227 Accuracy: 0.924000\n",
      " Iteration: 2240 , loss: 2.274554 Accuracy: 0.888000\n",
      " Iteration: 2250 , loss: 2.248670 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.6044776119402985 and the number of correct results is: 162\n",
      " Iteration: 2260 , loss: 2.247433 Accuracy: 0.928000\n",
      " Iteration: 2270 , loss: 2.255874 Accuracy: 0.892000\n",
      "\n",
      "Optimization of Split 1 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 2 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 3.040203 Accuracy: 0.060000\n",
      "The postprocessing average accuracy is: 0.05925925925925926 and the number of correct results is: 16\n",
      " Iteration: 10 , loss: 2.989432 Accuracy: 0.212000\n",
      " Iteration: 20 , loss: 2.962230 Accuracy: 0.272000\n",
      " Iteration: 30 , loss: 2.929392 Accuracy: 0.364000\n",
      " Iteration: 40 , loss: 2.900258 Accuracy: 0.336000\n",
      " Iteration: 50 , loss: 2.891957 Accuracy: 0.372000\n",
      "The postprocessing average accuracy is: 0.42962962962962964 and the number of correct results is: 116\n",
      " Iteration: 60 , loss: 2.831849 Accuracy: 0.420000\n",
      " Iteration: 70 , loss: 2.802373 Accuracy: 0.460000\n",
      " Iteration: 80 , loss: 2.822789 Accuracy: 0.404000\n",
      " Iteration: 90 , loss: 2.750919 Accuracy: 0.504000\n",
      " Iteration: 100 , loss: 2.754888 Accuracy: 0.476000\n",
      "The postprocessing average accuracy is: 0.5444444444444444 and the number of correct results is: 147\n",
      " Iteration: 110 , loss: 2.713584 Accuracy: 0.544000\n",
      " Iteration: 120 , loss: 2.658204 Accuracy: 0.624000\n",
      " Iteration: 130 , loss: 2.705584 Accuracy: 0.564000\n",
      " Iteration: 140 , loss: 2.689117 Accuracy: 0.568000\n",
      " Iteration: 150 , loss: 2.677705 Accuracy: 0.616000\n",
      "The postprocessing average accuracy is: 0.5259259259259259 and the number of correct results is: 142\n",
      " Iteration: 160 , loss: 2.646340 Accuracy: 0.600000\n",
      " Iteration: 170 , loss: 2.652793 Accuracy: 0.632000\n",
      " Iteration: 180 , loss: 2.672035 Accuracy: 0.576000\n",
      " Iteration: 190 , loss: 2.635170 Accuracy: 0.612000\n",
      " Iteration: 200 , loss: 2.646834 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.5851851851851851 and the number of correct results is: 158\n",
      " Iteration: 210 , loss: 2.664640 Accuracy: 0.592000\n",
      " Iteration: 220 , loss: 2.603770 Accuracy: 0.660000\n",
      " Iteration: 230 , loss: 2.628359 Accuracy: 0.640000\n",
      " Iteration: 240 , loss: 2.596037 Accuracy: 0.684000\n",
      " Iteration: 250 , loss: 2.600615 Accuracy: 0.612000\n",
      "The postprocessing average accuracy is: 0.5740740740740741 and the number of correct results is: 155\n",
      " Iteration: 260 , loss: 2.605295 Accuracy: 0.616000\n",
      " Iteration: 270 , loss: 2.550944 Accuracy: 0.688000\n",
      " Iteration: 280 , loss: 2.600424 Accuracy: 0.624000\n",
      " Iteration: 290 , loss: 2.567206 Accuracy: 0.700000\n",
      " Iteration: 300 , loss: 2.550208 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.5703703703703704 and the number of correct results is: 154\n",
      " Iteration: 310 , loss: 2.593293 Accuracy: 0.600000\n",
      " Iteration: 320 , loss: 2.568035 Accuracy: 0.696000\n",
      " Iteration: 330 , loss: 2.504254 Accuracy: 0.744000\n",
      " Iteration: 340 , loss: 2.527262 Accuracy: 0.720000\n",
      " Iteration: 350 , loss: 2.533655 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.6037037037037037 and the number of correct results is: 163\n",
      " Iteration: 360 , loss: 2.496377 Accuracy: 0.724000\n",
      " Iteration: 370 , loss: 2.530317 Accuracy: 0.716000\n",
      " Iteration: 380 , loss: 2.522357 Accuracy: 0.736000\n",
      " Iteration: 390 , loss: 2.520852 Accuracy: 0.720000\n",
      " Iteration: 400 , loss: 2.524035 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.5962962962962963 and the number of correct results is: 161\n",
      " Iteration: 410 , loss: 2.492085 Accuracy: 0.740000\n",
      " Iteration: 420 , loss: 2.496353 Accuracy: 0.740000\n",
      " Iteration: 430 , loss: 2.499777 Accuracy: 0.748000\n",
      " Iteration: 440 , loss: 2.511334 Accuracy: 0.716000\n",
      " Iteration: 450 , loss: 2.441752 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.5925925925925926 and the number of correct results is: 160\n",
      " Iteration: 460 , loss: 2.471149 Accuracy: 0.744000\n",
      " Iteration: 470 , loss: 2.493192 Accuracy: 0.728000\n",
      " Iteration: 480 , loss: 2.494273 Accuracy: 0.752000\n",
      " Iteration: 490 , loss: 2.491276 Accuracy: 0.716000\n",
      " Iteration: 500 , loss: 2.463848 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.5814814814814815 and the number of correct results is: 157\n",
      " Iteration: 510 , loss: 2.490703 Accuracy: 0.740000\n",
      " Iteration: 520 , loss: 2.431429 Accuracy: 0.804000\n",
      " Iteration: 530 , loss: 2.448272 Accuracy: 0.780000\n",
      " Iteration: 540 , loss: 2.438365 Accuracy: 0.768000\n",
      " Iteration: 550 , loss: 2.458749 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 162\n",
      " Iteration: 560 , loss: 2.451239 Accuracy: 0.768000\n",
      " Iteration: 570 , loss: 2.462238 Accuracy: 0.776000\n",
      " Iteration: 580 , loss: 2.449678 Accuracy: 0.760000\n",
      " Iteration: 590 , loss: 2.449710 Accuracy: 0.788000\n",
      " Iteration: 600 , loss: 2.442818 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.5851851851851851 and the number of correct results is: 158\n",
      " Iteration: 610 , loss: 2.457357 Accuracy: 0.764000\n",
      " Iteration: 620 , loss: 2.450495 Accuracy: 0.760000\n",
      " Iteration: 630 , loss: 2.480629 Accuracy: 0.748000\n",
      " Iteration: 640 , loss: 2.377712 Accuracy: 0.852000\n",
      " Iteration: 650 , loss: 2.390353 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 162\n",
      " Iteration: 660 , loss: 2.435642 Accuracy: 0.772000\n",
      " Iteration: 670 , loss: 2.431864 Accuracy: 0.804000\n",
      " Iteration: 680 , loss: 2.421098 Accuracy: 0.788000\n",
      " Iteration: 690 , loss: 2.427736 Accuracy: 0.800000\n",
      " Iteration: 700 , loss: 2.416381 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.5925925925925926 and the number of correct results is: 160\n",
      " Iteration: 710 , loss: 2.395398 Accuracy: 0.832000\n",
      " Iteration: 720 , loss: 2.417569 Accuracy: 0.788000\n",
      " Iteration: 730 , loss: 2.396297 Accuracy: 0.804000\n",
      " Iteration: 740 , loss: 2.382529 Accuracy: 0.792000\n",
      " Iteration: 750 , loss: 2.399554 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.6148148148148148 and the number of correct results is: 166\n",
      " Iteration: 760 , loss: 2.386415 Accuracy: 0.808000\n",
      " Iteration: 770 , loss: 2.406141 Accuracy: 0.800000\n",
      " Iteration: 780 , loss: 2.394042 Accuracy: 0.824000\n",
      " Iteration: 790 , loss: 2.367760 Accuracy: 0.860000\n",
      " Iteration: 800 , loss: 2.396398 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.6370370370370371 and the number of correct results is: 172\n",
      " Iteration: 810 , loss: 2.374963 Accuracy: 0.816000\n",
      " Iteration: 820 , loss: 2.368286 Accuracy: 0.856000\n",
      " Iteration: 830 , loss: 2.384572 Accuracy: 0.812000\n",
      " Iteration: 840 , loss: 2.377109 Accuracy: 0.812000\n",
      " Iteration: 850 , loss: 2.398170 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.6222222222222222 and the number of correct results is: 168\n",
      " Iteration: 860 , loss: 2.375240 Accuracy: 0.820000\n",
      " Iteration: 870 , loss: 2.400499 Accuracy: 0.832000\n",
      " Iteration: 880 , loss: 2.349107 Accuracy: 0.868000\n",
      " Iteration: 890 , loss: 2.376248 Accuracy: 0.832000\n",
      " Iteration: 900 , loss: 2.371308 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.6111111111111112 and the number of correct results is: 165\n",
      " Iteration: 910 , loss: 2.347219 Accuracy: 0.868000\n",
      " Iteration: 920 , loss: 2.351446 Accuracy: 0.860000\n",
      " Iteration: 930 , loss: 2.381542 Accuracy: 0.824000\n",
      " Iteration: 940 , loss: 2.373618 Accuracy: 0.832000\n",
      " Iteration: 950 , loss: 2.367159 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.6185185185185185 and the number of correct results is: 167\n",
      " Iteration: 960 , loss: 2.355304 Accuracy: 0.852000\n",
      " Iteration: 970 , loss: 2.349488 Accuracy: 0.836000\n",
      " Iteration: 980 , loss: 2.347392 Accuracy: 0.848000\n",
      " Iteration: 990 , loss: 2.364014 Accuracy: 0.848000\n",
      " Iteration: 1000 , loss: 2.332530 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.6074074074074074 and the number of correct results is: 164\n",
      " Iteration: 1010 , loss: 2.346126 Accuracy: 0.840000\n",
      " Iteration: 1020 , loss: 2.337367 Accuracy: 0.864000\n",
      " Iteration: 1030 , loss: 2.370782 Accuracy: 0.832000\n",
      " Iteration: 1040 , loss: 2.365716 Accuracy: 0.848000\n",
      " Iteration: 1050 , loss: 2.343629 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 162\n",
      " Iteration: 1060 , loss: 2.338610 Accuracy: 0.868000\n",
      " Iteration: 1070 , loss: 2.344213 Accuracy: 0.848000\n",
      " Iteration: 1080 , loss: 2.352986 Accuracy: 0.844000\n",
      " Iteration: 1090 , loss: 2.338969 Accuracy: 0.860000\n",
      " Iteration: 1100 , loss: 2.305050 Accuracy: 0.884000\n",
      "The postprocessing average accuracy is: 0.6333333333333333 and the number of correct results is: 171\n",
      " Iteration: 1110 , loss: 2.344240 Accuracy: 0.820000\n",
      " Iteration: 1120 , loss: 2.342899 Accuracy: 0.832000\n",
      " Iteration: 1130 , loss: 2.334814 Accuracy: 0.860000\n",
      " Iteration: 1140 , loss: 2.311674 Accuracy: 0.888000\n",
      " Iteration: 1150 , loss: 2.353899 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.6074074074074074 and the number of correct results is: 164\n",
      " Iteration: 1160 , loss: 2.317035 Accuracy: 0.876000\n",
      " Iteration: 1170 , loss: 2.305489 Accuracy: 0.924000\n",
      " Iteration: 1180 , loss: 2.352414 Accuracy: 0.840000\n",
      " Iteration: 1190 , loss: 2.340911 Accuracy: 0.848000\n",
      " Iteration: 1200 , loss: 2.312265 Accuracy: 0.868000\n",
      "The postprocessing average accuracy is: 0.6074074074074074 and the number of correct results is: 164\n",
      " Iteration: 1210 , loss: 2.313859 Accuracy: 0.864000\n",
      " Iteration: 1220 , loss: 2.319610 Accuracy: 0.868000\n",
      " Iteration: 1230 , loss: 2.330170 Accuracy: 0.840000\n",
      " Iteration: 1240 , loss: 2.316039 Accuracy: 0.888000\n",
      " Iteration: 1250 , loss: 2.297141 Accuracy: 0.900000\n",
      "The postprocessing average accuracy is: 0.6444444444444445 and the number of correct results is: 174\n",
      " Iteration: 1260 , loss: 2.322488 Accuracy: 0.868000\n",
      " Iteration: 1270 , loss: 2.323211 Accuracy: 0.872000\n",
      " Iteration: 1280 , loss: 2.321772 Accuracy: 0.876000\n",
      " Iteration: 1290 , loss: 2.310484 Accuracy: 0.880000\n",
      " Iteration: 1300 , loss: 2.319991 Accuracy: 0.868000\n",
      "The postprocessing average accuracy is: 0.6111111111111112 and the number of correct results is: 165\n",
      " Iteration: 1310 , loss: 2.290356 Accuracy: 0.916000\n",
      " Iteration: 1320 , loss: 2.312061 Accuracy: 0.884000\n",
      " Iteration: 1330 , loss: 2.306415 Accuracy: 0.908000\n",
      " Iteration: 1340 , loss: 2.317541 Accuracy: 0.872000\n",
      " Iteration: 1350 , loss: 2.291272 Accuracy: 0.900000\n",
      "The postprocessing average accuracy is: 0.6148148148148148 and the number of correct results is: 166\n",
      " Iteration: 1360 , loss: 2.298364 Accuracy: 0.880000\n",
      " Iteration: 1370 , loss: 2.305953 Accuracy: 0.896000\n",
      " Iteration: 1380 , loss: 2.312634 Accuracy: 0.880000\n",
      " Iteration: 1390 , loss: 2.306354 Accuracy: 0.860000\n",
      " Iteration: 1400 , loss: 2.319915 Accuracy: 0.864000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 162\n",
      " Iteration: 1410 , loss: 2.318692 Accuracy: 0.852000\n",
      " Iteration: 1420 , loss: 2.293331 Accuracy: 0.904000\n",
      " Iteration: 1430 , loss: 2.302253 Accuracy: 0.860000\n",
      " Iteration: 1440 , loss: 2.312971 Accuracy: 0.872000\n",
      " Iteration: 1450 , loss: 2.327147 Accuracy: 0.860000\n",
      "The postprocessing average accuracy is: 0.6185185185185185 and the number of correct results is: 167\n",
      " Iteration: 1460 , loss: 2.289049 Accuracy: 0.896000\n",
      " Iteration: 1470 , loss: 2.300397 Accuracy: 0.884000\n",
      " Iteration: 1480 , loss: 2.304566 Accuracy: 0.888000\n",
      " Iteration: 1490 , loss: 2.298498 Accuracy: 0.892000\n",
      " Iteration: 1500 , loss: 2.306477 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.6222222222222222 and the number of correct results is: 168\n",
      " Iteration: 1510 , loss: 2.279472 Accuracy: 0.904000\n",
      " Iteration: 1520 , loss: 2.297108 Accuracy: 0.892000\n",
      " Iteration: 1530 , loss: 2.302601 Accuracy: 0.868000\n",
      " Iteration: 1540 , loss: 2.285892 Accuracy: 0.892000\n",
      " Iteration: 1550 , loss: 2.310021 Accuracy: 0.880000\n",
      "The postprocessing average accuracy is: 0.6111111111111112 and the number of correct results is: 165\n",
      " Iteration: 1560 , loss: 2.296872 Accuracy: 0.876000\n",
      " Iteration: 1570 , loss: 2.255023 Accuracy: 0.920000\n",
      " Iteration: 1580 , loss: 2.317642 Accuracy: 0.872000\n",
      " Iteration: 1590 , loss: 2.300608 Accuracy: 0.892000\n",
      " Iteration: 1600 , loss: 2.248183 Accuracy: 0.936000\n",
      "The postprocessing average accuracy is: 0.6185185185185185 and the number of correct results is: 167\n",
      " Iteration: 1610 , loss: 2.292666 Accuracy: 0.884000\n",
      " Iteration: 1620 , loss: 2.260123 Accuracy: 0.896000\n",
      " Iteration: 1630 , loss: 2.264560 Accuracy: 0.920000\n",
      " Iteration: 1640 , loss: 2.238485 Accuracy: 0.924000\n",
      " Iteration: 1650 , loss: 2.277837 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.5962962962962963 and the number of correct results is: 161\n",
      " Iteration: 1660 , loss: 2.268275 Accuracy: 0.904000\n",
      " Iteration: 1670 , loss: 2.304607 Accuracy: 0.876000\n",
      " Iteration: 1680 , loss: 2.302833 Accuracy: 0.852000\n",
      " Iteration: 1690 , loss: 2.281036 Accuracy: 0.884000\n",
      " Iteration: 1700 , loss: 2.286311 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.6259259259259259 and the number of correct results is: 169\n",
      " Iteration: 1710 , loss: 2.264896 Accuracy: 0.916000\n",
      " Iteration: 1720 , loss: 2.273634 Accuracy: 0.896000\n",
      " Iteration: 1730 , loss: 2.311195 Accuracy: 0.868000\n",
      " Iteration: 1740 , loss: 2.258932 Accuracy: 0.920000\n",
      " Iteration: 1750 , loss: 2.236362 Accuracy: 0.920000\n",
      "The postprocessing average accuracy is: 0.6037037037037037 and the number of correct results is: 163\n",
      " Iteration: 1760 , loss: 2.264198 Accuracy: 0.908000\n",
      " Iteration: 1770 , loss: 2.276678 Accuracy: 0.896000\n",
      " Iteration: 1780 , loss: 2.264264 Accuracy: 0.912000\n",
      " Iteration: 1790 , loss: 2.272158 Accuracy: 0.892000\n",
      " Iteration: 1800 , loss: 2.266916 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.6037037037037037 and the number of correct results is: 163\n",
      " Iteration: 1810 , loss: 2.261609 Accuracy: 0.932000\n",
      " Iteration: 1820 , loss: 2.297139 Accuracy: 0.896000\n",
      " Iteration: 1830 , loss: 2.241183 Accuracy: 0.916000\n",
      " Iteration: 1840 , loss: 2.260399 Accuracy: 0.896000\n",
      " Iteration: 1850 , loss: 2.281264 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.6074074074074074 and the number of correct results is: 164\n",
      " Iteration: 1860 , loss: 2.263584 Accuracy: 0.928000\n",
      " Iteration: 1870 , loss: 2.259446 Accuracy: 0.936000\n",
      " Iteration: 1880 , loss: 2.280109 Accuracy: 0.900000\n",
      " Iteration: 1890 , loss: 2.294988 Accuracy: 0.868000\n",
      " Iteration: 1900 , loss: 2.237056 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 162\n",
      " Iteration: 1910 , loss: 2.289001 Accuracy: 0.892000\n",
      " Iteration: 1920 , loss: 2.282329 Accuracy: 0.900000\n",
      " Iteration: 1930 , loss: 2.244843 Accuracy: 0.912000\n",
      " Iteration: 1940 , loss: 2.261366 Accuracy: 0.908000\n",
      " Iteration: 1950 , loss: 2.277301 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 162\n",
      " Iteration: 1960 , loss: 2.248919 Accuracy: 0.932000\n",
      " Iteration: 1970 , loss: 2.272905 Accuracy: 0.904000\n",
      " Iteration: 1980 , loss: 2.260520 Accuracy: 0.908000\n",
      " Iteration: 1990 , loss: 2.248699 Accuracy: 0.916000\n",
      " Iteration: 2000 , loss: 2.256644 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.5888888888888889 and the number of correct results is: 159\n",
      " Iteration: 2010 , loss: 2.249508 Accuracy: 0.928000\n",
      " Iteration: 2020 , loss: 2.242116 Accuracy: 0.932000\n",
      " Iteration: 2030 , loss: 2.254403 Accuracy: 0.916000\n",
      " Iteration: 2040 , loss: 2.271484 Accuracy: 0.908000\n",
      " Iteration: 2050 , loss: 2.258144 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.6185185185185185 and the number of correct results is: 167\n",
      " Iteration: 2060 , loss: 2.258970 Accuracy: 0.916000\n",
      " Iteration: 2070 , loss: 2.244052 Accuracy: 0.936000\n",
      " Iteration: 2080 , loss: 2.229610 Accuracy: 0.940000\n",
      " Iteration: 2090 , loss: 2.264916 Accuracy: 0.884000\n",
      " Iteration: 2100 , loss: 2.229511 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.6185185185185185 and the number of correct results is: 167\n",
      " Iteration: 2110 , loss: 2.277319 Accuracy: 0.888000\n",
      " Iteration: 2120 , loss: 2.265411 Accuracy: 0.920000\n",
      " Iteration: 2130 , loss: 2.260967 Accuracy: 0.904000\n",
      " Iteration: 2140 , loss: 2.247326 Accuracy: 0.928000\n",
      " Iteration: 2150 , loss: 2.262137 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.6074074074074074 and the number of correct results is: 164\n",
      " Iteration: 2160 , loss: 2.265230 Accuracy: 0.888000\n",
      " Iteration: 2170 , loss: 2.235731 Accuracy: 0.924000\n",
      " Iteration: 2180 , loss: 2.245152 Accuracy: 0.916000\n",
      " Iteration: 2190 , loss: 2.244597 Accuracy: 0.924000\n",
      " Iteration: 2200 , loss: 2.269301 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.6333333333333333 and the number of correct results is: 171\n",
      " Iteration: 2210 , loss: 2.234127 Accuracy: 0.928000\n",
      " Iteration: 2220 , loss: 2.252969 Accuracy: 0.908000\n",
      " Iteration: 2230 , loss: 2.256711 Accuracy: 0.904000\n",
      " Iteration: 2240 , loss: 2.248862 Accuracy: 0.908000\n",
      " Iteration: 2250 , loss: 2.257812 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.6222222222222222 and the number of correct results is: 168\n",
      " Iteration: 2260 , loss: 2.230514 Accuracy: 0.924000\n",
      " Iteration: 2270 , loss: 2.246416 Accuracy: 0.928000\n",
      "\n",
      "Optimization of Split 2 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 3 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 3.045102 Accuracy: 0.048000\n",
      "The postprocessing average accuracy is: 0.04150943396226415 and the number of correct results is: 11\n",
      " Iteration: 10 , loss: 3.000071 Accuracy: 0.168000\n",
      " Iteration: 20 , loss: 2.970553 Accuracy: 0.244000\n",
      " Iteration: 30 , loss: 2.916396 Accuracy: 0.348000\n",
      " Iteration: 40 , loss: 2.913030 Accuracy: 0.356000\n",
      " Iteration: 50 , loss: 2.868950 Accuracy: 0.424000\n",
      "The postprocessing average accuracy is: 0.44150943396226416 and the number of correct results is: 117\n",
      " Iteration: 60 , loss: 2.847235 Accuracy: 0.456000\n",
      " Iteration: 70 , loss: 2.795531 Accuracy: 0.464000\n",
      " Iteration: 80 , loss: 2.811448 Accuracy: 0.444000\n",
      " Iteration: 90 , loss: 2.768406 Accuracy: 0.492000\n",
      " Iteration: 100 , loss: 2.736754 Accuracy: 0.552000\n",
      "The postprocessing average accuracy is: 0.5018867924528302 and the number of correct results is: 133\n",
      " Iteration: 110 , loss: 2.746406 Accuracy: 0.492000\n",
      " Iteration: 120 , loss: 2.741417 Accuracy: 0.488000\n",
      " Iteration: 130 , loss: 2.708991 Accuracy: 0.564000\n",
      " Iteration: 140 , loss: 2.681228 Accuracy: 0.584000\n",
      " Iteration: 150 , loss: 2.697767 Accuracy: 0.592000\n",
      "The postprocessing average accuracy is: 0.5433962264150943 and the number of correct results is: 144\n",
      " Iteration: 160 , loss: 2.674266 Accuracy: 0.580000\n",
      " Iteration: 170 , loss: 2.660947 Accuracy: 0.600000\n",
      " Iteration: 180 , loss: 2.640555 Accuracy: 0.636000\n",
      " Iteration: 190 , loss: 2.630191 Accuracy: 0.640000\n",
      " Iteration: 200 , loss: 2.626005 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.5509433962264151 and the number of correct results is: 146\n",
      " Iteration: 210 , loss: 2.634785 Accuracy: 0.644000\n",
      " Iteration: 220 , loss: 2.583271 Accuracy: 0.680000\n",
      " Iteration: 230 , loss: 2.610424 Accuracy: 0.640000\n",
      " Iteration: 240 , loss: 2.581867 Accuracy: 0.676000\n",
      " Iteration: 250 , loss: 2.531718 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.5735849056603773 and the number of correct results is: 152\n",
      " Iteration: 260 , loss: 2.600386 Accuracy: 0.616000\n",
      " Iteration: 270 , loss: 2.611535 Accuracy: 0.636000\n",
      " Iteration: 280 , loss: 2.555727 Accuracy: 0.684000\n",
      " Iteration: 290 , loss: 2.544339 Accuracy: 0.680000\n",
      " Iteration: 300 , loss: 2.541409 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.5735849056603773 and the number of correct results is: 152\n",
      " Iteration: 310 , loss: 2.534049 Accuracy: 0.704000\n",
      " Iteration: 320 , loss: 2.566173 Accuracy: 0.684000\n",
      " Iteration: 330 , loss: 2.531178 Accuracy: 0.696000\n",
      " Iteration: 340 , loss: 2.539953 Accuracy: 0.684000\n",
      " Iteration: 350 , loss: 2.492014 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.5735849056603773 and the number of correct results is: 152\n",
      " Iteration: 360 , loss: 2.527491 Accuracy: 0.696000\n",
      " Iteration: 370 , loss: 2.477880 Accuracy: 0.744000\n",
      " Iteration: 380 , loss: 2.492493 Accuracy: 0.736000\n",
      " Iteration: 390 , loss: 2.490135 Accuracy: 0.720000\n",
      " Iteration: 400 , loss: 2.492075 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.6188679245283019 and the number of correct results is: 164\n",
      " Iteration: 410 , loss: 2.502330 Accuracy: 0.732000\n",
      " Iteration: 420 , loss: 2.500408 Accuracy: 0.748000\n",
      " Iteration: 430 , loss: 2.475600 Accuracy: 0.732000\n",
      " Iteration: 440 , loss: 2.459975 Accuracy: 0.780000\n",
      " Iteration: 450 , loss: 2.479648 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.6150943396226415 and the number of correct results is: 163\n",
      " Iteration: 460 , loss: 2.458760 Accuracy: 0.776000\n",
      " Iteration: 470 , loss: 2.457002 Accuracy: 0.768000\n",
      " Iteration: 480 , loss: 2.487362 Accuracy: 0.732000\n",
      " Iteration: 490 , loss: 2.453823 Accuracy: 0.764000\n",
      " Iteration: 500 , loss: 2.447373 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.6226415094339622 and the number of correct results is: 165\n",
      " Iteration: 510 , loss: 2.433437 Accuracy: 0.784000\n",
      " Iteration: 520 , loss: 2.444105 Accuracy: 0.800000\n",
      " Iteration: 530 , loss: 2.445369 Accuracy: 0.768000\n",
      " Iteration: 540 , loss: 2.458857 Accuracy: 0.760000\n",
      " Iteration: 550 , loss: 2.405142 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.5924528301886792 and the number of correct results is: 157\n",
      " Iteration: 560 , loss: 2.419755 Accuracy: 0.788000\n",
      " Iteration: 570 , loss: 2.471777 Accuracy: 0.728000\n",
      " Iteration: 580 , loss: 2.417808 Accuracy: 0.800000\n",
      " Iteration: 590 , loss: 2.416277 Accuracy: 0.800000\n",
      " Iteration: 600 , loss: 2.409110 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.6377358490566037 and the number of correct results is: 169\n",
      " Iteration: 610 , loss: 2.411605 Accuracy: 0.828000\n",
      " Iteration: 620 , loss: 2.417921 Accuracy: 0.788000\n",
      " Iteration: 630 , loss: 2.409061 Accuracy: 0.816000\n",
      " Iteration: 640 , loss: 2.433815 Accuracy: 0.764000\n",
      " Iteration: 650 , loss: 2.416432 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.6037735849056604 and the number of correct results is: 160\n",
      " Iteration: 660 , loss: 2.420128 Accuracy: 0.796000\n",
      " Iteration: 670 , loss: 2.438210 Accuracy: 0.788000\n",
      " Iteration: 680 , loss: 2.427822 Accuracy: 0.804000\n",
      " Iteration: 690 , loss: 2.413649 Accuracy: 0.792000\n",
      " Iteration: 700 , loss: 2.433297 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.6339622641509434 and the number of correct results is: 168\n",
      " Iteration: 710 , loss: 2.385093 Accuracy: 0.820000\n",
      " Iteration: 720 , loss: 2.390348 Accuracy: 0.820000\n",
      " Iteration: 730 , loss: 2.398774 Accuracy: 0.812000\n",
      " Iteration: 740 , loss: 2.389396 Accuracy: 0.824000\n",
      " Iteration: 750 , loss: 2.379139 Accuracy: 0.820000\n",
      "The postprocessing average accuracy is: 0.6188679245283019 and the number of correct results is: 164\n",
      " Iteration: 760 , loss: 2.416989 Accuracy: 0.776000\n",
      " Iteration: 770 , loss: 2.367963 Accuracy: 0.840000\n",
      " Iteration: 780 , loss: 2.383731 Accuracy: 0.820000\n",
      " Iteration: 790 , loss: 2.382409 Accuracy: 0.832000\n",
      " Iteration: 800 , loss: 2.409200 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.630188679245283 and the number of correct results is: 167\n",
      " Iteration: 810 , loss: 2.397656 Accuracy: 0.804000\n",
      " Iteration: 820 , loss: 2.370389 Accuracy: 0.868000\n",
      " Iteration: 830 , loss: 2.393835 Accuracy: 0.804000\n",
      " Iteration: 840 , loss: 2.370929 Accuracy: 0.828000\n",
      " Iteration: 850 , loss: 2.354180 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.5773584905660377 and the number of correct results is: 153\n",
      " Iteration: 860 , loss: 2.369630 Accuracy: 0.828000\n",
      " Iteration: 870 , loss: 2.368638 Accuracy: 0.836000\n",
      " Iteration: 880 , loss: 2.385005 Accuracy: 0.808000\n",
      " Iteration: 890 , loss: 2.377561 Accuracy: 0.792000\n",
      " Iteration: 900 , loss: 2.362659 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.5924528301886792 and the number of correct results is: 157\n",
      " Iteration: 910 , loss: 2.379611 Accuracy: 0.828000\n",
      " Iteration: 920 , loss: 2.326622 Accuracy: 0.860000\n",
      " Iteration: 930 , loss: 2.321263 Accuracy: 0.856000\n",
      " Iteration: 940 , loss: 2.387965 Accuracy: 0.812000\n",
      " Iteration: 950 , loss: 2.324574 Accuracy: 0.868000\n",
      "The postprocessing average accuracy is: 0.5924528301886792 and the number of correct results is: 157\n",
      " Iteration: 960 , loss: 2.365089 Accuracy: 0.832000\n",
      " Iteration: 970 , loss: 2.345459 Accuracy: 0.860000\n",
      " Iteration: 980 , loss: 2.360737 Accuracy: 0.832000\n",
      " Iteration: 990 , loss: 2.343031 Accuracy: 0.844000\n",
      " Iteration: 1000 , loss: 2.342793 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 159\n",
      " Iteration: 1010 , loss: 2.359362 Accuracy: 0.832000\n",
      " Iteration: 1020 , loss: 2.369472 Accuracy: 0.824000\n",
      " Iteration: 1030 , loss: 2.322864 Accuracy: 0.860000\n",
      " Iteration: 1040 , loss: 2.327727 Accuracy: 0.852000\n",
      " Iteration: 1050 , loss: 2.366041 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.6113207547169811 and the number of correct results is: 162\n",
      " Iteration: 1060 , loss: 2.301044 Accuracy: 0.908000\n",
      " Iteration: 1070 , loss: 2.326831 Accuracy: 0.872000\n",
      " Iteration: 1080 , loss: 2.329648 Accuracy: 0.840000\n",
      " Iteration: 1090 , loss: 2.349609 Accuracy: 0.872000\n",
      " Iteration: 1100 , loss: 2.309689 Accuracy: 0.876000\n",
      "The postprocessing average accuracy is: 0.5886792452830188 and the number of correct results is: 156\n",
      " Iteration: 1110 , loss: 2.295689 Accuracy: 0.896000\n",
      " Iteration: 1120 , loss: 2.312793 Accuracy: 0.872000\n",
      " Iteration: 1130 , loss: 2.299118 Accuracy: 0.888000\n",
      " Iteration: 1140 , loss: 2.346219 Accuracy: 0.820000\n",
      " Iteration: 1150 , loss: 2.360048 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.630188679245283 and the number of correct results is: 167\n",
      " Iteration: 1160 , loss: 2.302749 Accuracy: 0.880000\n",
      " Iteration: 1170 , loss: 2.315710 Accuracy: 0.876000\n",
      " Iteration: 1180 , loss: 2.340104 Accuracy: 0.864000\n",
      " Iteration: 1190 , loss: 2.305928 Accuracy: 0.888000\n",
      " Iteration: 1200 , loss: 2.333605 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.6113207547169811 and the number of correct results is: 162\n",
      " Iteration: 1210 , loss: 2.305503 Accuracy: 0.888000\n",
      " Iteration: 1220 , loss: 2.342989 Accuracy: 0.848000\n",
      " Iteration: 1230 , loss: 2.330130 Accuracy: 0.872000\n",
      " Iteration: 1240 , loss: 2.353458 Accuracy: 0.836000\n",
      " Iteration: 1250 , loss: 2.332631 Accuracy: 0.848000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 159\n",
      " Iteration: 1260 , loss: 2.300291 Accuracy: 0.888000\n",
      " Iteration: 1270 , loss: 2.322222 Accuracy: 0.864000\n",
      " Iteration: 1280 , loss: 2.294981 Accuracy: 0.904000\n",
      " Iteration: 1290 , loss: 2.270899 Accuracy: 0.900000\n",
      " Iteration: 1300 , loss: 2.338444 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 159\n",
      " Iteration: 1310 , loss: 2.320229 Accuracy: 0.868000\n",
      " Iteration: 1320 , loss: 2.282686 Accuracy: 0.876000\n",
      " Iteration: 1330 , loss: 2.294853 Accuracy: 0.880000\n",
      " Iteration: 1340 , loss: 2.308097 Accuracy: 0.880000\n",
      " Iteration: 1350 , loss: 2.294919 Accuracy: 0.892000\n",
      "The postprocessing average accuracy is: 0.6075471698113207 and the number of correct results is: 161\n",
      " Iteration: 1360 , loss: 2.279729 Accuracy: 0.912000\n",
      " Iteration: 1370 , loss: 2.320238 Accuracy: 0.864000\n",
      " Iteration: 1380 , loss: 2.326132 Accuracy: 0.860000\n",
      " Iteration: 1390 , loss: 2.287635 Accuracy: 0.888000\n",
      " Iteration: 1400 , loss: 2.318005 Accuracy: 0.856000\n",
      "The postprocessing average accuracy is: 0.6264150943396226 and the number of correct results is: 166\n",
      " Iteration: 1410 , loss: 2.282348 Accuracy: 0.880000\n",
      " Iteration: 1420 , loss: 2.272862 Accuracy: 0.908000\n",
      " Iteration: 1430 , loss: 2.320781 Accuracy: 0.852000\n",
      " Iteration: 1440 , loss: 2.298644 Accuracy: 0.900000\n",
      " Iteration: 1450 , loss: 2.241718 Accuracy: 0.940000\n",
      "The postprocessing average accuracy is: 0.6150943396226415 and the number of correct results is: 163\n",
      " Iteration: 1460 , loss: 2.285660 Accuracy: 0.888000\n",
      " Iteration: 1470 , loss: 2.273526 Accuracy: 0.896000\n",
      " Iteration: 1480 , loss: 2.292549 Accuracy: 0.884000\n",
      " Iteration: 1490 , loss: 2.289551 Accuracy: 0.888000\n",
      " Iteration: 1500 , loss: 2.310078 Accuracy: 0.872000\n",
      "The postprocessing average accuracy is: 0.5962264150943396 and the number of correct results is: 158\n",
      " Iteration: 1510 , loss: 2.300111 Accuracy: 0.880000\n",
      " Iteration: 1520 , loss: 2.292406 Accuracy: 0.864000\n",
      " Iteration: 1530 , loss: 2.310628 Accuracy: 0.884000\n",
      " Iteration: 1540 , loss: 2.267037 Accuracy: 0.924000\n",
      " Iteration: 1550 , loss: 2.310747 Accuracy: 0.876000\n",
      "The postprocessing average accuracy is: 0.6150943396226415 and the number of correct results is: 163\n",
      " Iteration: 1560 , loss: 2.273053 Accuracy: 0.888000\n",
      " Iteration: 1570 , loss: 2.282392 Accuracy: 0.900000\n",
      " Iteration: 1580 , loss: 2.275126 Accuracy: 0.916000\n",
      " Iteration: 1590 , loss: 2.283285 Accuracy: 0.892000\n",
      " Iteration: 1600 , loss: 2.275602 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.6188679245283019 and the number of correct results is: 164\n",
      " Iteration: 1610 , loss: 2.294807 Accuracy: 0.880000\n",
      " Iteration: 1620 , loss: 2.305219 Accuracy: 0.884000\n",
      " Iteration: 1630 , loss: 2.301517 Accuracy: 0.892000\n",
      " Iteration: 1640 , loss: 2.284737 Accuracy: 0.908000\n",
      " Iteration: 1650 , loss: 2.275559 Accuracy: 0.900000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 159\n",
      " Iteration: 1660 , loss: 2.261106 Accuracy: 0.924000\n",
      " Iteration: 1670 , loss: 2.284616 Accuracy: 0.896000\n",
      " Iteration: 1680 , loss: 2.265255 Accuracy: 0.900000\n",
      " Iteration: 1690 , loss: 2.278576 Accuracy: 0.904000\n",
      " Iteration: 1700 , loss: 2.285312 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.6226415094339622 and the number of correct results is: 165\n",
      " Iteration: 1710 , loss: 2.284524 Accuracy: 0.892000\n",
      " Iteration: 1720 , loss: 2.276959 Accuracy: 0.900000\n",
      " Iteration: 1730 , loss: 2.271687 Accuracy: 0.908000\n",
      " Iteration: 1740 , loss: 2.241196 Accuracy: 0.928000\n",
      " Iteration: 1750 , loss: 2.264318 Accuracy: 0.896000\n",
      "The postprocessing average accuracy is: 0.5924528301886792 and the number of correct results is: 157\n",
      " Iteration: 1760 , loss: 2.279060 Accuracy: 0.904000\n",
      " Iteration: 1770 , loss: 2.282923 Accuracy: 0.896000\n",
      " Iteration: 1780 , loss: 2.278843 Accuracy: 0.888000\n",
      " Iteration: 1790 , loss: 2.276707 Accuracy: 0.892000\n",
      " Iteration: 1800 , loss: 2.249579 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.6264150943396226 and the number of correct results is: 166\n",
      " Iteration: 1810 , loss: 2.259373 Accuracy: 0.924000\n",
      " Iteration: 1820 , loss: 2.263624 Accuracy: 0.916000\n",
      " Iteration: 1830 , loss: 2.281322 Accuracy: 0.896000\n",
      " Iteration: 1840 , loss: 2.248900 Accuracy: 0.904000\n",
      " Iteration: 1850 , loss: 2.239271 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.5962264150943396 and the number of correct results is: 158\n",
      " Iteration: 1860 , loss: 2.243934 Accuracy: 0.916000\n",
      " Iteration: 1870 , loss: 2.298427 Accuracy: 0.872000\n",
      " Iteration: 1880 , loss: 2.258677 Accuracy: 0.912000\n",
      " Iteration: 1890 , loss: 2.284819 Accuracy: 0.888000\n",
      " Iteration: 1900 , loss: 2.254789 Accuracy: 0.916000\n",
      "The postprocessing average accuracy is: 0.6113207547169811 and the number of correct results is: 162\n",
      " Iteration: 1910 , loss: 2.276396 Accuracy: 0.908000\n",
      " Iteration: 1920 , loss: 2.254866 Accuracy: 0.924000\n",
      " Iteration: 1930 , loss: 2.242776 Accuracy: 0.924000\n",
      " Iteration: 1940 , loss: 2.245087 Accuracy: 0.924000\n",
      " Iteration: 1950 , loss: 2.237628 Accuracy: 0.932000\n",
      "The postprocessing average accuracy is: 0.6150943396226415 and the number of correct results is: 163\n",
      " Iteration: 1960 , loss: 2.272823 Accuracy: 0.904000\n",
      " Iteration: 1970 , loss: 2.280950 Accuracy: 0.892000\n",
      " Iteration: 1980 , loss: 2.237483 Accuracy: 0.932000\n",
      " Iteration: 1990 , loss: 2.226298 Accuracy: 0.932000\n",
      " Iteration: 2000 , loss: 2.264773 Accuracy: 0.888000\n",
      "The postprocessing average accuracy is: 0.6075471698113207 and the number of correct results is: 161\n",
      " Iteration: 2010 , loss: 2.231547 Accuracy: 0.944000\n",
      " Iteration: 2020 , loss: 2.236108 Accuracy: 0.940000\n",
      " Iteration: 2030 , loss: 2.236029 Accuracy: 0.932000\n",
      " Iteration: 2040 , loss: 2.246507 Accuracy: 0.928000\n",
      " Iteration: 2050 , loss: 2.244861 Accuracy: 0.924000\n",
      "The postprocessing average accuracy is: 0.5886792452830188 and the number of correct results is: 156\n",
      " Iteration: 2060 , loss: 2.243720 Accuracy: 0.920000\n",
      " Iteration: 2070 , loss: 2.256790 Accuracy: 0.916000\n",
      " Iteration: 2080 , loss: 2.248405 Accuracy: 0.924000\n",
      " Iteration: 2090 , loss: 2.258319 Accuracy: 0.912000\n",
      " Iteration: 2100 , loss: 2.216839 Accuracy: 0.956000\n",
      "The postprocessing average accuracy is: 0.6 and the number of correct results is: 159\n",
      " Iteration: 2110 , loss: 2.229728 Accuracy: 0.944000\n",
      " Iteration: 2120 , loss: 2.262949 Accuracy: 0.924000\n",
      " Iteration: 2130 , loss: 2.244438 Accuracy: 0.940000\n",
      " Iteration: 2140 , loss: 2.225285 Accuracy: 0.928000\n",
      " Iteration: 2150 , loss: 2.222412 Accuracy: 0.952000\n",
      "The postprocessing average accuracy is: 0.5811320754716981 and the number of correct results is: 154\n",
      " Iteration: 2160 , loss: 2.230193 Accuracy: 0.936000\n",
      " Iteration: 2170 , loss: 2.228998 Accuracy: 0.928000\n",
      " Iteration: 2180 , loss: 2.214603 Accuracy: 0.948000\n",
      " Iteration: 2190 , loss: 2.258609 Accuracy: 0.916000\n",
      " Iteration: 2200 , loss: 2.225864 Accuracy: 0.944000\n",
      "The postprocessing average accuracy is: 0.5962264150943396 and the number of correct results is: 158\n",
      " Iteration: 2210 , loss: 2.245633 Accuracy: 0.924000\n",
      " Iteration: 2220 , loss: 2.252508 Accuracy: 0.920000\n",
      " Iteration: 2230 , loss: 2.246310 Accuracy: 0.904000\n",
      " Iteration: 2240 , loss: 2.242602 Accuracy: 0.924000\n",
      " Iteration: 2250 , loss: 2.268814 Accuracy: 0.908000\n",
      "The postprocessing average accuracy is: 0.6188679245283019 and the number of correct results is: 164\n",
      " Iteration: 2260 , loss: 2.245238 Accuracy: 0.920000\n",
      " Iteration: 2270 , loss: 2.238172 Accuracy: 0.936000\n",
      "\n",
      "Optimization of Split 3 Finished\n",
      "\n",
      "\n",
      "The number of sequences found in split 1 are: 29\n",
      "The number of sequences found in split 2 are: 18\n",
      "The number of sequences found in split 3 are: 21\n",
      "The number of iterations for in this split is: 335.5\n",
      "Starting training of Florence_3d \n",
      "\n",
      "loaded data 3 well\n",
      "shape of the data 30 number of labels 9 size of train data ( 3355 3355 ) \n",
      "\n",
      "\n",
      "layer 1 operation results\n",
      "h_conv is: Tensor(\"Relu:0\", shape=(?, 1, 256), dtype=float32)\n",
      "h_conv_ to FCN is: Tensor(\"Reshape_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 2 operation results\n",
      "h_fc1 is: Tensor(\"Relu_1:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc1_drop is: Tensor(\"dropout/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 3 operation results\n",
      "h_fc2 is: Tensor(\"Relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc2_drop is: Tensor(\"dropout_1/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 4 operation results\n",
      "h_fc3 is: Tensor(\"add_3:0\", shape=(?, 9), dtype=float32)\n",
      "y_conv is: Tensor(\"add_4:0\", shape=(?, 9), dtype=float32)\n",
      "\n",
      " Optimization of Split 1 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.164365 Accuracy: 0.196000\n",
      "The postprocessing average accuracy is: 0.27586206896551724 and the number of correct results is: 8\n",
      " Iteration: 10 , loss: 2.076435 Accuracy: 0.344000\n",
      " Iteration: 20 , loss: 2.052163 Accuracy: 0.376000\n",
      " Iteration: 30 , loss: 1.958049 Accuracy: 0.508000\n",
      " Iteration: 40 , loss: 1.919824 Accuracy: 0.548000\n",
      " Iteration: 50 , loss: 1.898499 Accuracy: 0.560000\n",
      "The postprocessing average accuracy is: 0.6896551724137931 and the number of correct results is: 20\n",
      " Iteration: 60 , loss: 1.945009 Accuracy: 0.512000\n",
      " Iteration: 70 , loss: 1.862806 Accuracy: 0.588000\n",
      " Iteration: 80 , loss: 1.814355 Accuracy: 0.616000\n",
      " Iteration: 90 , loss: 1.806255 Accuracy: 0.640000\n",
      " Iteration: 100 , loss: 1.839358 Accuracy: 0.636000\n",
      "The postprocessing average accuracy is: 0.7931034482758621 and the number of correct results is: 23\n",
      " Iteration: 110 , loss: 1.770566 Accuracy: 0.684000\n",
      " Iteration: 120 , loss: 1.758605 Accuracy: 0.700000\n",
      " Iteration: 130 , loss: 1.742579 Accuracy: 0.724000\n",
      " Iteration: 140 , loss: 1.757390 Accuracy: 0.708000\n",
      " Iteration: 150 , loss: 1.751723 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.7586206896551724 and the number of correct results is: 22\n",
      " Iteration: 160 , loss: 1.694921 Accuracy: 0.764000\n",
      " Iteration: 170 , loss: 1.695593 Accuracy: 0.772000\n",
      " Iteration: 180 , loss: 1.708667 Accuracy: 0.768000\n",
      " Iteration: 190 , loss: 1.695372 Accuracy: 0.760000\n",
      " Iteration: 200 , loss: 1.652135 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.7931034482758621 and the number of correct results is: 23\n",
      " Iteration: 210 , loss: 1.657553 Accuracy: 0.792000\n",
      " Iteration: 220 , loss: 1.627681 Accuracy: 0.852000\n",
      " Iteration: 230 , loss: 1.678427 Accuracy: 0.772000\n",
      " Iteration: 240 , loss: 1.618205 Accuracy: 0.820000\n",
      " Iteration: 250 , loss: 1.614928 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.7241379310344828 and the number of correct results is: 21\n",
      " Iteration: 260 , loss: 1.616500 Accuracy: 0.824000\n",
      " Iteration: 270 , loss: 1.646503 Accuracy: 0.780000\n",
      " Iteration: 280 , loss: 1.602803 Accuracy: 0.852000\n",
      " Iteration: 290 , loss: 1.616284 Accuracy: 0.840000\n",
      " Iteration: 300 , loss: 1.595709 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.6896551724137931 and the number of correct results is: 20\n",
      " Iteration: 310 , loss: 1.578810 Accuracy: 0.832000\n",
      " Iteration: 320 , loss: 1.588247 Accuracy: 0.856000\n",
      " Iteration: 330 , loss: 1.591995 Accuracy: 0.864000\n",
      "\n",
      "Optimization of Split 1 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 2 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.187247 Accuracy: 0.132000\n",
      "The postprocessing average accuracy is: 0.05555555555555555 and the number of correct results is: 1\n",
      " Iteration: 10 , loss: 2.104785 Accuracy: 0.296000\n",
      " Iteration: 20 , loss: 2.053418 Accuracy: 0.392000\n",
      " Iteration: 30 , loss: 2.007717 Accuracy: 0.432000\n",
      " Iteration: 40 , loss: 1.963457 Accuracy: 0.496000\n",
      " Iteration: 50 , loss: 1.910355 Accuracy: 0.560000\n",
      "The postprocessing average accuracy is: 0.8333333333333334 and the number of correct results is: 15\n",
      " Iteration: 60 , loss: 1.914828 Accuracy: 0.512000\n",
      " Iteration: 70 , loss: 1.906170 Accuracy: 0.516000\n",
      " Iteration: 80 , loss: 1.846758 Accuracy: 0.660000\n",
      " Iteration: 90 , loss: 1.856518 Accuracy: 0.600000\n",
      " Iteration: 100 , loss: 1.823246 Accuracy: 0.608000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 16\n",
      " Iteration: 110 , loss: 1.799756 Accuracy: 0.652000\n",
      " Iteration: 120 , loss: 1.782694 Accuracy: 0.668000\n",
      " Iteration: 130 , loss: 1.777333 Accuracy: 0.672000\n",
      " Iteration: 140 , loss: 1.761739 Accuracy: 0.720000\n",
      " Iteration: 150 , loss: 1.750866 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 16\n",
      " Iteration: 160 , loss: 1.717062 Accuracy: 0.708000\n",
      " Iteration: 170 , loss: 1.715249 Accuracy: 0.752000\n",
      " Iteration: 180 , loss: 1.724865 Accuracy: 0.724000\n",
      " Iteration: 190 , loss: 1.704061 Accuracy: 0.740000\n",
      " Iteration: 200 , loss: 1.685528 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 16\n",
      " Iteration: 210 , loss: 1.678894 Accuracy: 0.788000\n",
      " Iteration: 220 , loss: 1.669355 Accuracy: 0.776000\n",
      " Iteration: 230 , loss: 1.699747 Accuracy: 0.748000\n",
      " Iteration: 240 , loss: 1.649433 Accuracy: 0.792000\n",
      " Iteration: 250 , loss: 1.659031 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8333333333333334 and the number of correct results is: 15\n",
      " Iteration: 260 , loss: 1.664890 Accuracy: 0.788000\n",
      " Iteration: 270 , loss: 1.640073 Accuracy: 0.804000\n",
      " Iteration: 280 , loss: 1.622414 Accuracy: 0.824000\n",
      " Iteration: 290 , loss: 1.620658 Accuracy: 0.868000\n",
      " Iteration: 300 , loss: 1.644587 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8333333333333334 and the number of correct results is: 15\n",
      " Iteration: 310 , loss: 1.636747 Accuracy: 0.796000\n",
      " Iteration: 320 , loss: 1.612507 Accuracy: 0.840000\n",
      " Iteration: 330 , loss: 1.605818 Accuracy: 0.828000\n",
      "\n",
      "Optimization of Split 2 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 3 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 2.192344 Accuracy: 0.112000\n",
      "The postprocessing average accuracy is: 0.14285714285714285 and the number of correct results is: 3\n",
      " Iteration: 10 , loss: 2.090527 Accuracy: 0.336000\n",
      " Iteration: 20 , loss: 2.055854 Accuracy: 0.360000\n",
      " Iteration: 30 , loss: 1.989013 Accuracy: 0.464000\n",
      " Iteration: 40 , loss: 1.964875 Accuracy: 0.488000\n",
      " Iteration: 50 , loss: 1.937546 Accuracy: 0.544000\n",
      "The postprocessing average accuracy is: 0.8571428571428571 and the number of correct results is: 18\n",
      " Iteration: 60 , loss: 1.907412 Accuracy: 0.528000\n",
      " Iteration: 70 , loss: 1.898457 Accuracy: 0.572000\n",
      " Iteration: 80 , loss: 1.854163 Accuracy: 0.592000\n",
      " Iteration: 90 , loss: 1.826780 Accuracy: 0.640000\n",
      " Iteration: 100 , loss: 1.813437 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.9523809523809523 and the number of correct results is: 20\n",
      " Iteration: 110 , loss: 1.805247 Accuracy: 0.652000\n",
      " Iteration: 120 , loss: 1.788523 Accuracy: 0.676000\n",
      " Iteration: 130 , loss: 1.765213 Accuracy: 0.712000\n",
      " Iteration: 140 , loss: 1.737074 Accuracy: 0.768000\n",
      " Iteration: 150 , loss: 1.726636 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9523809523809523 and the number of correct results is: 20\n",
      " Iteration: 160 , loss: 1.750244 Accuracy: 0.708000\n",
      " Iteration: 170 , loss: 1.764838 Accuracy: 0.668000\n",
      " Iteration: 180 , loss: 1.721539 Accuracy: 0.736000\n",
      " Iteration: 190 , loss: 1.696536 Accuracy: 0.780000\n",
      " Iteration: 200 , loss: 1.690377 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9523809523809523 and the number of correct results is: 20\n",
      " Iteration: 210 , loss: 1.698560 Accuracy: 0.748000\n",
      " Iteration: 220 , loss: 1.684233 Accuracy: 0.768000\n",
      " Iteration: 230 , loss: 1.636685 Accuracy: 0.812000\n",
      " Iteration: 240 , loss: 1.639464 Accuracy: 0.816000\n",
      " Iteration: 250 , loss: 1.632012 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.9523809523809523 and the number of correct results is: 20\n",
      " Iteration: 260 , loss: 1.640940 Accuracy: 0.828000\n",
      " Iteration: 270 , loss: 1.654257 Accuracy: 0.792000\n",
      " Iteration: 280 , loss: 1.640126 Accuracy: 0.800000\n",
      " Iteration: 290 , loss: 1.626102 Accuracy: 0.836000\n",
      " Iteration: 300 , loss: 1.641918 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9523809523809523 and the number of correct results is: 20\n",
      " Iteration: 310 , loss: 1.605366 Accuracy: 0.840000\n",
      " Iteration: 320 , loss: 1.617646 Accuracy: 0.824000\n",
      " Iteration: 330 , loss: 1.601749 Accuracy: 0.828000\n",
      "\n",
      "Optimization of Split 3 Finished\n",
      "\n",
      "\n",
      "The number of sequences found in split 1 are: 234\n",
      "The number of sequences found in split 2 are: 233\n",
      "The number of sequences found in split 3 are: 240\n",
      "The number of iterations for in this split is: 13908.4\n",
      "Starting training of Bn_mocap \n",
      "\n",
      "loaded data 4 well\n",
      "shape of the data 30 number of labels 65 size of train data ( 139084 139084 ) \n",
      "\n",
      "\n",
      "layer 1 operation results\n",
      "h_conv is: Tensor(\"Relu:0\", shape=(?, 1, 256), dtype=float32)\n",
      "h_conv_ to FCN is: Tensor(\"Reshape_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 2 operation results\n",
      "h_fc1 is: Tensor(\"Relu_1:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc1_drop is: Tensor(\"dropout/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 3 operation results\n",
      "h_fc2 is: Tensor(\"Relu_2:0\", shape=(?, 256), dtype=float32)\n",
      "h_fc2_drop is: Tensor(\"dropout_1/mul_1:0\", shape=(?, 256), dtype=float32)\n",
      "layer 4 operation results\n",
      "h_fc3 is: Tensor(\"add_3:0\", shape=(?, 65), dtype=float32)\n",
      "y_conv is: Tensor(\"add_4:0\", shape=(?, 65), dtype=float32)\n",
      "\n",
      " Optimization of Split 1 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 4.173621 Accuracy: 0.016000\n",
      "The postprocessing average accuracy is: 0.01282051282051282 and the number of correct results is: 3\n",
      " Iteration: 10 , loss: 4.164744 Accuracy: 0.068000\n",
      " Iteration: 20 , loss: 4.158837 Accuracy: 0.080000\n",
      " Iteration: 30 , loss: 4.147492 Accuracy: 0.108000\n",
      " Iteration: 40 , loss: 4.142140 Accuracy: 0.112000\n",
      " Iteration: 50 , loss: 4.122253 Accuracy: 0.164000\n",
      "The postprocessing average accuracy is: 0.2564102564102564 and the number of correct results is: 60\n",
      " Iteration: 60 , loss: 4.117629 Accuracy: 0.200000\n",
      " Iteration: 70 , loss: 4.117016 Accuracy: 0.172000\n",
      " Iteration: 80 , loss: 4.098207 Accuracy: 0.244000\n",
      " Iteration: 90 , loss: 4.104919 Accuracy: 0.208000\n",
      " Iteration: 100 , loss: 4.073023 Accuracy: 0.232000\n",
      "The postprocessing average accuracy is: 0.3888888888888889 and the number of correct results is: 91\n",
      " Iteration: 110 , loss: 4.075280 Accuracy: 0.236000\n",
      " Iteration: 120 , loss: 4.045191 Accuracy: 0.244000\n",
      " Iteration: 130 , loss: 4.041157 Accuracy: 0.284000\n",
      " Iteration: 140 , loss: 4.053007 Accuracy: 0.264000\n",
      " Iteration: 150 , loss: 4.053493 Accuracy: 0.272000\n",
      "The postprocessing average accuracy is: 0.49145299145299143 and the number of correct results is: 115\n",
      " Iteration: 160 , loss: 4.005069 Accuracy: 0.332000\n",
      " Iteration: 170 , loss: 4.003581 Accuracy: 0.328000\n",
      " Iteration: 180 , loss: 4.007660 Accuracy: 0.308000\n",
      " Iteration: 190 , loss: 4.010852 Accuracy: 0.336000\n",
      " Iteration: 200 , loss: 3.970068 Accuracy: 0.364000\n",
      "The postprocessing average accuracy is: 0.5769230769230769 and the number of correct results is: 135\n",
      " Iteration: 210 , loss: 4.006455 Accuracy: 0.348000\n",
      " Iteration: 220 , loss: 4.015791 Accuracy: 0.284000\n",
      " Iteration: 230 , loss: 3.992354 Accuracy: 0.316000\n",
      " Iteration: 240 , loss: 3.972914 Accuracy: 0.368000\n",
      " Iteration: 250 , loss: 3.990501 Accuracy: 0.340000\n",
      "The postprocessing average accuracy is: 0.6196581196581197 and the number of correct results is: 145\n",
      " Iteration: 260 , loss: 3.950082 Accuracy: 0.384000\n",
      " Iteration: 270 , loss: 3.951849 Accuracy: 0.396000\n",
      " Iteration: 280 , loss: 3.988725 Accuracy: 0.364000\n",
      " Iteration: 290 , loss: 3.944436 Accuracy: 0.380000\n",
      " Iteration: 300 , loss: 3.945513 Accuracy: 0.388000\n",
      "The postprocessing average accuracy is: 0.5982905982905983 and the number of correct results is: 140\n",
      " Iteration: 310 , loss: 3.932341 Accuracy: 0.424000\n",
      " Iteration: 320 , loss: 3.913607 Accuracy: 0.456000\n",
      " Iteration: 330 , loss: 3.942299 Accuracy: 0.356000\n",
      " Iteration: 340 , loss: 3.934241 Accuracy: 0.420000\n",
      " Iteration: 350 , loss: 3.920256 Accuracy: 0.412000\n",
      "The postprocessing average accuracy is: 0.6666666666666666 and the number of correct results is: 156\n",
      " Iteration: 360 , loss: 3.926744 Accuracy: 0.404000\n",
      " Iteration: 370 , loss: 3.949551 Accuracy: 0.404000\n",
      " Iteration: 380 , loss: 3.868359 Accuracy: 0.468000\n",
      " Iteration: 390 , loss: 3.919668 Accuracy: 0.396000\n",
      " Iteration: 400 , loss: 3.896332 Accuracy: 0.408000\n",
      "The postprocessing average accuracy is: 0.6495726495726496 and the number of correct results is: 152\n",
      " Iteration: 410 , loss: 3.927921 Accuracy: 0.408000\n",
      " Iteration: 420 , loss: 3.873712 Accuracy: 0.464000\n",
      " Iteration: 430 , loss: 3.915796 Accuracy: 0.416000\n",
      " Iteration: 440 , loss: 3.877889 Accuracy: 0.428000\n",
      " Iteration: 450 , loss: 3.882833 Accuracy: 0.476000\n",
      "The postprocessing average accuracy is: 0.6709401709401709 and the number of correct results is: 157\n",
      " Iteration: 460 , loss: 3.892840 Accuracy: 0.496000\n",
      " Iteration: 470 , loss: 3.879004 Accuracy: 0.436000\n",
      " Iteration: 480 , loss: 3.919888 Accuracy: 0.384000\n",
      " Iteration: 490 , loss: 3.910957 Accuracy: 0.408000\n",
      " Iteration: 500 , loss: 3.841407 Accuracy: 0.484000\n",
      "The postprocessing average accuracy is: 0.7307692307692307 and the number of correct results is: 171\n",
      " Iteration: 510 , loss: 3.881809 Accuracy: 0.460000\n",
      " Iteration: 520 , loss: 3.895142 Accuracy: 0.440000\n",
      " Iteration: 530 , loss: 3.885880 Accuracy: 0.428000\n",
      " Iteration: 540 , loss: 3.873627 Accuracy: 0.444000\n",
      " Iteration: 550 , loss: 3.872033 Accuracy: 0.424000\n",
      "The postprocessing average accuracy is: 0.7008547008547008 and the number of correct results is: 164\n",
      " Iteration: 560 , loss: 3.888242 Accuracy: 0.440000\n",
      " Iteration: 570 , loss: 3.857949 Accuracy: 0.516000\n",
      " Iteration: 580 , loss: 3.839499 Accuracy: 0.484000\n",
      " Iteration: 590 , loss: 3.844409 Accuracy: 0.508000\n",
      " Iteration: 600 , loss: 3.869373 Accuracy: 0.472000\n",
      "The postprocessing average accuracy is: 0.7222222222222222 and the number of correct results is: 169\n",
      " Iteration: 610 , loss: 3.849418 Accuracy: 0.512000\n",
      " Iteration: 620 , loss: 3.868467 Accuracy: 0.468000\n",
      " Iteration: 630 , loss: 3.865194 Accuracy: 0.472000\n",
      " Iteration: 640 , loss: 3.812758 Accuracy: 0.516000\n",
      " Iteration: 650 , loss: 3.828984 Accuracy: 0.504000\n",
      "The postprocessing average accuracy is: 0.7264957264957265 and the number of correct results is: 170\n",
      " Iteration: 660 , loss: 3.823219 Accuracy: 0.520000\n",
      " Iteration: 670 , loss: 3.830328 Accuracy: 0.484000\n",
      " Iteration: 680 , loss: 3.852659 Accuracy: 0.468000\n",
      " Iteration: 690 , loss: 3.826170 Accuracy: 0.476000\n",
      " Iteration: 700 , loss: 3.861722 Accuracy: 0.460000\n",
      "The postprocessing average accuracy is: 0.7564102564102564 and the number of correct results is: 177\n",
      " Iteration: 710 , loss: 3.802584 Accuracy: 0.528000\n",
      " Iteration: 720 , loss: 3.775950 Accuracy: 0.560000\n",
      " Iteration: 730 , loss: 3.817022 Accuracy: 0.520000\n",
      " Iteration: 740 , loss: 3.799464 Accuracy: 0.528000\n",
      " Iteration: 750 , loss: 3.832439 Accuracy: 0.508000\n",
      "The postprocessing average accuracy is: 0.7478632478632479 and the number of correct results is: 175\n",
      " Iteration: 760 , loss: 3.845263 Accuracy: 0.480000\n",
      " Iteration: 770 , loss: 3.838025 Accuracy: 0.496000\n",
      " Iteration: 780 , loss: 3.828559 Accuracy: 0.504000\n",
      " Iteration: 790 , loss: 3.816701 Accuracy: 0.516000\n",
      " Iteration: 800 , loss: 3.818166 Accuracy: 0.528000\n",
      "The postprocessing average accuracy is: 0.7521367521367521 and the number of correct results is: 176\n",
      " Iteration: 810 , loss: 3.826542 Accuracy: 0.500000\n",
      " Iteration: 820 , loss: 3.765426 Accuracy: 0.548000\n",
      " Iteration: 830 , loss: 3.845943 Accuracy: 0.488000\n",
      " Iteration: 840 , loss: 3.810552 Accuracy: 0.492000\n",
      " Iteration: 850 , loss: 3.836015 Accuracy: 0.472000\n",
      "The postprocessing average accuracy is: 0.782051282051282 and the number of correct results is: 183\n",
      " Iteration: 860 , loss: 3.784387 Accuracy: 0.532000\n",
      " Iteration: 870 , loss: 3.788902 Accuracy: 0.512000\n",
      " Iteration: 880 , loss: 3.791464 Accuracy: 0.552000\n",
      " Iteration: 890 , loss: 3.802767 Accuracy: 0.528000\n",
      " Iteration: 900 , loss: 3.806808 Accuracy: 0.524000\n",
      "The postprocessing average accuracy is: 0.7564102564102564 and the number of correct results is: 177\n",
      " Iteration: 910 , loss: 3.761541 Accuracy: 0.564000\n",
      " Iteration: 920 , loss: 3.773424 Accuracy: 0.564000\n",
      " Iteration: 930 , loss: 3.770642 Accuracy: 0.512000\n",
      " Iteration: 940 , loss: 3.797680 Accuracy: 0.532000\n",
      " Iteration: 950 , loss: 3.819909 Accuracy: 0.468000\n",
      "The postprocessing average accuracy is: 0.7564102564102564 and the number of correct results is: 177\n",
      " Iteration: 960 , loss: 3.773195 Accuracy: 0.528000\n",
      " Iteration: 970 , loss: 3.796415 Accuracy: 0.528000\n",
      " Iteration: 980 , loss: 3.764652 Accuracy: 0.556000\n",
      " Iteration: 990 , loss: 3.785702 Accuracy: 0.512000\n",
      " Iteration: 1000 , loss: 3.755820 Accuracy: 0.552000\n",
      "The postprocessing average accuracy is: 0.7521367521367521 and the number of correct results is: 176\n",
      " Iteration: 1010 , loss: 3.730675 Accuracy: 0.624000\n",
      " Iteration: 1020 , loss: 3.770862 Accuracy: 0.576000\n",
      " Iteration: 1030 , loss: 3.739103 Accuracy: 0.568000\n",
      " Iteration: 1040 , loss: 3.787396 Accuracy: 0.584000\n",
      " Iteration: 1050 , loss: 3.736722 Accuracy: 0.636000\n",
      "The postprocessing average accuracy is: 0.782051282051282 and the number of correct results is: 183\n",
      " Iteration: 1060 , loss: 3.774266 Accuracy: 0.540000\n",
      " Iteration: 1070 , loss: 3.766031 Accuracy: 0.560000\n",
      " Iteration: 1080 , loss: 3.754200 Accuracy: 0.568000\n",
      " Iteration: 1090 , loss: 3.789912 Accuracy: 0.524000\n",
      " Iteration: 1100 , loss: 3.760692 Accuracy: 0.588000\n",
      "The postprocessing average accuracy is: 0.7863247863247863 and the number of correct results is: 184\n",
      " Iteration: 1110 , loss: 3.783849 Accuracy: 0.540000\n",
      " Iteration: 1120 , loss: 3.775545 Accuracy: 0.552000\n",
      " Iteration: 1130 , loss: 3.754571 Accuracy: 0.592000\n",
      " Iteration: 1140 , loss: 3.748335 Accuracy: 0.596000\n",
      " Iteration: 1150 , loss: 3.723659 Accuracy: 0.600000\n",
      "The postprocessing average accuracy is: 0.782051282051282 and the number of correct results is: 183\n",
      " Iteration: 1160 , loss: 3.773705 Accuracy: 0.524000\n",
      " Iteration: 1170 , loss: 3.729362 Accuracy: 0.572000\n",
      " Iteration: 1180 , loss: 3.750193 Accuracy: 0.584000\n",
      " Iteration: 1190 , loss: 3.779644 Accuracy: 0.564000\n",
      " Iteration: 1200 , loss: 3.750688 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.782051282051282 and the number of correct results is: 183\n",
      " Iteration: 1210 , loss: 3.700998 Accuracy: 0.628000\n",
      " Iteration: 1220 , loss: 3.743418 Accuracy: 0.636000\n",
      " Iteration: 1230 , loss: 3.764279 Accuracy: 0.572000\n",
      " Iteration: 1240 , loss: 3.768173 Accuracy: 0.536000\n",
      " Iteration: 1250 , loss: 3.686751 Accuracy: 0.636000\n",
      "The postprocessing average accuracy is: 0.8034188034188035 and the number of correct results is: 188\n",
      " Iteration: 1260 , loss: 3.715971 Accuracy: 0.592000\n",
      " Iteration: 1270 , loss: 3.748330 Accuracy: 0.572000\n",
      " Iteration: 1280 , loss: 3.731583 Accuracy: 0.596000\n",
      " Iteration: 1290 , loss: 3.713695 Accuracy: 0.596000\n",
      " Iteration: 1300 , loss: 3.735334 Accuracy: 0.580000\n",
      "The postprocessing average accuracy is: 0.8076923076923077 and the number of correct results is: 189\n",
      " Iteration: 1310 , loss: 3.710621 Accuracy: 0.644000\n",
      " Iteration: 1320 , loss: 3.738598 Accuracy: 0.560000\n",
      " Iteration: 1330 , loss: 3.768193 Accuracy: 0.548000\n",
      " Iteration: 1340 , loss: 3.750720 Accuracy: 0.548000\n",
      " Iteration: 1350 , loss: 3.736743 Accuracy: 0.584000\n",
      "The postprocessing average accuracy is: 0.7905982905982906 and the number of correct results is: 185\n",
      " Iteration: 1360 , loss: 3.750575 Accuracy: 0.572000\n",
      " Iteration: 1370 , loss: 3.709238 Accuracy: 0.612000\n",
      " Iteration: 1380 , loss: 3.758913 Accuracy: 0.548000\n",
      " Iteration: 1390 , loss: 3.749367 Accuracy: 0.560000\n",
      " Iteration: 1400 , loss: 3.746385 Accuracy: 0.604000\n",
      "The postprocessing average accuracy is: 0.7991452991452992 and the number of correct results is: 187\n",
      " Iteration: 1410 , loss: 3.732928 Accuracy: 0.588000\n",
      " Iteration: 1420 , loss: 3.716811 Accuracy: 0.612000\n",
      " Iteration: 1430 , loss: 3.743226 Accuracy: 0.568000\n",
      " Iteration: 1440 , loss: 3.724652 Accuracy: 0.600000\n",
      " Iteration: 1450 , loss: 3.764096 Accuracy: 0.544000\n",
      "The postprocessing average accuracy is: 0.8076923076923077 and the number of correct results is: 189\n",
      " Iteration: 1460 , loss: 3.712510 Accuracy: 0.612000\n",
      " Iteration: 1470 , loss: 3.736884 Accuracy: 0.592000\n",
      " Iteration: 1480 , loss: 3.722586 Accuracy: 0.600000\n",
      " Iteration: 1490 , loss: 3.723480 Accuracy: 0.580000\n",
      " Iteration: 1500 , loss: 3.724938 Accuracy: 0.604000\n",
      "The postprocessing average accuracy is: 0.8205128205128205 and the number of correct results is: 192\n",
      " Iteration: 1510 , loss: 3.719956 Accuracy: 0.592000\n",
      " Iteration: 1520 , loss: 3.730711 Accuracy: 0.596000\n",
      " Iteration: 1530 , loss: 3.732220 Accuracy: 0.592000\n",
      " Iteration: 1540 , loss: 3.741395 Accuracy: 0.548000\n",
      " Iteration: 1550 , loss: 3.725202 Accuracy: 0.620000\n",
      "The postprocessing average accuracy is: 0.8162393162393162 and the number of correct results is: 191\n",
      " Iteration: 1560 , loss: 3.705216 Accuracy: 0.608000\n",
      " Iteration: 1570 , loss: 3.693583 Accuracy: 0.644000\n",
      " Iteration: 1580 , loss: 3.742182 Accuracy: 0.540000\n",
      " Iteration: 1590 , loss: 3.698173 Accuracy: 0.624000\n",
      " Iteration: 1600 , loss: 3.723269 Accuracy: 0.576000\n",
      "The postprocessing average accuracy is: 0.811965811965812 and the number of correct results is: 190\n",
      " Iteration: 1610 , loss: 3.683959 Accuracy: 0.640000\n",
      " Iteration: 1620 , loss: 3.718522 Accuracy: 0.588000\n",
      " Iteration: 1630 , loss: 3.724230 Accuracy: 0.580000\n",
      " Iteration: 1640 , loss: 3.713821 Accuracy: 0.628000\n",
      " Iteration: 1650 , loss: 3.686090 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.811965811965812 and the number of correct results is: 190\n",
      " Iteration: 1660 , loss: 3.725488 Accuracy: 0.592000\n",
      " Iteration: 1670 , loss: 3.701142 Accuracy: 0.600000\n",
      " Iteration: 1680 , loss: 3.719207 Accuracy: 0.564000\n",
      " Iteration: 1690 , loss: 3.688431 Accuracy: 0.620000\n",
      " Iteration: 1700 , loss: 3.650062 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8076923076923077 and the number of correct results is: 189\n",
      " Iteration: 1710 , loss: 3.675972 Accuracy: 0.668000\n",
      " Iteration: 1720 , loss: 3.728387 Accuracy: 0.584000\n",
      " Iteration: 1730 , loss: 3.736907 Accuracy: 0.588000\n",
      " Iteration: 1740 , loss: 3.701969 Accuracy: 0.632000\n",
      " Iteration: 1750 , loss: 3.670093 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8290598290598291 and the number of correct results is: 194\n",
      " Iteration: 1760 , loss: 3.651396 Accuracy: 0.636000\n",
      " Iteration: 1770 , loss: 3.682247 Accuracy: 0.620000\n",
      " Iteration: 1780 , loss: 3.700071 Accuracy: 0.596000\n",
      " Iteration: 1790 , loss: 3.698331 Accuracy: 0.608000\n",
      " Iteration: 1800 , loss: 3.651553 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8290598290598291 and the number of correct results is: 194\n",
      " Iteration: 1810 , loss: 3.691626 Accuracy: 0.632000\n",
      " Iteration: 1820 , loss: 3.715811 Accuracy: 0.600000\n",
      " Iteration: 1830 , loss: 3.700431 Accuracy: 0.580000\n",
      " Iteration: 1840 , loss: 3.713936 Accuracy: 0.604000\n",
      " Iteration: 1850 , loss: 3.643821 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8247863247863247 and the number of correct results is: 193\n",
      " Iteration: 1860 , loss: 3.715851 Accuracy: 0.580000\n",
      " Iteration: 1870 , loss: 3.655046 Accuracy: 0.624000\n",
      " Iteration: 1880 , loss: 3.701573 Accuracy: 0.628000\n",
      " Iteration: 1890 , loss: 3.661893 Accuracy: 0.652000\n",
      " Iteration: 1900 , loss: 3.661780 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8247863247863247 and the number of correct results is: 193\n",
      " Iteration: 1910 , loss: 3.681184 Accuracy: 0.608000\n",
      " Iteration: 1920 , loss: 3.663446 Accuracy: 0.644000\n",
      " Iteration: 1930 , loss: 3.695040 Accuracy: 0.588000\n",
      " Iteration: 1940 , loss: 3.683499 Accuracy: 0.664000\n",
      " Iteration: 1950 , loss: 3.671799 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8162393162393162 and the number of correct results is: 191\n",
      " Iteration: 1960 , loss: 3.661735 Accuracy: 0.668000\n",
      " Iteration: 1970 , loss: 3.653517 Accuracy: 0.652000\n",
      " Iteration: 1980 , loss: 3.670761 Accuracy: 0.616000\n",
      " Iteration: 1990 , loss: 3.686594 Accuracy: 0.592000\n",
      " Iteration: 2000 , loss: 3.683852 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8418803418803419 and the number of correct results is: 197\n",
      " Iteration: 2010 , loss: 3.663398 Accuracy: 0.652000\n",
      " Iteration: 2020 , loss: 3.657496 Accuracy: 0.620000\n",
      " Iteration: 2030 , loss: 3.686385 Accuracy: 0.596000\n",
      " Iteration: 2040 , loss: 3.666795 Accuracy: 0.652000\n",
      " Iteration: 2050 , loss: 3.616967 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8162393162393162 and the number of correct results is: 191\n",
      " Iteration: 2060 , loss: 3.694019 Accuracy: 0.608000\n",
      " Iteration: 2070 , loss: 3.698221 Accuracy: 0.584000\n",
      " Iteration: 2080 , loss: 3.647315 Accuracy: 0.676000\n",
      " Iteration: 2090 , loss: 3.690447 Accuracy: 0.636000\n",
      " Iteration: 2100 , loss: 3.680955 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8376068376068376 and the number of correct results is: 196\n",
      " Iteration: 2110 , loss: 3.649031 Accuracy: 0.688000\n",
      " Iteration: 2120 , loss: 3.661699 Accuracy: 0.604000\n",
      " Iteration: 2130 , loss: 3.689573 Accuracy: 0.604000\n",
      " Iteration: 2140 , loss: 3.690014 Accuracy: 0.612000\n",
      " Iteration: 2150 , loss: 3.656411 Accuracy: 0.628000\n",
      "The postprocessing average accuracy is: 0.8376068376068376 and the number of correct results is: 196\n",
      " Iteration: 2160 , loss: 3.652649 Accuracy: 0.676000\n",
      " Iteration: 2170 , loss: 3.647696 Accuracy: 0.668000\n",
      " Iteration: 2180 , loss: 3.691457 Accuracy: 0.600000\n",
      " Iteration: 2190 , loss: 3.678723 Accuracy: 0.668000\n",
      " Iteration: 2200 , loss: 3.714023 Accuracy: 0.588000\n",
      "The postprocessing average accuracy is: 0.8632478632478633 and the number of correct results is: 202\n",
      " Iteration: 2210 , loss: 3.652447 Accuracy: 0.636000\n",
      " Iteration: 2220 , loss: 3.691859 Accuracy: 0.576000\n",
      " Iteration: 2230 , loss: 3.700316 Accuracy: 0.576000\n",
      " Iteration: 2240 , loss: 3.687863 Accuracy: 0.600000\n",
      " Iteration: 2250 , loss: 3.696773 Accuracy: 0.608000\n",
      "The postprocessing average accuracy is: 0.8376068376068376 and the number of correct results is: 196\n",
      " Iteration: 2260 , loss: 3.652832 Accuracy: 0.672000\n",
      " Iteration: 2270 , loss: 3.692517 Accuracy: 0.616000\n",
      " Iteration: 2280 , loss: 3.623524 Accuracy: 0.688000\n",
      " Iteration: 2290 , loss: 3.681588 Accuracy: 0.632000\n",
      " Iteration: 2300 , loss: 3.671859 Accuracy: 0.648000\n",
      "The postprocessing average accuracy is: 0.8504273504273504 and the number of correct results is: 199\n",
      " Iteration: 2310 , loss: 3.661935 Accuracy: 0.680000\n",
      " Iteration: 2320 , loss: 3.661693 Accuracy: 0.640000\n",
      " Iteration: 2330 , loss: 3.657104 Accuracy: 0.692000\n",
      " Iteration: 2340 , loss: 3.676898 Accuracy: 0.632000\n",
      " Iteration: 2350 , loss: 3.664038 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8205128205128205 and the number of correct results is: 192\n",
      " Iteration: 2360 , loss: 3.644036 Accuracy: 0.636000\n",
      " Iteration: 2370 , loss: 3.614931 Accuracy: 0.684000\n",
      " Iteration: 2380 , loss: 3.719018 Accuracy: 0.576000\n",
      " Iteration: 2390 , loss: 3.660135 Accuracy: 0.660000\n",
      " Iteration: 2400 , loss: 3.691650 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 2410 , loss: 3.668581 Accuracy: 0.632000\n",
      " Iteration: 2420 , loss: 3.626254 Accuracy: 0.692000\n",
      " Iteration: 2430 , loss: 3.655084 Accuracy: 0.656000\n",
      " Iteration: 2440 , loss: 3.659593 Accuracy: 0.632000\n",
      " Iteration: 2450 , loss: 3.643566 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8247863247863247 and the number of correct results is: 193\n",
      " Iteration: 2460 , loss: 3.660969 Accuracy: 0.672000\n",
      " Iteration: 2470 , loss: 3.636681 Accuracy: 0.676000\n",
      " Iteration: 2480 , loss: 3.631049 Accuracy: 0.676000\n",
      " Iteration: 2490 , loss: 3.657781 Accuracy: 0.660000\n",
      " Iteration: 2500 , loss: 3.673419 Accuracy: 0.644000\n",
      "The postprocessing average accuracy is: 0.8418803418803419 and the number of correct results is: 197\n",
      " Iteration: 2510 , loss: 3.639941 Accuracy: 0.684000\n",
      " Iteration: 2520 , loss: 3.659355 Accuracy: 0.660000\n",
      " Iteration: 2530 , loss: 3.645268 Accuracy: 0.640000\n",
      " Iteration: 2540 , loss: 3.594067 Accuracy: 0.720000\n",
      " Iteration: 2550 , loss: 3.701933 Accuracy: 0.600000\n",
      "The postprocessing average accuracy is: 0.8504273504273504 and the number of correct results is: 199\n",
      " Iteration: 2560 , loss: 3.632323 Accuracy: 0.644000\n",
      " Iteration: 2570 , loss: 3.626132 Accuracy: 0.684000\n",
      " Iteration: 2580 , loss: 3.618972 Accuracy: 0.656000\n",
      " Iteration: 2590 , loss: 3.679313 Accuracy: 0.640000\n",
      " Iteration: 2600 , loss: 3.635934 Accuracy: 0.656000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 2610 , loss: 3.660699 Accuracy: 0.648000\n",
      " Iteration: 2620 , loss: 3.685704 Accuracy: 0.632000\n",
      " Iteration: 2630 , loss: 3.680110 Accuracy: 0.668000\n",
      " Iteration: 2640 , loss: 3.648363 Accuracy: 0.648000\n",
      " Iteration: 2650 , loss: 3.631611 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 2660 , loss: 3.654615 Accuracy: 0.644000\n",
      " Iteration: 2670 , loss: 3.613980 Accuracy: 0.676000\n",
      " Iteration: 2680 , loss: 3.613187 Accuracy: 0.680000\n",
      " Iteration: 2690 , loss: 3.648234 Accuracy: 0.672000\n",
      " Iteration: 2700 , loss: 3.672368 Accuracy: 0.636000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 2710 , loss: 3.671328 Accuracy: 0.644000\n",
      " Iteration: 2720 , loss: 3.629033 Accuracy: 0.708000\n",
      " Iteration: 2730 , loss: 3.628609 Accuracy: 0.648000\n",
      " Iteration: 2740 , loss: 3.665849 Accuracy: 0.644000\n",
      " Iteration: 2750 , loss: 3.680030 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.8333333333333334 and the number of correct results is: 195\n",
      " Iteration: 2760 , loss: 3.634217 Accuracy: 0.636000\n",
      " Iteration: 2770 , loss: 3.646033 Accuracy: 0.668000\n",
      " Iteration: 2780 , loss: 3.634227 Accuracy: 0.652000\n",
      " Iteration: 2790 , loss: 3.663841 Accuracy: 0.648000\n",
      " Iteration: 2800 , loss: 3.645943 Accuracy: 0.656000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 2810 , loss: 3.672625 Accuracy: 0.628000\n",
      " Iteration: 2820 , loss: 3.626840 Accuracy: 0.688000\n",
      " Iteration: 2830 , loss: 3.651923 Accuracy: 0.652000\n",
      " Iteration: 2840 , loss: 3.597908 Accuracy: 0.700000\n",
      " Iteration: 2850 , loss: 3.670091 Accuracy: 0.624000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 2860 , loss: 3.670270 Accuracy: 0.664000\n",
      " Iteration: 2870 , loss: 3.618889 Accuracy: 0.700000\n",
      " Iteration: 2880 , loss: 3.605153 Accuracy: 0.716000\n",
      " Iteration: 2890 , loss: 3.618196 Accuracy: 0.696000\n",
      " Iteration: 2900 , loss: 3.627514 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8333333333333334 and the number of correct results is: 195\n",
      " Iteration: 2910 , loss: 3.625383 Accuracy: 0.660000\n",
      " Iteration: 2920 , loss: 3.623375 Accuracy: 0.704000\n",
      " Iteration: 2930 , loss: 3.645877 Accuracy: 0.672000\n",
      " Iteration: 2940 , loss: 3.648077 Accuracy: 0.648000\n",
      " Iteration: 2950 , loss: 3.641379 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 2960 , loss: 3.624886 Accuracy: 0.680000\n",
      " Iteration: 2970 , loss: 3.626560 Accuracy: 0.652000\n",
      " Iteration: 2980 , loss: 3.632012 Accuracy: 0.648000\n",
      " Iteration: 2990 , loss: 3.602103 Accuracy: 0.704000\n",
      " Iteration: 3000 , loss: 3.634649 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 3010 , loss: 3.630018 Accuracy: 0.644000\n",
      " Iteration: 3020 , loss: 3.625757 Accuracy: 0.704000\n",
      " Iteration: 3030 , loss: 3.664463 Accuracy: 0.664000\n",
      " Iteration: 3040 , loss: 3.608740 Accuracy: 0.680000\n",
      " Iteration: 3050 , loss: 3.583280 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8504273504273504 and the number of correct results is: 199\n",
      " Iteration: 3060 , loss: 3.584072 Accuracy: 0.740000\n",
      " Iteration: 3070 , loss: 3.623654 Accuracy: 0.676000\n",
      " Iteration: 3080 , loss: 3.643151 Accuracy: 0.664000\n",
      " Iteration: 3090 , loss: 3.663622 Accuracy: 0.652000\n",
      " Iteration: 3100 , loss: 3.589919 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8589743589743589 and the number of correct results is: 201\n",
      " Iteration: 3110 , loss: 3.641050 Accuracy: 0.644000\n",
      " Iteration: 3120 , loss: 3.637407 Accuracy: 0.688000\n",
      " Iteration: 3130 , loss: 3.610900 Accuracy: 0.660000\n",
      " Iteration: 3140 , loss: 3.656396 Accuracy: 0.620000\n",
      " Iteration: 3150 , loss: 3.634826 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8632478632478633 and the number of correct results is: 202\n",
      " Iteration: 3160 , loss: 3.641124 Accuracy: 0.648000\n",
      " Iteration: 3170 , loss: 3.670456 Accuracy: 0.620000\n",
      " Iteration: 3180 , loss: 3.596588 Accuracy: 0.672000\n",
      " Iteration: 3190 , loss: 3.646325 Accuracy: 0.648000\n",
      " Iteration: 3200 , loss: 3.636304 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8632478632478633 and the number of correct results is: 202\n",
      " Iteration: 3210 , loss: 3.593280 Accuracy: 0.704000\n",
      " Iteration: 3220 , loss: 3.593455 Accuracy: 0.720000\n",
      " Iteration: 3230 , loss: 3.604309 Accuracy: 0.680000\n",
      " Iteration: 3240 , loss: 3.663729 Accuracy: 0.620000\n",
      " Iteration: 3250 , loss: 3.629685 Accuracy: 0.656000\n",
      "The postprocessing average accuracy is: 0.8547008547008547 and the number of correct results is: 200\n",
      " Iteration: 3260 , loss: 3.616679 Accuracy: 0.688000\n",
      " Iteration: 3270 , loss: 3.594402 Accuracy: 0.720000\n",
      " Iteration: 3280 , loss: 3.619133 Accuracy: 0.700000\n",
      " Iteration: 3290 , loss: 3.625764 Accuracy: 0.692000\n",
      " Iteration: 3300 , loss: 3.646557 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8547008547008547 and the number of correct results is: 200\n",
      " Iteration: 3310 , loss: 3.587970 Accuracy: 0.712000\n",
      " Iteration: 3320 , loss: 3.649169 Accuracy: 0.648000\n",
      " Iteration: 3330 , loss: 3.652652 Accuracy: 0.652000\n",
      " Iteration: 3340 , loss: 3.646206 Accuracy: 0.664000\n",
      " Iteration: 3350 , loss: 3.627930 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 3360 , loss: 3.605336 Accuracy: 0.672000\n",
      " Iteration: 3370 , loss: 3.654297 Accuracy: 0.668000\n",
      " Iteration: 3380 , loss: 3.609789 Accuracy: 0.704000\n",
      " Iteration: 3390 , loss: 3.618293 Accuracy: 0.652000\n",
      " Iteration: 3400 , loss: 3.568370 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8376068376068376 and the number of correct results is: 196\n",
      " Iteration: 3410 , loss: 3.607816 Accuracy: 0.704000\n",
      " Iteration: 3420 , loss: 3.651406 Accuracy: 0.648000\n",
      " Iteration: 3430 , loss: 3.617002 Accuracy: 0.720000\n",
      " Iteration: 3440 , loss: 3.616515 Accuracy: 0.672000\n",
      " Iteration: 3450 , loss: 3.638258 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 3460 , loss: 3.621797 Accuracy: 0.664000\n",
      " Iteration: 3470 , loss: 3.567743 Accuracy: 0.752000\n",
      " Iteration: 3480 , loss: 3.625302 Accuracy: 0.680000\n",
      " Iteration: 3490 , loss: 3.651325 Accuracy: 0.672000\n",
      " Iteration: 3500 , loss: 3.633356 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 3510 , loss: 3.598368 Accuracy: 0.716000\n",
      " Iteration: 3520 , loss: 3.622773 Accuracy: 0.652000\n",
      " Iteration: 3530 , loss: 3.612879 Accuracy: 0.684000\n",
      " Iteration: 3540 , loss: 3.602682 Accuracy: 0.692000\n",
      " Iteration: 3550 , loss: 3.589354 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8418803418803419 and the number of correct results is: 197\n",
      " Iteration: 3560 , loss: 3.635679 Accuracy: 0.656000\n",
      " Iteration: 3570 , loss: 3.599376 Accuracy: 0.684000\n",
      " Iteration: 3580 , loss: 3.644541 Accuracy: 0.604000\n",
      " Iteration: 3590 , loss: 3.579402 Accuracy: 0.736000\n",
      " Iteration: 3600 , loss: 3.641429 Accuracy: 0.656000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 3610 , loss: 3.612868 Accuracy: 0.656000\n",
      " Iteration: 3620 , loss: 3.597008 Accuracy: 0.696000\n",
      " Iteration: 3630 , loss: 3.635587 Accuracy: 0.664000\n",
      " Iteration: 3640 , loss: 3.660697 Accuracy: 0.612000\n",
      " Iteration: 3650 , loss: 3.561643 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8717948717948718 and the number of correct results is: 204\n",
      " Iteration: 3660 , loss: 3.629789 Accuracy: 0.684000\n",
      " Iteration: 3670 , loss: 3.574526 Accuracy: 0.720000\n",
      " Iteration: 3680 , loss: 3.600305 Accuracy: 0.692000\n",
      " Iteration: 3690 , loss: 3.587388 Accuracy: 0.716000\n",
      " Iteration: 3700 , loss: 3.626411 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8418803418803419 and the number of correct results is: 197\n",
      " Iteration: 3710 , loss: 3.589451 Accuracy: 0.684000\n",
      " Iteration: 3720 , loss: 3.643381 Accuracy: 0.660000\n",
      " Iteration: 3730 , loss: 3.585832 Accuracy: 0.748000\n",
      " Iteration: 3740 , loss: 3.630321 Accuracy: 0.676000\n",
      " Iteration: 3750 , loss: 3.618966 Accuracy: 0.656000\n",
      "The postprocessing average accuracy is: 0.8547008547008547 and the number of correct results is: 200\n",
      " Iteration: 3760 , loss: 3.616642 Accuracy: 0.688000\n",
      " Iteration: 3770 , loss: 3.583028 Accuracy: 0.716000\n",
      " Iteration: 3780 , loss: 3.592173 Accuracy: 0.672000\n",
      " Iteration: 3790 , loss: 3.595822 Accuracy: 0.708000\n",
      " Iteration: 3800 , loss: 3.626904 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 3810 , loss: 3.638358 Accuracy: 0.620000\n",
      " Iteration: 3820 , loss: 3.564820 Accuracy: 0.712000\n",
      " Iteration: 3830 , loss: 3.603911 Accuracy: 0.700000\n",
      " Iteration: 3840 , loss: 3.656925 Accuracy: 0.640000\n",
      " Iteration: 3850 , loss: 3.572144 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8589743589743589 and the number of correct results is: 201\n",
      " Iteration: 3860 , loss: 3.610237 Accuracy: 0.684000\n",
      " Iteration: 3870 , loss: 3.642812 Accuracy: 0.628000\n",
      " Iteration: 3880 , loss: 3.613470 Accuracy: 0.688000\n",
      " Iteration: 3890 , loss: 3.617319 Accuracy: 0.676000\n",
      " Iteration: 3900 , loss: 3.583179 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 3910 , loss: 3.613763 Accuracy: 0.708000\n",
      " Iteration: 3920 , loss: 3.617488 Accuracy: 0.708000\n",
      " Iteration: 3930 , loss: 3.592716 Accuracy: 0.716000\n",
      " Iteration: 3940 , loss: 3.577552 Accuracy: 0.704000\n",
      " Iteration: 3950 , loss: 3.597414 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8504273504273504 and the number of correct results is: 199\n",
      " Iteration: 3960 , loss: 3.599536 Accuracy: 0.704000\n",
      " Iteration: 3970 , loss: 3.613254 Accuracy: 0.712000\n",
      " Iteration: 3980 , loss: 3.641665 Accuracy: 0.620000\n",
      " Iteration: 3990 , loss: 3.579874 Accuracy: 0.724000\n",
      " Iteration: 4000 , loss: 3.573872 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8632478632478633 and the number of correct results is: 202\n",
      " Iteration: 4010 , loss: 3.592121 Accuracy: 0.700000\n",
      " Iteration: 4020 , loss: 3.606502 Accuracy: 0.668000\n",
      " Iteration: 4030 , loss: 3.603432 Accuracy: 0.692000\n",
      " Iteration: 4040 , loss: 3.608101 Accuracy: 0.700000\n",
      " Iteration: 4050 , loss: 3.599220 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 4060 , loss: 3.555041 Accuracy: 0.740000\n",
      " Iteration: 4070 , loss: 3.609085 Accuracy: 0.668000\n",
      " Iteration: 4080 , loss: 3.642632 Accuracy: 0.648000\n",
      " Iteration: 4090 , loss: 3.607849 Accuracy: 0.704000\n",
      " Iteration: 4100 , loss: 3.560781 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 4110 , loss: 3.609721 Accuracy: 0.708000\n",
      " Iteration: 4120 , loss: 3.578528 Accuracy: 0.712000\n",
      " Iteration: 4130 , loss: 3.600909 Accuracy: 0.668000\n",
      " Iteration: 4140 , loss: 3.621848 Accuracy: 0.696000\n",
      " Iteration: 4150 , loss: 3.585490 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 4160 , loss: 3.594412 Accuracy: 0.692000\n",
      " Iteration: 4170 , loss: 3.621085 Accuracy: 0.704000\n",
      " Iteration: 4180 , loss: 3.608883 Accuracy: 0.680000\n",
      " Iteration: 4190 , loss: 3.562311 Accuracy: 0.756000\n",
      " Iteration: 4200 , loss: 3.626997 Accuracy: 0.648000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 4210 , loss: 3.583314 Accuracy: 0.692000\n",
      " Iteration: 4220 , loss: 3.568308 Accuracy: 0.720000\n",
      " Iteration: 4230 , loss: 3.587995 Accuracy: 0.728000\n",
      " Iteration: 4240 , loss: 3.563625 Accuracy: 0.744000\n",
      " Iteration: 4250 , loss: 3.577502 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8632478632478633 and the number of correct results is: 202\n",
      " Iteration: 4260 , loss: 3.580229 Accuracy: 0.676000\n",
      " Iteration: 4270 , loss: 3.561461 Accuracy: 0.744000\n",
      " Iteration: 4280 , loss: 3.570295 Accuracy: 0.732000\n",
      " Iteration: 4290 , loss: 3.599013 Accuracy: 0.688000\n",
      " Iteration: 4300 , loss: 3.605504 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 4310 , loss: 3.576470 Accuracy: 0.716000\n",
      " Iteration: 4320 , loss: 3.552444 Accuracy: 0.736000\n",
      " Iteration: 4330 , loss: 3.570070 Accuracy: 0.700000\n",
      " Iteration: 4340 , loss: 3.582960 Accuracy: 0.708000\n",
      " Iteration: 4350 , loss: 3.598292 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8717948717948718 and the number of correct results is: 204\n",
      " Iteration: 4360 , loss: 3.583360 Accuracy: 0.696000\n",
      " Iteration: 4370 , loss: 3.622992 Accuracy: 0.668000\n",
      " Iteration: 4380 , loss: 3.609565 Accuracy: 0.696000\n",
      " Iteration: 4390 , loss: 3.620774 Accuracy: 0.680000\n",
      " Iteration: 4400 , loss: 3.569732 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8589743589743589 and the number of correct results is: 201\n",
      " Iteration: 4410 , loss: 3.569524 Accuracy: 0.696000\n",
      " Iteration: 4420 , loss: 3.574381 Accuracy: 0.704000\n",
      " Iteration: 4430 , loss: 3.561365 Accuracy: 0.716000\n",
      " Iteration: 4440 , loss: 3.576846 Accuracy: 0.716000\n",
      " Iteration: 4450 , loss: 3.568136 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 4460 , loss: 3.597812 Accuracy: 0.708000\n",
      " Iteration: 4470 , loss: 3.539812 Accuracy: 0.752000\n",
      " Iteration: 4480 , loss: 3.574484 Accuracy: 0.732000\n",
      " Iteration: 4490 , loss: 3.570651 Accuracy: 0.724000\n",
      " Iteration: 4500 , loss: 3.604116 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 4510 , loss: 3.595352 Accuracy: 0.708000\n",
      " Iteration: 4520 , loss: 3.608503 Accuracy: 0.712000\n",
      " Iteration: 4530 , loss: 3.614467 Accuracy: 0.692000\n",
      " Iteration: 4540 , loss: 3.584339 Accuracy: 0.696000\n",
      " Iteration: 4550 , loss: 3.576097 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 4560 , loss: 3.593594 Accuracy: 0.708000\n",
      " Iteration: 4570 , loss: 3.550529 Accuracy: 0.732000\n",
      " Iteration: 4580 , loss: 3.580096 Accuracy: 0.708000\n",
      " Iteration: 4590 , loss: 3.602363 Accuracy: 0.724000\n",
      " Iteration: 4600 , loss: 3.568612 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 4610 , loss: 3.540061 Accuracy: 0.752000\n",
      " Iteration: 4620 , loss: 3.535850 Accuracy: 0.792000\n",
      " Iteration: 4630 , loss: 3.552801 Accuracy: 0.736000\n",
      " Iteration: 4640 , loss: 3.572562 Accuracy: 0.732000\n",
      " Iteration: 4650 , loss: 3.584282 Accuracy: 0.664000\n",
      "The postprocessing average accuracy is: 0.8632478632478633 and the number of correct results is: 202\n",
      " Iteration: 4660 , loss: 3.558400 Accuracy: 0.736000\n",
      " Iteration: 4670 , loss: 3.589656 Accuracy: 0.680000\n",
      " Iteration: 4680 , loss: 3.594162 Accuracy: 0.700000\n",
      " Iteration: 4690 , loss: 3.563148 Accuracy: 0.692000\n",
      " Iteration: 4700 , loss: 3.601599 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 4710 , loss: 3.564871 Accuracy: 0.724000\n",
      " Iteration: 4720 , loss: 3.603074 Accuracy: 0.704000\n",
      " Iteration: 4730 , loss: 3.557799 Accuracy: 0.736000\n",
      " Iteration: 4740 , loss: 3.549295 Accuracy: 0.748000\n",
      " Iteration: 4750 , loss: 3.607034 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8717948717948718 and the number of correct results is: 204\n",
      " Iteration: 4760 , loss: 3.567937 Accuracy: 0.748000\n",
      " Iteration: 4770 , loss: 3.585127 Accuracy: 0.700000\n",
      " Iteration: 4780 , loss: 3.604796 Accuracy: 0.708000\n",
      " Iteration: 4790 , loss: 3.547873 Accuracy: 0.732000\n",
      " Iteration: 4800 , loss: 3.571930 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8461538461538461 and the number of correct results is: 198\n",
      " Iteration: 4810 , loss: 3.584749 Accuracy: 0.712000\n",
      " Iteration: 4820 , loss: 3.576976 Accuracy: 0.740000\n",
      " Iteration: 4830 , loss: 3.571358 Accuracy: 0.704000\n",
      " Iteration: 4840 , loss: 3.592752 Accuracy: 0.712000\n",
      " Iteration: 4850 , loss: 3.579602 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 4860 , loss: 3.548721 Accuracy: 0.740000\n",
      " Iteration: 4870 , loss: 3.580366 Accuracy: 0.708000\n",
      " Iteration: 4880 , loss: 3.584439 Accuracy: 0.736000\n",
      " Iteration: 4890 , loss: 3.573836 Accuracy: 0.680000\n",
      " Iteration: 4900 , loss: 3.558339 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 4910 , loss: 3.571696 Accuracy: 0.692000\n",
      " Iteration: 4920 , loss: 3.607783 Accuracy: 0.672000\n",
      " Iteration: 4930 , loss: 3.552797 Accuracy: 0.728000\n",
      " Iteration: 4940 , loss: 3.588427 Accuracy: 0.708000\n",
      " Iteration: 4950 , loss: 3.570891 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 4960 , loss: 3.568396 Accuracy: 0.720000\n",
      " Iteration: 4970 , loss: 3.583849 Accuracy: 0.712000\n",
      " Iteration: 4980 , loss: 3.554252 Accuracy: 0.760000\n",
      " Iteration: 4990 , loss: 3.569063 Accuracy: 0.748000\n",
      " Iteration: 5000 , loss: 3.563747 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 5010 , loss: 3.576966 Accuracy: 0.736000\n",
      " Iteration: 5020 , loss: 3.618018 Accuracy: 0.680000\n",
      " Iteration: 5030 , loss: 3.582558 Accuracy: 0.676000\n",
      " Iteration: 5040 , loss: 3.582429 Accuracy: 0.716000\n",
      " Iteration: 5050 , loss: 3.571202 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 5060 , loss: 3.589315 Accuracy: 0.680000\n",
      " Iteration: 5070 , loss: 3.596860 Accuracy: 0.684000\n",
      " Iteration: 5080 , loss: 3.537317 Accuracy: 0.744000\n",
      " Iteration: 5090 , loss: 3.576369 Accuracy: 0.692000\n",
      " Iteration: 5100 , loss: 3.607745 Accuracy: 0.664000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 5110 , loss: 3.554010 Accuracy: 0.748000\n",
      " Iteration: 5120 , loss: 3.544232 Accuracy: 0.736000\n",
      " Iteration: 5130 , loss: 3.592302 Accuracy: 0.716000\n",
      " Iteration: 5140 , loss: 3.595586 Accuracy: 0.692000\n",
      " Iteration: 5150 , loss: 3.531038 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8589743589743589 and the number of correct results is: 201\n",
      " Iteration: 5160 , loss: 3.557228 Accuracy: 0.700000\n",
      " Iteration: 5170 , loss: 3.593532 Accuracy: 0.688000\n",
      " Iteration: 5180 , loss: 3.542781 Accuracy: 0.748000\n",
      " Iteration: 5190 , loss: 3.596343 Accuracy: 0.704000\n",
      " Iteration: 5200 , loss: 3.582941 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8547008547008547 and the number of correct results is: 200\n",
      " Iteration: 5210 , loss: 3.564131 Accuracy: 0.732000\n",
      " Iteration: 5220 , loss: 3.545712 Accuracy: 0.732000\n",
      " Iteration: 5230 , loss: 3.589601 Accuracy: 0.680000\n",
      " Iteration: 5240 , loss: 3.611916 Accuracy: 0.680000\n",
      " Iteration: 5250 , loss: 3.541614 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 5260 , loss: 3.573020 Accuracy: 0.740000\n",
      " Iteration: 5270 , loss: 3.567981 Accuracy: 0.704000\n",
      " Iteration: 5280 , loss: 3.590834 Accuracy: 0.688000\n",
      " Iteration: 5290 , loss: 3.561022 Accuracy: 0.752000\n",
      " Iteration: 5300 , loss: 3.543987 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 5310 , loss: 3.537634 Accuracy: 0.748000\n",
      " Iteration: 5320 , loss: 3.542402 Accuracy: 0.752000\n",
      " Iteration: 5330 , loss: 3.560710 Accuracy: 0.696000\n",
      " Iteration: 5340 , loss: 3.545152 Accuracy: 0.756000\n",
      " Iteration: 5350 , loss: 3.577703 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 5360 , loss: 3.558129 Accuracy: 0.756000\n",
      " Iteration: 5370 , loss: 3.566713 Accuracy: 0.768000\n",
      " Iteration: 5380 , loss: 3.559550 Accuracy: 0.716000\n",
      " Iteration: 5390 , loss: 3.536121 Accuracy: 0.760000\n",
      " Iteration: 5400 , loss: 3.559443 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8675213675213675 and the number of correct results is: 203\n",
      " Iteration: 5410 , loss: 3.558465 Accuracy: 0.740000\n",
      " Iteration: 5420 , loss: 3.536685 Accuracy: 0.764000\n",
      " Iteration: 5430 , loss: 3.553615 Accuracy: 0.752000\n",
      " Iteration: 5440 , loss: 3.586840 Accuracy: 0.704000\n",
      " Iteration: 5450 , loss: 3.574060 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 5460 , loss: 3.552116 Accuracy: 0.744000\n",
      " Iteration: 5470 , loss: 3.587472 Accuracy: 0.692000\n",
      " Iteration: 5480 , loss: 3.570213 Accuracy: 0.736000\n",
      " Iteration: 5490 , loss: 3.556194 Accuracy: 0.732000\n",
      " Iteration: 5500 , loss: 3.531644 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 5510 , loss: 3.589483 Accuracy: 0.684000\n",
      " Iteration: 5520 , loss: 3.547787 Accuracy: 0.740000\n",
      " Iteration: 5530 , loss: 3.576069 Accuracy: 0.716000\n",
      " Iteration: 5540 , loss: 3.555982 Accuracy: 0.732000\n",
      " Iteration: 5550 , loss: 3.578506 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 5560 , loss: 3.561400 Accuracy: 0.728000\n",
      " Iteration: 5570 , loss: 3.548204 Accuracy: 0.764000\n",
      " Iteration: 5580 , loss: 3.540663 Accuracy: 0.744000\n",
      " Iteration: 5590 , loss: 3.568983 Accuracy: 0.724000\n",
      " Iteration: 5600 , loss: 3.520768 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 5610 , loss: 3.557365 Accuracy: 0.728000\n",
      " Iteration: 5620 , loss: 3.543822 Accuracy: 0.760000\n",
      " Iteration: 5630 , loss: 3.509697 Accuracy: 0.792000\n",
      " Iteration: 5640 , loss: 3.561569 Accuracy: 0.736000\n",
      " Iteration: 5650 , loss: 3.550231 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 5660 , loss: 3.553811 Accuracy: 0.736000\n",
      " Iteration: 5670 , loss: 3.574410 Accuracy: 0.712000\n",
      " Iteration: 5680 , loss: 3.573537 Accuracy: 0.708000\n",
      " Iteration: 5690 , loss: 3.551460 Accuracy: 0.752000\n",
      " Iteration: 5700 , loss: 3.538811 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 5710 , loss: 3.560980 Accuracy: 0.700000\n",
      " Iteration: 5720 , loss: 3.542080 Accuracy: 0.744000\n",
      " Iteration: 5730 , loss: 3.526928 Accuracy: 0.740000\n",
      " Iteration: 5740 , loss: 3.548356 Accuracy: 0.756000\n",
      " Iteration: 5750 , loss: 3.555199 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 5760 , loss: 3.499118 Accuracy: 0.772000\n",
      " Iteration: 5770 , loss: 3.563328 Accuracy: 0.740000\n",
      " Iteration: 5780 , loss: 3.580814 Accuracy: 0.716000\n",
      " Iteration: 5790 , loss: 3.560994 Accuracy: 0.704000\n",
      " Iteration: 5800 , loss: 3.540589 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 5810 , loss: 3.570898 Accuracy: 0.716000\n",
      " Iteration: 5820 , loss: 3.576141 Accuracy: 0.696000\n",
      " Iteration: 5830 , loss: 3.534417 Accuracy: 0.720000\n",
      " Iteration: 5840 , loss: 3.519104 Accuracy: 0.784000\n",
      " Iteration: 5850 , loss: 3.524947 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 5860 , loss: 3.534799 Accuracy: 0.772000\n",
      " Iteration: 5870 , loss: 3.540211 Accuracy: 0.752000\n",
      " Iteration: 5880 , loss: 3.568588 Accuracy: 0.720000\n",
      " Iteration: 5890 , loss: 3.574967 Accuracy: 0.736000\n",
      " Iteration: 5900 , loss: 3.542165 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8717948717948718 and the number of correct results is: 204\n",
      " Iteration: 5910 , loss: 3.520867 Accuracy: 0.784000\n",
      " Iteration: 5920 , loss: 3.549871 Accuracy: 0.736000\n",
      " Iteration: 5930 , loss: 3.530886 Accuracy: 0.728000\n",
      " Iteration: 5940 , loss: 3.532076 Accuracy: 0.756000\n",
      " Iteration: 5950 , loss: 3.561624 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 5960 , loss: 3.585441 Accuracy: 0.696000\n",
      " Iteration: 5970 , loss: 3.540988 Accuracy: 0.772000\n",
      " Iteration: 5980 , loss: 3.569204 Accuracy: 0.716000\n",
      " Iteration: 5990 , loss: 3.580634 Accuracy: 0.704000\n",
      " Iteration: 6000 , loss: 3.528172 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 6010 , loss: 3.571946 Accuracy: 0.692000\n",
      " Iteration: 6020 , loss: 3.513210 Accuracy: 0.764000\n",
      " Iteration: 6030 , loss: 3.522697 Accuracy: 0.768000\n",
      " Iteration: 6040 , loss: 3.546361 Accuracy: 0.736000\n",
      " Iteration: 6050 , loss: 3.574718 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 6060 , loss: 3.567301 Accuracy: 0.744000\n",
      " Iteration: 6070 , loss: 3.558643 Accuracy: 0.712000\n",
      " Iteration: 6080 , loss: 3.520802 Accuracy: 0.744000\n",
      " Iteration: 6090 , loss: 3.567156 Accuracy: 0.716000\n",
      " Iteration: 6100 , loss: 3.558537 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 6110 , loss: 3.551294 Accuracy: 0.732000\n",
      " Iteration: 6120 , loss: 3.531545 Accuracy: 0.748000\n",
      " Iteration: 6130 , loss: 3.584322 Accuracy: 0.684000\n",
      " Iteration: 6140 , loss: 3.525112 Accuracy: 0.772000\n",
      " Iteration: 6150 , loss: 3.508142 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 6160 , loss: 3.516441 Accuracy: 0.764000\n",
      " Iteration: 6170 , loss: 3.542686 Accuracy: 0.736000\n",
      " Iteration: 6180 , loss: 3.542646 Accuracy: 0.736000\n",
      " Iteration: 6190 , loss: 3.540896 Accuracy: 0.756000\n",
      " Iteration: 6200 , loss: 3.534179 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 6210 , loss: 3.555846 Accuracy: 0.704000\n",
      " Iteration: 6220 , loss: 3.507207 Accuracy: 0.764000\n",
      " Iteration: 6230 , loss: 3.546109 Accuracy: 0.744000\n",
      " Iteration: 6240 , loss: 3.541754 Accuracy: 0.748000\n",
      " Iteration: 6250 , loss: 3.512457 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 6260 , loss: 3.538613 Accuracy: 0.736000\n",
      " Iteration: 6270 , loss: 3.550344 Accuracy: 0.708000\n",
      " Iteration: 6280 , loss: 3.546812 Accuracy: 0.756000\n",
      " Iteration: 6290 , loss: 3.566339 Accuracy: 0.708000\n",
      " Iteration: 6300 , loss: 3.534999 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 6310 , loss: 3.563911 Accuracy: 0.736000\n",
      " Iteration: 6320 , loss: 3.492315 Accuracy: 0.780000\n",
      " Iteration: 6330 , loss: 3.564453 Accuracy: 0.692000\n",
      " Iteration: 6340 , loss: 3.554394 Accuracy: 0.752000\n",
      " Iteration: 6350 , loss: 3.525059 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 6360 , loss: 3.569520 Accuracy: 0.704000\n",
      " Iteration: 6370 , loss: 3.564902 Accuracy: 0.716000\n",
      " Iteration: 6380 , loss: 3.543641 Accuracy: 0.744000\n",
      " Iteration: 6390 , loss: 3.576869 Accuracy: 0.684000\n",
      " Iteration: 6400 , loss: 3.548065 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 6410 , loss: 3.541019 Accuracy: 0.740000\n",
      " Iteration: 6420 , loss: 3.514170 Accuracy: 0.756000\n",
      " Iteration: 6430 , loss: 3.567161 Accuracy: 0.724000\n",
      " Iteration: 6440 , loss: 3.519614 Accuracy: 0.764000\n",
      " Iteration: 6450 , loss: 3.556936 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 6460 , loss: 3.512877 Accuracy: 0.792000\n",
      " Iteration: 6470 , loss: 3.544997 Accuracy: 0.756000\n",
      " Iteration: 6480 , loss: 3.531150 Accuracy: 0.728000\n",
      " Iteration: 6490 , loss: 3.554334 Accuracy: 0.716000\n",
      " Iteration: 6500 , loss: 3.521705 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 6510 , loss: 3.527178 Accuracy: 0.780000\n",
      " Iteration: 6520 , loss: 3.561815 Accuracy: 0.704000\n",
      " Iteration: 6530 , loss: 3.530996 Accuracy: 0.748000\n",
      " Iteration: 6540 , loss: 3.578963 Accuracy: 0.688000\n",
      " Iteration: 6550 , loss: 3.536756 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 6560 , loss: 3.498125 Accuracy: 0.776000\n",
      " Iteration: 6570 , loss: 3.509991 Accuracy: 0.752000\n",
      " Iteration: 6580 , loss: 3.545673 Accuracy: 0.732000\n",
      " Iteration: 6590 , loss: 3.528361 Accuracy: 0.744000\n",
      " Iteration: 6600 , loss: 3.584648 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 6610 , loss: 3.582963 Accuracy: 0.656000\n",
      " Iteration: 6620 , loss: 3.557977 Accuracy: 0.712000\n",
      " Iteration: 6630 , loss: 3.540947 Accuracy: 0.748000\n",
      " Iteration: 6640 , loss: 3.585746 Accuracy: 0.700000\n",
      " Iteration: 6650 , loss: 3.544016 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 6660 , loss: 3.522135 Accuracy: 0.780000\n",
      " Iteration: 6670 , loss: 3.488937 Accuracy: 0.776000\n",
      " Iteration: 6680 , loss: 3.548927 Accuracy: 0.748000\n",
      " Iteration: 6690 , loss: 3.565408 Accuracy: 0.724000\n",
      " Iteration: 6700 , loss: 3.535202 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 6710 , loss: 3.542377 Accuracy: 0.724000\n",
      " Iteration: 6720 , loss: 3.592721 Accuracy: 0.640000\n",
      " Iteration: 6730 , loss: 3.538261 Accuracy: 0.732000\n",
      " Iteration: 6740 , loss: 3.533790 Accuracy: 0.772000\n",
      " Iteration: 6750 , loss: 3.556988 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 6760 , loss: 3.532194 Accuracy: 0.740000\n",
      " Iteration: 6770 , loss: 3.530140 Accuracy: 0.776000\n",
      " Iteration: 6780 , loss: 3.482357 Accuracy: 0.816000\n",
      " Iteration: 6790 , loss: 3.525725 Accuracy: 0.784000\n",
      " Iteration: 6800 , loss: 3.562539 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8717948717948718 and the number of correct results is: 204\n",
      " Iteration: 6810 , loss: 3.540354 Accuracy: 0.728000\n",
      " Iteration: 6820 , loss: 3.525572 Accuracy: 0.752000\n",
      " Iteration: 6830 , loss: 3.554256 Accuracy: 0.708000\n",
      " Iteration: 6840 , loss: 3.487683 Accuracy: 0.792000\n",
      " Iteration: 6850 , loss: 3.551365 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 6860 , loss: 3.515965 Accuracy: 0.772000\n",
      " Iteration: 6870 , loss: 3.535939 Accuracy: 0.756000\n",
      " Iteration: 6880 , loss: 3.538497 Accuracy: 0.756000\n",
      " Iteration: 6890 , loss: 3.555453 Accuracy: 0.724000\n",
      " Iteration: 6900 , loss: 3.530030 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 6910 , loss: 3.537316 Accuracy: 0.748000\n",
      " Iteration: 6920 , loss: 3.557971 Accuracy: 0.724000\n",
      " Iteration: 6930 , loss: 3.554003 Accuracy: 0.764000\n",
      " Iteration: 6940 , loss: 3.454432 Accuracy: 0.856000\n",
      " Iteration: 6950 , loss: 3.558121 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 6960 , loss: 3.548384 Accuracy: 0.728000\n",
      " Iteration: 6970 , loss: 3.547693 Accuracy: 0.736000\n",
      " Iteration: 6980 , loss: 3.526410 Accuracy: 0.744000\n",
      " Iteration: 6990 , loss: 3.560956 Accuracy: 0.732000\n",
      " Iteration: 7000 , loss: 3.517318 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 7010 , loss: 3.510568 Accuracy: 0.760000\n",
      " Iteration: 7020 , loss: 3.518349 Accuracy: 0.768000\n",
      " Iteration: 7030 , loss: 3.517418 Accuracy: 0.744000\n",
      " Iteration: 7040 , loss: 3.526915 Accuracy: 0.784000\n",
      " Iteration: 7050 , loss: 3.556081 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 7060 , loss: 3.537490 Accuracy: 0.732000\n",
      " Iteration: 7070 , loss: 3.515222 Accuracy: 0.756000\n",
      " Iteration: 7080 , loss: 3.533584 Accuracy: 0.740000\n",
      " Iteration: 7090 , loss: 3.560756 Accuracy: 0.796000\n",
      " Iteration: 7100 , loss: 3.493393 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 7110 , loss: 3.526617 Accuracy: 0.764000\n",
      " Iteration: 7120 , loss: 3.490413 Accuracy: 0.796000\n",
      " Iteration: 7130 , loss: 3.508139 Accuracy: 0.776000\n",
      " Iteration: 7140 , loss: 3.511362 Accuracy: 0.748000\n",
      " Iteration: 7150 , loss: 3.516557 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 7160 , loss: 3.495862 Accuracy: 0.796000\n",
      " Iteration: 7170 , loss: 3.531093 Accuracy: 0.756000\n",
      " Iteration: 7180 , loss: 3.517844 Accuracy: 0.776000\n",
      " Iteration: 7190 , loss: 3.529596 Accuracy: 0.752000\n",
      " Iteration: 7200 , loss: 3.533782 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 7210 , loss: 3.544327 Accuracy: 0.740000\n",
      " Iteration: 7220 , loss: 3.484944 Accuracy: 0.812000\n",
      " Iteration: 7230 , loss: 3.504587 Accuracy: 0.808000\n",
      " Iteration: 7240 , loss: 3.564367 Accuracy: 0.700000\n",
      " Iteration: 7250 , loss: 3.533613 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9230769230769231 and the number of correct results is: 216\n",
      " Iteration: 7260 , loss: 3.508545 Accuracy: 0.760000\n",
      " Iteration: 7270 , loss: 3.507858 Accuracy: 0.768000\n",
      " Iteration: 7280 , loss: 3.542777 Accuracy: 0.724000\n",
      " Iteration: 7290 , loss: 3.513504 Accuracy: 0.752000\n",
      " Iteration: 7300 , loss: 3.549008 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 7310 , loss: 3.539564 Accuracy: 0.724000\n",
      " Iteration: 7320 , loss: 3.534510 Accuracy: 0.756000\n",
      " Iteration: 7330 , loss: 3.501222 Accuracy: 0.768000\n",
      " Iteration: 7340 , loss: 3.511183 Accuracy: 0.768000\n",
      " Iteration: 7350 , loss: 3.564263 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 7360 , loss: 3.519082 Accuracy: 0.764000\n",
      " Iteration: 7370 , loss: 3.490474 Accuracy: 0.792000\n",
      " Iteration: 7380 , loss: 3.507595 Accuracy: 0.764000\n",
      " Iteration: 7390 , loss: 3.537246 Accuracy: 0.724000\n",
      " Iteration: 7400 , loss: 3.492647 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 7410 , loss: 3.521753 Accuracy: 0.768000\n",
      " Iteration: 7420 , loss: 3.537803 Accuracy: 0.756000\n",
      " Iteration: 7430 , loss: 3.493134 Accuracy: 0.768000\n",
      " Iteration: 7440 , loss: 3.536411 Accuracy: 0.740000\n",
      " Iteration: 7450 , loss: 3.556482 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 7460 , loss: 3.542780 Accuracy: 0.716000\n",
      " Iteration: 7470 , loss: 3.517895 Accuracy: 0.784000\n",
      " Iteration: 7480 , loss: 3.522147 Accuracy: 0.744000\n",
      " Iteration: 7490 , loss: 3.543007 Accuracy: 0.728000\n",
      " Iteration: 7500 , loss: 3.512698 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 7510 , loss: 3.546972 Accuracy: 0.728000\n",
      " Iteration: 7520 , loss: 3.540453 Accuracy: 0.728000\n",
      " Iteration: 7530 , loss: 3.508548 Accuracy: 0.752000\n",
      " Iteration: 7540 , loss: 3.516004 Accuracy: 0.740000\n",
      " Iteration: 7550 , loss: 3.511150 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 7560 , loss: 3.512622 Accuracy: 0.744000\n",
      " Iteration: 7570 , loss: 3.541263 Accuracy: 0.776000\n",
      " Iteration: 7580 , loss: 3.527645 Accuracy: 0.744000\n",
      " Iteration: 7590 , loss: 3.518424 Accuracy: 0.764000\n",
      " Iteration: 7600 , loss: 3.528793 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 7610 , loss: 3.531309 Accuracy: 0.736000\n",
      " Iteration: 7620 , loss: 3.534556 Accuracy: 0.740000\n",
      " Iteration: 7630 , loss: 3.516660 Accuracy: 0.768000\n",
      " Iteration: 7640 , loss: 3.539618 Accuracy: 0.756000\n",
      " Iteration: 7650 , loss: 3.513175 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 7660 , loss: 3.541203 Accuracy: 0.716000\n",
      " Iteration: 7670 , loss: 3.502034 Accuracy: 0.756000\n",
      " Iteration: 7680 , loss: 3.513236 Accuracy: 0.756000\n",
      " Iteration: 7690 , loss: 3.515421 Accuracy: 0.732000\n",
      " Iteration: 7700 , loss: 3.534334 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 7710 , loss: 3.512576 Accuracy: 0.760000\n",
      " Iteration: 7720 , loss: 3.518356 Accuracy: 0.776000\n",
      " Iteration: 7730 , loss: 3.503888 Accuracy: 0.772000\n",
      " Iteration: 7740 , loss: 3.533750 Accuracy: 0.764000\n",
      " Iteration: 7750 , loss: 3.514407 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 7760 , loss: 3.518982 Accuracy: 0.760000\n",
      " Iteration: 7770 , loss: 3.525707 Accuracy: 0.752000\n",
      " Iteration: 7780 , loss: 3.492972 Accuracy: 0.784000\n",
      " Iteration: 7790 , loss: 3.543932 Accuracy: 0.732000\n",
      " Iteration: 7800 , loss: 3.520244 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 7810 , loss: 3.518989 Accuracy: 0.744000\n",
      " Iteration: 7820 , loss: 3.513240 Accuracy: 0.748000\n",
      " Iteration: 7830 , loss: 3.513557 Accuracy: 0.760000\n",
      " Iteration: 7840 , loss: 3.542974 Accuracy: 0.724000\n",
      " Iteration: 7850 , loss: 3.528289 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 7860 , loss: 3.518271 Accuracy: 0.780000\n",
      " Iteration: 7870 , loss: 3.548950 Accuracy: 0.740000\n",
      " Iteration: 7880 , loss: 3.532635 Accuracy: 0.732000\n",
      " Iteration: 7890 , loss: 3.513966 Accuracy: 0.756000\n",
      " Iteration: 7900 , loss: 3.514836 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 7910 , loss: 3.542449 Accuracy: 0.728000\n",
      " Iteration: 7920 , loss: 3.534024 Accuracy: 0.748000\n",
      " Iteration: 7930 , loss: 3.521511 Accuracy: 0.760000\n",
      " Iteration: 7940 , loss: 3.528970 Accuracy: 0.748000\n",
      " Iteration: 7950 , loss: 3.552154 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 7960 , loss: 3.529678 Accuracy: 0.748000\n",
      " Iteration: 7970 , loss: 3.485656 Accuracy: 0.760000\n",
      " Iteration: 7980 , loss: 3.549726 Accuracy: 0.728000\n",
      " Iteration: 7990 , loss: 3.510068 Accuracy: 0.756000\n",
      " Iteration: 8000 , loss: 3.514960 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 8010 , loss: 3.498849 Accuracy: 0.788000\n",
      " Iteration: 8020 , loss: 3.503824 Accuracy: 0.748000\n",
      " Iteration: 8030 , loss: 3.508361 Accuracy: 0.756000\n",
      " Iteration: 8040 , loss: 3.506792 Accuracy: 0.772000\n",
      " Iteration: 8050 , loss: 3.517762 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 8060 , loss: 3.548315 Accuracy: 0.708000\n",
      " Iteration: 8070 , loss: 3.484612 Accuracy: 0.820000\n",
      " Iteration: 8080 , loss: 3.529117 Accuracy: 0.748000\n",
      " Iteration: 8090 , loss: 3.509600 Accuracy: 0.772000\n",
      " Iteration: 8100 , loss: 3.483207 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 8110 , loss: 3.495806 Accuracy: 0.796000\n",
      " Iteration: 8120 , loss: 3.478624 Accuracy: 0.784000\n",
      " Iteration: 8130 , loss: 3.512212 Accuracy: 0.772000\n",
      " Iteration: 8140 , loss: 3.462546 Accuracy: 0.796000\n",
      " Iteration: 8150 , loss: 3.478826 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 8160 , loss: 3.502210 Accuracy: 0.752000\n",
      " Iteration: 8170 , loss: 3.524748 Accuracy: 0.768000\n",
      " Iteration: 8180 , loss: 3.535026 Accuracy: 0.732000\n",
      " Iteration: 8190 , loss: 3.527058 Accuracy: 0.764000\n",
      " Iteration: 8200 , loss: 3.510580 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 8210 , loss: 3.511919 Accuracy: 0.772000\n",
      " Iteration: 8220 , loss: 3.513730 Accuracy: 0.764000\n",
      " Iteration: 8230 , loss: 3.509299 Accuracy: 0.788000\n",
      " Iteration: 8240 , loss: 3.519663 Accuracy: 0.768000\n",
      " Iteration: 8250 , loss: 3.530322 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 8260 , loss: 3.524076 Accuracy: 0.780000\n",
      " Iteration: 8270 , loss: 3.515705 Accuracy: 0.764000\n",
      " Iteration: 8280 , loss: 3.571797 Accuracy: 0.704000\n",
      " Iteration: 8290 , loss: 3.528914 Accuracy: 0.748000\n",
      " Iteration: 8300 , loss: 3.548291 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 8310 , loss: 3.535846 Accuracy: 0.744000\n",
      " Iteration: 8320 , loss: 3.528532 Accuracy: 0.760000\n",
      " Iteration: 8330 , loss: 3.493413 Accuracy: 0.792000\n",
      " Iteration: 8340 , loss: 3.548893 Accuracy: 0.740000\n",
      " Iteration: 8350 , loss: 3.559037 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 8360 , loss: 3.518358 Accuracy: 0.780000\n",
      " Iteration: 8370 , loss: 3.562652 Accuracy: 0.728000\n",
      " Iteration: 8380 , loss: 3.531817 Accuracy: 0.728000\n",
      " Iteration: 8390 , loss: 3.540196 Accuracy: 0.720000\n",
      " Iteration: 8400 , loss: 3.474295 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 8410 , loss: 3.497772 Accuracy: 0.816000\n",
      " Iteration: 8420 , loss: 3.520524 Accuracy: 0.740000\n",
      " Iteration: 8430 , loss: 3.513561 Accuracy: 0.772000\n",
      " Iteration: 8440 , loss: 3.504524 Accuracy: 0.768000\n",
      " Iteration: 8450 , loss: 3.511201 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 8460 , loss: 3.536054 Accuracy: 0.736000\n",
      " Iteration: 8470 , loss: 3.514618 Accuracy: 0.748000\n",
      " Iteration: 8480 , loss: 3.514455 Accuracy: 0.780000\n",
      " Iteration: 8490 , loss: 3.485350 Accuracy: 0.784000\n",
      " Iteration: 8500 , loss: 3.550315 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9230769230769231 and the number of correct results is: 216\n",
      " Iteration: 8510 , loss: 3.495395 Accuracy: 0.780000\n",
      " Iteration: 8520 , loss: 3.516838 Accuracy: 0.756000\n",
      " Iteration: 8530 , loss: 3.533230 Accuracy: 0.752000\n",
      " Iteration: 8540 , loss: 3.493348 Accuracy: 0.756000\n",
      " Iteration: 8550 , loss: 3.530598 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 8560 , loss: 3.537027 Accuracy: 0.740000\n",
      " Iteration: 8570 , loss: 3.495854 Accuracy: 0.772000\n",
      " Iteration: 8580 , loss: 3.547311 Accuracy: 0.736000\n",
      " Iteration: 8590 , loss: 3.518780 Accuracy: 0.764000\n",
      " Iteration: 8600 , loss: 3.502481 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 8610 , loss: 3.552325 Accuracy: 0.744000\n",
      " Iteration: 8620 , loss: 3.551029 Accuracy: 0.732000\n",
      " Iteration: 8630 , loss: 3.524072 Accuracy: 0.736000\n",
      " Iteration: 8640 , loss: 3.492008 Accuracy: 0.792000\n",
      " Iteration: 8650 , loss: 3.539891 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 8660 , loss: 3.493104 Accuracy: 0.764000\n",
      " Iteration: 8670 , loss: 3.518018 Accuracy: 0.760000\n",
      " Iteration: 8680 , loss: 3.474440 Accuracy: 0.808000\n",
      " Iteration: 8690 , loss: 3.472905 Accuracy: 0.816000\n",
      " Iteration: 8700 , loss: 3.485301 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8760683760683761 and the number of correct results is: 205\n",
      " Iteration: 8710 , loss: 3.545663 Accuracy: 0.756000\n",
      " Iteration: 8720 , loss: 3.485078 Accuracy: 0.792000\n",
      " Iteration: 8730 , loss: 3.494367 Accuracy: 0.776000\n",
      " Iteration: 8740 , loss: 3.563107 Accuracy: 0.732000\n",
      " Iteration: 8750 , loss: 3.521846 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 8760 , loss: 3.525941 Accuracy: 0.760000\n",
      " Iteration: 8770 , loss: 3.447194 Accuracy: 0.808000\n",
      " Iteration: 8780 , loss: 3.488067 Accuracy: 0.800000\n",
      " Iteration: 8790 , loss: 3.498512 Accuracy: 0.716000\n",
      " Iteration: 8800 , loss: 3.483092 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 8810 , loss: 3.527001 Accuracy: 0.748000\n",
      " Iteration: 8820 , loss: 3.516716 Accuracy: 0.768000\n",
      " Iteration: 8830 , loss: 3.529008 Accuracy: 0.772000\n",
      " Iteration: 8840 , loss: 3.479902 Accuracy: 0.800000\n",
      " Iteration: 8850 , loss: 3.493433 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 8860 , loss: 3.482730 Accuracy: 0.780000\n",
      " Iteration: 8870 , loss: 3.527371 Accuracy: 0.752000\n",
      " Iteration: 8880 , loss: 3.540897 Accuracy: 0.708000\n",
      " Iteration: 8890 , loss: 3.541651 Accuracy: 0.736000\n",
      " Iteration: 8900 , loss: 3.504143 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 8910 , loss: 3.531803 Accuracy: 0.756000\n",
      " Iteration: 8920 , loss: 3.510940 Accuracy: 0.768000\n",
      " Iteration: 8930 , loss: 3.545643 Accuracy: 0.736000\n",
      " Iteration: 8940 , loss: 3.477445 Accuracy: 0.812000\n",
      " Iteration: 8950 , loss: 3.499478 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 8960 , loss: 3.499128 Accuracy: 0.764000\n",
      " Iteration: 8970 , loss: 3.508599 Accuracy: 0.796000\n",
      " Iteration: 8980 , loss: 3.523210 Accuracy: 0.744000\n",
      " Iteration: 8990 , loss: 3.506953 Accuracy: 0.752000\n",
      " Iteration: 9000 , loss: 3.512718 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 9010 , loss: 3.495480 Accuracy: 0.800000\n",
      " Iteration: 9020 , loss: 3.488101 Accuracy: 0.792000\n",
      " Iteration: 9030 , loss: 3.553102 Accuracy: 0.720000\n",
      " Iteration: 9040 , loss: 3.508559 Accuracy: 0.764000\n",
      " Iteration: 9050 , loss: 3.514984 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 9060 , loss: 3.528161 Accuracy: 0.728000\n",
      " Iteration: 9070 , loss: 3.504725 Accuracy: 0.788000\n",
      " Iteration: 9080 , loss: 3.504861 Accuracy: 0.768000\n",
      " Iteration: 9090 , loss: 3.496213 Accuracy: 0.804000\n",
      " Iteration: 9100 , loss: 3.528102 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8589743589743589 and the number of correct results is: 201\n",
      " Iteration: 9110 , loss: 3.465991 Accuracy: 0.816000\n",
      " Iteration: 9120 , loss: 3.494381 Accuracy: 0.792000\n",
      " Iteration: 9130 , loss: 3.532949 Accuracy: 0.732000\n",
      " Iteration: 9140 , loss: 3.481842 Accuracy: 0.776000\n",
      " Iteration: 9150 , loss: 3.542214 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 9160 , loss: 3.518936 Accuracy: 0.756000\n",
      " Iteration: 9170 , loss: 3.497742 Accuracy: 0.768000\n",
      " Iteration: 9180 , loss: 3.464891 Accuracy: 0.840000\n",
      " Iteration: 9190 , loss: 3.496343 Accuracy: 0.780000\n",
      " Iteration: 9200 , loss: 3.533901 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 9210 , loss: 3.528879 Accuracy: 0.752000\n",
      " Iteration: 9220 , loss: 3.518197 Accuracy: 0.752000\n",
      " Iteration: 9230 , loss: 3.505990 Accuracy: 0.768000\n",
      " Iteration: 9240 , loss: 3.522877 Accuracy: 0.756000\n",
      " Iteration: 9250 , loss: 3.519692 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 9260 , loss: 3.515015 Accuracy: 0.760000\n",
      " Iteration: 9270 , loss: 3.510033 Accuracy: 0.800000\n",
      " Iteration: 9280 , loss: 3.517358 Accuracy: 0.776000\n",
      " Iteration: 9290 , loss: 3.508025 Accuracy: 0.788000\n",
      " Iteration: 9300 , loss: 3.514633 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 9310 , loss: 3.512280 Accuracy: 0.756000\n",
      " Iteration: 9320 , loss: 3.537948 Accuracy: 0.728000\n",
      " Iteration: 9330 , loss: 3.486680 Accuracy: 0.788000\n",
      " Iteration: 9340 , loss: 3.505743 Accuracy: 0.772000\n",
      " Iteration: 9350 , loss: 3.491352 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 9360 , loss: 3.510315 Accuracy: 0.756000\n",
      " Iteration: 9370 , loss: 3.507344 Accuracy: 0.800000\n",
      " Iteration: 9380 , loss: 3.508074 Accuracy: 0.760000\n",
      " Iteration: 9390 , loss: 3.476030 Accuracy: 0.812000\n",
      " Iteration: 9400 , loss: 3.473224 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 9410 , loss: 3.487000 Accuracy: 0.780000\n",
      " Iteration: 9420 , loss: 3.520922 Accuracy: 0.760000\n",
      " Iteration: 9430 , loss: 3.479505 Accuracy: 0.796000\n",
      " Iteration: 9440 , loss: 3.520620 Accuracy: 0.732000\n",
      " Iteration: 9450 , loss: 3.500514 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 9460 , loss: 3.526134 Accuracy: 0.784000\n",
      " Iteration: 9470 , loss: 3.551975 Accuracy: 0.724000\n",
      " Iteration: 9480 , loss: 3.500085 Accuracy: 0.780000\n",
      " Iteration: 9490 , loss: 3.539808 Accuracy: 0.728000\n",
      " Iteration: 9500 , loss: 3.516036 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 9510 , loss: 3.496508 Accuracy: 0.764000\n",
      " Iteration: 9520 , loss: 3.480805 Accuracy: 0.808000\n",
      " Iteration: 9530 , loss: 3.495074 Accuracy: 0.804000\n",
      " Iteration: 9540 , loss: 3.517449 Accuracy: 0.756000\n",
      " Iteration: 9550 , loss: 3.489364 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 9560 , loss: 3.509379 Accuracy: 0.744000\n",
      " Iteration: 9570 , loss: 3.532097 Accuracy: 0.732000\n",
      " Iteration: 9580 , loss: 3.546370 Accuracy: 0.724000\n",
      " Iteration: 9590 , loss: 3.507412 Accuracy: 0.752000\n",
      " Iteration: 9600 , loss: 3.507682 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 9610 , loss: 3.518230 Accuracy: 0.768000\n",
      " Iteration: 9620 , loss: 3.569471 Accuracy: 0.688000\n",
      " Iteration: 9630 , loss: 3.490777 Accuracy: 0.784000\n",
      " Iteration: 9640 , loss: 3.510253 Accuracy: 0.760000\n",
      " Iteration: 9650 , loss: 3.490486 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 9660 , loss: 3.510769 Accuracy: 0.756000\n",
      " Iteration: 9670 , loss: 3.458290 Accuracy: 0.824000\n",
      " Iteration: 9680 , loss: 3.529998 Accuracy: 0.728000\n",
      " Iteration: 9690 , loss: 3.527342 Accuracy: 0.752000\n",
      " Iteration: 9700 , loss: 3.514226 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 9710 , loss: 3.467026 Accuracy: 0.828000\n",
      " Iteration: 9720 , loss: 3.519663 Accuracy: 0.748000\n",
      " Iteration: 9730 , loss: 3.486230 Accuracy: 0.772000\n",
      " Iteration: 9740 , loss: 3.511204 Accuracy: 0.764000\n",
      " Iteration: 9750 , loss: 3.510730 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 9760 , loss: 3.483680 Accuracy: 0.800000\n",
      " Iteration: 9770 , loss: 3.447802 Accuracy: 0.856000\n",
      " Iteration: 9780 , loss: 3.522171 Accuracy: 0.756000\n",
      " Iteration: 9790 , loss: 3.497082 Accuracy: 0.784000\n",
      " Iteration: 9800 , loss: 3.518560 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 9810 , loss: 3.505090 Accuracy: 0.780000\n",
      " Iteration: 9820 , loss: 3.524618 Accuracy: 0.776000\n",
      " Iteration: 9830 , loss: 3.494555 Accuracy: 0.772000\n",
      " Iteration: 9840 , loss: 3.491663 Accuracy: 0.792000\n",
      " Iteration: 9850 , loss: 3.506499 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 9860 , loss: 3.493955 Accuracy: 0.800000\n",
      " Iteration: 9870 , loss: 3.530292 Accuracy: 0.744000\n",
      " Iteration: 9880 , loss: 3.521208 Accuracy: 0.736000\n",
      " Iteration: 9890 , loss: 3.496448 Accuracy: 0.800000\n",
      " Iteration: 9900 , loss: 3.480954 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 9910 , loss: 3.497588 Accuracy: 0.772000\n",
      " Iteration: 9920 , loss: 3.531970 Accuracy: 0.748000\n",
      " Iteration: 9930 , loss: 3.505245 Accuracy: 0.788000\n",
      " Iteration: 9940 , loss: 3.472443 Accuracy: 0.796000\n",
      " Iteration: 9950 , loss: 3.523641 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 9960 , loss: 3.496980 Accuracy: 0.816000\n",
      " Iteration: 9970 , loss: 3.502865 Accuracy: 0.788000\n",
      " Iteration: 9980 , loss: 3.478043 Accuracy: 0.796000\n",
      " Iteration: 9990 , loss: 3.552960 Accuracy: 0.704000\n",
      " Iteration: 10000 , loss: 3.502450 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 10010 , loss: 3.520397 Accuracy: 0.772000\n",
      " Iteration: 10020 , loss: 3.492044 Accuracy: 0.792000\n",
      " Iteration: 10030 , loss: 3.503338 Accuracy: 0.748000\n",
      " Iteration: 10040 , loss: 3.513411 Accuracy: 0.740000\n",
      " Iteration: 10050 , loss: 3.491415 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 10060 , loss: 3.475030 Accuracy: 0.816000\n",
      " Iteration: 10070 , loss: 3.494658 Accuracy: 0.752000\n",
      " Iteration: 10080 , loss: 3.487725 Accuracy: 0.792000\n",
      " Iteration: 10090 , loss: 3.519791 Accuracy: 0.748000\n",
      " Iteration: 10100 , loss: 3.500753 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 10110 , loss: 3.497128 Accuracy: 0.772000\n",
      " Iteration: 10120 , loss: 3.483635 Accuracy: 0.784000\n",
      " Iteration: 10130 , loss: 3.465395 Accuracy: 0.796000\n",
      " Iteration: 10140 , loss: 3.519536 Accuracy: 0.740000\n",
      " Iteration: 10150 , loss: 3.491935 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 10160 , loss: 3.524317 Accuracy: 0.772000\n",
      " Iteration: 10170 , loss: 3.489403 Accuracy: 0.808000\n",
      " Iteration: 10180 , loss: 3.481536 Accuracy: 0.780000\n",
      " Iteration: 10190 , loss: 3.510549 Accuracy: 0.744000\n",
      " Iteration: 10200 , loss: 3.524326 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 10210 , loss: 3.494687 Accuracy: 0.764000\n",
      " Iteration: 10220 , loss: 3.498500 Accuracy: 0.780000\n",
      " Iteration: 10230 , loss: 3.511443 Accuracy: 0.780000\n",
      " Iteration: 10240 , loss: 3.501655 Accuracy: 0.780000\n",
      " Iteration: 10250 , loss: 3.475779 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 10260 , loss: 3.540493 Accuracy: 0.732000\n",
      " Iteration: 10270 , loss: 3.521996 Accuracy: 0.740000\n",
      " Iteration: 10280 , loss: 3.481511 Accuracy: 0.780000\n",
      " Iteration: 10290 , loss: 3.530707 Accuracy: 0.760000\n",
      " Iteration: 10300 , loss: 3.510407 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 10310 , loss: 3.501977 Accuracy: 0.752000\n",
      " Iteration: 10320 , loss: 3.510773 Accuracy: 0.780000\n",
      " Iteration: 10330 , loss: 3.482946 Accuracy: 0.768000\n",
      " Iteration: 10340 , loss: 3.492116 Accuracy: 0.756000\n",
      " Iteration: 10350 , loss: 3.500915 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 10360 , loss: 3.496894 Accuracy: 0.768000\n",
      " Iteration: 10370 , loss: 3.503853 Accuracy: 0.776000\n",
      " Iteration: 10380 , loss: 3.493998 Accuracy: 0.772000\n",
      " Iteration: 10390 , loss: 3.495771 Accuracy: 0.788000\n",
      " Iteration: 10400 , loss: 3.505449 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 10410 , loss: 3.486907 Accuracy: 0.780000\n",
      " Iteration: 10420 , loss: 3.522946 Accuracy: 0.740000\n",
      " Iteration: 10430 , loss: 3.523112 Accuracy: 0.756000\n",
      " Iteration: 10440 , loss: 3.488244 Accuracy: 0.796000\n",
      " Iteration: 10450 , loss: 3.494025 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 10460 , loss: 3.469838 Accuracy: 0.832000\n",
      " Iteration: 10470 , loss: 3.495686 Accuracy: 0.760000\n",
      " Iteration: 10480 , loss: 3.502973 Accuracy: 0.792000\n",
      " Iteration: 10490 , loss: 3.504354 Accuracy: 0.752000\n",
      " Iteration: 10500 , loss: 3.520630 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 10510 , loss: 3.520398 Accuracy: 0.752000\n",
      " Iteration: 10520 , loss: 3.499923 Accuracy: 0.752000\n",
      " Iteration: 10530 , loss: 3.525712 Accuracy: 0.732000\n",
      " Iteration: 10540 , loss: 3.513513 Accuracy: 0.764000\n",
      " Iteration: 10550 , loss: 3.508126 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 10560 , loss: 3.494073 Accuracy: 0.768000\n",
      " Iteration: 10570 , loss: 3.478590 Accuracy: 0.792000\n",
      " Iteration: 10580 , loss: 3.506263 Accuracy: 0.776000\n",
      " Iteration: 10590 , loss: 3.462442 Accuracy: 0.804000\n",
      " Iteration: 10600 , loss: 3.468716 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 10610 , loss: 3.485071 Accuracy: 0.784000\n",
      " Iteration: 10620 , loss: 3.500403 Accuracy: 0.728000\n",
      " Iteration: 10630 , loss: 3.502064 Accuracy: 0.780000\n",
      " Iteration: 10640 , loss: 3.511146 Accuracy: 0.752000\n",
      " Iteration: 10650 , loss: 3.497456 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 10660 , loss: 3.503341 Accuracy: 0.756000\n",
      " Iteration: 10670 , loss: 3.484370 Accuracy: 0.784000\n",
      " Iteration: 10680 , loss: 3.504514 Accuracy: 0.780000\n",
      " Iteration: 10690 , loss: 3.504046 Accuracy: 0.756000\n",
      " Iteration: 10700 , loss: 3.473555 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 10710 , loss: 3.514814 Accuracy: 0.760000\n",
      " Iteration: 10720 , loss: 3.513617 Accuracy: 0.768000\n",
      " Iteration: 10730 , loss: 3.490860 Accuracy: 0.772000\n",
      " Iteration: 10740 , loss: 3.489040 Accuracy: 0.772000\n",
      " Iteration: 10750 , loss: 3.482314 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 10760 , loss: 3.509256 Accuracy: 0.752000\n",
      " Iteration: 10770 , loss: 3.481972 Accuracy: 0.788000\n",
      " Iteration: 10780 , loss: 3.488038 Accuracy: 0.760000\n",
      " Iteration: 10790 , loss: 3.505236 Accuracy: 0.748000\n",
      " Iteration: 10800 , loss: 3.526804 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 10810 , loss: 3.480240 Accuracy: 0.764000\n",
      " Iteration: 10820 , loss: 3.493616 Accuracy: 0.792000\n",
      " Iteration: 10830 , loss: 3.463480 Accuracy: 0.804000\n",
      " Iteration: 10840 , loss: 3.498530 Accuracy: 0.792000\n",
      " Iteration: 10850 , loss: 3.496833 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 10860 , loss: 3.450454 Accuracy: 0.844000\n",
      " Iteration: 10870 , loss: 3.506895 Accuracy: 0.760000\n",
      " Iteration: 10880 , loss: 3.494756 Accuracy: 0.784000\n",
      " Iteration: 10890 , loss: 3.478852 Accuracy: 0.800000\n",
      " Iteration: 10900 , loss: 3.514815 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 10910 , loss: 3.486157 Accuracy: 0.776000\n",
      " Iteration: 10920 , loss: 3.451454 Accuracy: 0.804000\n",
      " Iteration: 10930 , loss: 3.501989 Accuracy: 0.748000\n",
      " Iteration: 10940 , loss: 3.470464 Accuracy: 0.820000\n",
      " Iteration: 10950 , loss: 3.495976 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 10960 , loss: 3.456283 Accuracy: 0.796000\n",
      " Iteration: 10970 , loss: 3.494598 Accuracy: 0.768000\n",
      " Iteration: 10980 , loss: 3.472742 Accuracy: 0.796000\n",
      " Iteration: 10990 , loss: 3.484416 Accuracy: 0.796000\n",
      " Iteration: 11000 , loss: 3.491398 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 11010 , loss: 3.459202 Accuracy: 0.792000\n",
      " Iteration: 11020 , loss: 3.466195 Accuracy: 0.796000\n",
      " Iteration: 11030 , loss: 3.508135 Accuracy: 0.768000\n",
      " Iteration: 11040 , loss: 3.505387 Accuracy: 0.776000\n",
      " Iteration: 11050 , loss: 3.519608 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 11060 , loss: 3.515497 Accuracy: 0.748000\n",
      " Iteration: 11070 , loss: 3.478755 Accuracy: 0.764000\n",
      " Iteration: 11080 , loss: 3.477489 Accuracy: 0.804000\n",
      " Iteration: 11090 , loss: 3.504165 Accuracy: 0.760000\n",
      " Iteration: 11100 , loss: 3.502050 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9230769230769231 and the number of correct results is: 216\n",
      " Iteration: 11110 , loss: 3.482876 Accuracy: 0.808000\n",
      " Iteration: 11120 , loss: 3.492966 Accuracy: 0.768000\n",
      " Iteration: 11130 , loss: 3.498369 Accuracy: 0.736000\n",
      " Iteration: 11140 , loss: 3.529538 Accuracy: 0.748000\n",
      " Iteration: 11150 , loss: 3.486728 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 11160 , loss: 3.462392 Accuracy: 0.788000\n",
      " Iteration: 11170 , loss: 3.494887 Accuracy: 0.780000\n",
      " Iteration: 11180 , loss: 3.494416 Accuracy: 0.784000\n",
      " Iteration: 11190 , loss: 3.474233 Accuracy: 0.804000\n",
      " Iteration: 11200 , loss: 3.504472 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 11210 , loss: 3.475570 Accuracy: 0.804000\n",
      " Iteration: 11220 , loss: 3.515313 Accuracy: 0.728000\n",
      " Iteration: 11230 , loss: 3.508393 Accuracy: 0.744000\n",
      " Iteration: 11240 , loss: 3.458351 Accuracy: 0.848000\n",
      " Iteration: 11250 , loss: 3.476914 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 11260 , loss: 3.505444 Accuracy: 0.764000\n",
      " Iteration: 11270 , loss: 3.502214 Accuracy: 0.748000\n",
      " Iteration: 11280 , loss: 3.478135 Accuracy: 0.772000\n",
      " Iteration: 11290 , loss: 3.448085 Accuracy: 0.812000\n",
      " Iteration: 11300 , loss: 3.477406 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 11310 , loss: 3.488653 Accuracy: 0.784000\n",
      " Iteration: 11320 , loss: 3.476889 Accuracy: 0.820000\n",
      " Iteration: 11330 , loss: 3.501299 Accuracy: 0.756000\n",
      " Iteration: 11340 , loss: 3.485451 Accuracy: 0.788000\n",
      " Iteration: 11350 , loss: 3.518195 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 11360 , loss: 3.521164 Accuracy: 0.756000\n",
      " Iteration: 11370 , loss: 3.486578 Accuracy: 0.792000\n",
      " Iteration: 11380 , loss: 3.495862 Accuracy: 0.772000\n",
      " Iteration: 11390 , loss: 3.471500 Accuracy: 0.812000\n",
      " Iteration: 11400 , loss: 3.516356 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 11410 , loss: 3.503394 Accuracy: 0.796000\n",
      " Iteration: 11420 , loss: 3.479605 Accuracy: 0.764000\n",
      " Iteration: 11430 , loss: 3.496975 Accuracy: 0.736000\n",
      " Iteration: 11440 , loss: 3.503172 Accuracy: 0.772000\n",
      " Iteration: 11450 , loss: 3.483531 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 11460 , loss: 3.471018 Accuracy: 0.800000\n",
      " Iteration: 11470 , loss: 3.481046 Accuracy: 0.796000\n",
      " Iteration: 11480 , loss: 3.453135 Accuracy: 0.812000\n",
      " Iteration: 11490 , loss: 3.487489 Accuracy: 0.824000\n",
      " Iteration: 11500 , loss: 3.511668 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 11510 , loss: 3.510440 Accuracy: 0.764000\n",
      " Iteration: 11520 , loss: 3.540447 Accuracy: 0.736000\n",
      " Iteration: 11530 , loss: 3.474729 Accuracy: 0.780000\n",
      " Iteration: 11540 , loss: 3.469018 Accuracy: 0.784000\n",
      " Iteration: 11550 , loss: 3.514844 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 11560 , loss: 3.540646 Accuracy: 0.744000\n",
      " Iteration: 11570 , loss: 3.460795 Accuracy: 0.808000\n",
      " Iteration: 11580 , loss: 3.450989 Accuracy: 0.816000\n",
      " Iteration: 11590 , loss: 3.484297 Accuracy: 0.772000\n",
      " Iteration: 11600 , loss: 3.458647 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 11610 , loss: 3.497293 Accuracy: 0.772000\n",
      " Iteration: 11620 , loss: 3.455823 Accuracy: 0.860000\n",
      " Iteration: 11630 , loss: 3.487295 Accuracy: 0.784000\n",
      " Iteration: 11640 , loss: 3.469207 Accuracy: 0.824000\n",
      " Iteration: 11650 , loss: 3.488203 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 11660 , loss: 3.485677 Accuracy: 0.768000\n",
      " Iteration: 11670 , loss: 3.515777 Accuracy: 0.768000\n",
      " Iteration: 11680 , loss: 3.509543 Accuracy: 0.772000\n",
      " Iteration: 11690 , loss: 3.492942 Accuracy: 0.776000\n",
      " Iteration: 11700 , loss: 3.455489 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 11710 , loss: 3.467640 Accuracy: 0.796000\n",
      " Iteration: 11720 , loss: 3.439734 Accuracy: 0.812000\n",
      " Iteration: 11730 , loss: 3.481267 Accuracy: 0.788000\n",
      " Iteration: 11740 , loss: 3.443228 Accuracy: 0.820000\n",
      " Iteration: 11750 , loss: 3.485332 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 11760 , loss: 3.523385 Accuracy: 0.720000\n",
      " Iteration: 11770 , loss: 3.498260 Accuracy: 0.784000\n",
      " Iteration: 11780 , loss: 3.443097 Accuracy: 0.832000\n",
      " Iteration: 11790 , loss: 3.495947 Accuracy: 0.756000\n",
      " Iteration: 11800 , loss: 3.500411 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 11810 , loss: 3.499883 Accuracy: 0.772000\n",
      " Iteration: 11820 , loss: 3.480600 Accuracy: 0.784000\n",
      " Iteration: 11830 , loss: 3.506128 Accuracy: 0.744000\n",
      " Iteration: 11840 , loss: 3.470053 Accuracy: 0.816000\n",
      " Iteration: 11850 , loss: 3.491599 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9230769230769231 and the number of correct results is: 216\n",
      " Iteration: 11860 , loss: 3.499592 Accuracy: 0.756000\n",
      " Iteration: 11870 , loss: 3.478613 Accuracy: 0.788000\n",
      " Iteration: 11880 , loss: 3.476201 Accuracy: 0.792000\n",
      " Iteration: 11890 , loss: 3.497540 Accuracy: 0.776000\n",
      " Iteration: 11900 , loss: 3.490386 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 11910 , loss: 3.486187 Accuracy: 0.764000\n",
      " Iteration: 11920 , loss: 3.459793 Accuracy: 0.788000\n",
      " Iteration: 11930 , loss: 3.495636 Accuracy: 0.744000\n",
      " Iteration: 11940 , loss: 3.527133 Accuracy: 0.708000\n",
      " Iteration: 11950 , loss: 3.473310 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 11960 , loss: 3.495562 Accuracy: 0.772000\n",
      " Iteration: 11970 , loss: 3.465795 Accuracy: 0.796000\n",
      " Iteration: 11980 , loss: 3.479036 Accuracy: 0.796000\n",
      " Iteration: 11990 , loss: 3.495147 Accuracy: 0.772000\n",
      " Iteration: 12000 , loss: 3.481309 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 12010 , loss: 3.490454 Accuracy: 0.768000\n",
      " Iteration: 12020 , loss: 3.500097 Accuracy: 0.772000\n",
      " Iteration: 12030 , loss: 3.481388 Accuracy: 0.772000\n",
      " Iteration: 12040 , loss: 3.483724 Accuracy: 0.784000\n",
      " Iteration: 12050 , loss: 3.515636 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 12060 , loss: 3.499895 Accuracy: 0.776000\n",
      " Iteration: 12070 , loss: 3.468328 Accuracy: 0.816000\n",
      " Iteration: 12080 , loss: 3.497032 Accuracy: 0.792000\n",
      " Iteration: 12090 , loss: 3.497092 Accuracy: 0.772000\n",
      " Iteration: 12100 , loss: 3.471849 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 12110 , loss: 3.512086 Accuracy: 0.776000\n",
      " Iteration: 12120 , loss: 3.468881 Accuracy: 0.804000\n",
      " Iteration: 12130 , loss: 3.487512 Accuracy: 0.760000\n",
      " Iteration: 12140 , loss: 3.454018 Accuracy: 0.772000\n",
      " Iteration: 12150 , loss: 3.445120 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 12160 , loss: 3.477208 Accuracy: 0.788000\n",
      " Iteration: 12170 , loss: 3.497864 Accuracy: 0.788000\n",
      " Iteration: 12180 , loss: 3.490930 Accuracy: 0.772000\n",
      " Iteration: 12190 , loss: 3.466369 Accuracy: 0.804000\n",
      " Iteration: 12200 , loss: 3.457830 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 12210 , loss: 3.492151 Accuracy: 0.748000\n",
      " Iteration: 12220 , loss: 3.474780 Accuracy: 0.784000\n",
      " Iteration: 12230 , loss: 3.494780 Accuracy: 0.772000\n",
      " Iteration: 12240 , loss: 3.466090 Accuracy: 0.796000\n",
      " Iteration: 12250 , loss: 3.505651 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 12260 , loss: 3.490824 Accuracy: 0.776000\n",
      " Iteration: 12270 , loss: 3.478451 Accuracy: 0.764000\n",
      " Iteration: 12280 , loss: 3.484668 Accuracy: 0.784000\n",
      " Iteration: 12290 , loss: 3.507724 Accuracy: 0.732000\n",
      " Iteration: 12300 , loss: 3.503134 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8888888888888888 and the number of correct results is: 208\n",
      " Iteration: 12310 , loss: 3.473825 Accuracy: 0.824000\n",
      " Iteration: 12320 , loss: 3.448534 Accuracy: 0.836000\n",
      " Iteration: 12330 , loss: 3.457880 Accuracy: 0.808000\n",
      " Iteration: 12340 , loss: 3.468231 Accuracy: 0.812000\n",
      " Iteration: 12350 , loss: 3.479023 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 12360 , loss: 3.497034 Accuracy: 0.788000\n",
      " Iteration: 12370 , loss: 3.447547 Accuracy: 0.800000\n",
      " Iteration: 12380 , loss: 3.428919 Accuracy: 0.816000\n",
      " Iteration: 12390 , loss: 3.486606 Accuracy: 0.784000\n",
      " Iteration: 12400 , loss: 3.488606 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 12410 , loss: 3.487146 Accuracy: 0.776000\n",
      " Iteration: 12420 , loss: 3.465782 Accuracy: 0.804000\n",
      " Iteration: 12430 , loss: 3.498292 Accuracy: 0.772000\n",
      " Iteration: 12440 , loss: 3.445327 Accuracy: 0.832000\n",
      " Iteration: 12450 , loss: 3.530418 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 12460 , loss: 3.446139 Accuracy: 0.840000\n",
      " Iteration: 12470 , loss: 3.449864 Accuracy: 0.816000\n",
      " Iteration: 12480 , loss: 3.480069 Accuracy: 0.776000\n",
      " Iteration: 12490 , loss: 3.462848 Accuracy: 0.796000\n",
      " Iteration: 12500 , loss: 3.472821 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 12510 , loss: 3.486392 Accuracy: 0.788000\n",
      " Iteration: 12520 , loss: 3.458405 Accuracy: 0.820000\n",
      " Iteration: 12530 , loss: 3.497576 Accuracy: 0.744000\n",
      " Iteration: 12540 , loss: 3.458667 Accuracy: 0.820000\n",
      " Iteration: 12550 , loss: 3.484926 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 12560 , loss: 3.461179 Accuracy: 0.820000\n",
      " Iteration: 12570 , loss: 3.486067 Accuracy: 0.780000\n",
      " Iteration: 12580 , loss: 3.453042 Accuracy: 0.828000\n",
      " Iteration: 12590 , loss: 3.493621 Accuracy: 0.792000\n",
      " Iteration: 12600 , loss: 3.464808 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.8846153846153846 and the number of correct results is: 207\n",
      " Iteration: 12610 , loss: 3.480377 Accuracy: 0.776000\n",
      " Iteration: 12620 , loss: 3.444870 Accuracy: 0.804000\n",
      " Iteration: 12630 , loss: 3.472309 Accuracy: 0.784000\n",
      " Iteration: 12640 , loss: 3.503367 Accuracy: 0.772000\n",
      " Iteration: 12650 , loss: 3.507857 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 12660 , loss: 3.502786 Accuracy: 0.776000\n",
      " Iteration: 12670 , loss: 3.482999 Accuracy: 0.804000\n",
      " Iteration: 12680 , loss: 3.441507 Accuracy: 0.832000\n",
      " Iteration: 12690 , loss: 3.452022 Accuracy: 0.820000\n",
      " Iteration: 12700 , loss: 3.450008 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 12710 , loss: 3.460826 Accuracy: 0.808000\n",
      " Iteration: 12720 , loss: 3.510666 Accuracy: 0.764000\n",
      " Iteration: 12730 , loss: 3.485412 Accuracy: 0.776000\n",
      " Iteration: 12740 , loss: 3.482548 Accuracy: 0.796000\n",
      " Iteration: 12750 , loss: 3.459326 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 12760 , loss: 3.514252 Accuracy: 0.756000\n",
      " Iteration: 12770 , loss: 3.473316 Accuracy: 0.776000\n",
      " Iteration: 12780 , loss: 3.479547 Accuracy: 0.764000\n",
      " Iteration: 12790 , loss: 3.473943 Accuracy: 0.816000\n",
      " Iteration: 12800 , loss: 3.526728 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 12810 , loss: 3.497977 Accuracy: 0.776000\n",
      " Iteration: 12820 , loss: 3.496164 Accuracy: 0.768000\n",
      " Iteration: 12830 , loss: 3.477371 Accuracy: 0.780000\n",
      " Iteration: 12840 , loss: 3.526044 Accuracy: 0.732000\n",
      " Iteration: 12850 , loss: 3.430167 Accuracy: 0.860000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 12860 , loss: 3.463996 Accuracy: 0.816000\n",
      " Iteration: 12870 , loss: 3.509626 Accuracy: 0.752000\n",
      " Iteration: 12880 , loss: 3.466173 Accuracy: 0.792000\n",
      " Iteration: 12890 , loss: 3.478873 Accuracy: 0.788000\n",
      " Iteration: 12900 , loss: 3.465644 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.8803418803418803 and the number of correct results is: 206\n",
      " Iteration: 12910 , loss: 3.489047 Accuracy: 0.804000\n",
      " Iteration: 12920 , loss: 3.499285 Accuracy: 0.764000\n",
      " Iteration: 12930 , loss: 3.468514 Accuracy: 0.808000\n",
      " Iteration: 12940 , loss: 3.460662 Accuracy: 0.800000\n",
      " Iteration: 12950 , loss: 3.487075 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 12960 , loss: 3.470098 Accuracy: 0.812000\n",
      " Iteration: 12970 , loss: 3.488413 Accuracy: 0.788000\n",
      " Iteration: 12980 , loss: 3.458534 Accuracy: 0.824000\n",
      " Iteration: 12990 , loss: 3.480005 Accuracy: 0.788000\n",
      " Iteration: 13000 , loss: 3.490106 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 13010 , loss: 3.461573 Accuracy: 0.788000\n",
      " Iteration: 13020 , loss: 3.461484 Accuracy: 0.804000\n",
      " Iteration: 13030 , loss: 3.499978 Accuracy: 0.780000\n",
      " Iteration: 13040 , loss: 3.500866 Accuracy: 0.780000\n",
      " Iteration: 13050 , loss: 3.497595 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 13060 , loss: 3.431999 Accuracy: 0.836000\n",
      " Iteration: 13070 , loss: 3.470107 Accuracy: 0.800000\n",
      " Iteration: 13080 , loss: 3.481107 Accuracy: 0.812000\n",
      " Iteration: 13090 , loss: 3.494456 Accuracy: 0.748000\n",
      " Iteration: 13100 , loss: 3.467149 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 13110 , loss: 3.436036 Accuracy: 0.824000\n",
      " Iteration: 13120 , loss: 3.478127 Accuracy: 0.780000\n",
      " Iteration: 13130 , loss: 3.470170 Accuracy: 0.780000\n",
      " Iteration: 13140 , loss: 3.460827 Accuracy: 0.824000\n",
      " Iteration: 13150 , loss: 3.464261 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 13160 , loss: 3.471252 Accuracy: 0.800000\n",
      " Iteration: 13170 , loss: 3.463105 Accuracy: 0.840000\n",
      " Iteration: 13180 , loss: 3.453243 Accuracy: 0.840000\n",
      " Iteration: 13190 , loss: 3.483182 Accuracy: 0.780000\n",
      " Iteration: 13200 , loss: 3.474748 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 13210 , loss: 3.478590 Accuracy: 0.784000\n",
      " Iteration: 13220 , loss: 3.431057 Accuracy: 0.804000\n",
      " Iteration: 13230 , loss: 3.469646 Accuracy: 0.816000\n",
      " Iteration: 13240 , loss: 3.453848 Accuracy: 0.788000\n",
      " Iteration: 13250 , loss: 3.455640 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 13260 , loss: 3.463284 Accuracy: 0.784000\n",
      " Iteration: 13270 , loss: 3.472392 Accuracy: 0.788000\n",
      " Iteration: 13280 , loss: 3.483830 Accuracy: 0.776000\n",
      " Iteration: 13290 , loss: 3.469338 Accuracy: 0.792000\n",
      " Iteration: 13300 , loss: 3.466141 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 13310 , loss: 3.463534 Accuracy: 0.808000\n",
      " Iteration: 13320 , loss: 3.493562 Accuracy: 0.764000\n",
      " Iteration: 13330 , loss: 3.487248 Accuracy: 0.780000\n",
      " Iteration: 13340 , loss: 3.432997 Accuracy: 0.836000\n",
      " Iteration: 13350 , loss: 3.481551 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 13360 , loss: 3.513906 Accuracy: 0.756000\n",
      " Iteration: 13370 , loss: 3.473710 Accuracy: 0.784000\n",
      " Iteration: 13380 , loss: 3.472410 Accuracy: 0.780000\n",
      " Iteration: 13390 , loss: 3.452062 Accuracy: 0.800000\n",
      " Iteration: 13400 , loss: 3.475610 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 13410 , loss: 3.483376 Accuracy: 0.768000\n",
      " Iteration: 13420 , loss: 3.456309 Accuracy: 0.808000\n",
      " Iteration: 13430 , loss: 3.480371 Accuracy: 0.780000\n",
      " Iteration: 13440 , loss: 3.467256 Accuracy: 0.816000\n",
      " Iteration: 13450 , loss: 3.457072 Accuracy: 0.832000\n",
      "The postprocessing average accuracy is: 0.9017094017094017 and the number of correct results is: 211\n",
      " Iteration: 13460 , loss: 3.459104 Accuracy: 0.812000\n",
      " Iteration: 13470 , loss: 3.481836 Accuracy: 0.792000\n",
      " Iteration: 13480 , loss: 3.450519 Accuracy: 0.812000\n",
      " Iteration: 13490 , loss: 3.430790 Accuracy: 0.844000\n",
      " Iteration: 13500 , loss: 3.459160 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 13510 , loss: 3.493258 Accuracy: 0.764000\n",
      " Iteration: 13520 , loss: 3.478268 Accuracy: 0.796000\n",
      " Iteration: 13530 , loss: 3.492437 Accuracy: 0.764000\n",
      " Iteration: 13540 , loss: 3.467390 Accuracy: 0.792000\n",
      " Iteration: 13550 , loss: 3.453985 Accuracy: 0.832000\n",
      "The postprocessing average accuracy is: 0.9102564102564102 and the number of correct results is: 213\n",
      " Iteration: 13560 , loss: 3.480856 Accuracy: 0.808000\n",
      " Iteration: 13570 , loss: 3.478995 Accuracy: 0.784000\n",
      " Iteration: 13580 , loss: 3.464825 Accuracy: 0.800000\n",
      " Iteration: 13590 , loss: 3.491699 Accuracy: 0.792000\n",
      " Iteration: 13600 , loss: 3.532976 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8931623931623932 and the number of correct results is: 209\n",
      " Iteration: 13610 , loss: 3.437972 Accuracy: 0.844000\n",
      " Iteration: 13620 , loss: 3.458454 Accuracy: 0.788000\n",
      " Iteration: 13630 , loss: 3.444539 Accuracy: 0.832000\n",
      " Iteration: 13640 , loss: 3.505831 Accuracy: 0.756000\n",
      " Iteration: 13650 , loss: 3.463981 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9145299145299145 and the number of correct results is: 214\n",
      " Iteration: 13660 , loss: 3.468302 Accuracy: 0.820000\n",
      " Iteration: 13670 , loss: 3.485701 Accuracy: 0.784000\n",
      " Iteration: 13680 , loss: 3.468765 Accuracy: 0.808000\n",
      " Iteration: 13690 , loss: 3.500239 Accuracy: 0.764000\n",
      " Iteration: 13700 , loss: 3.461528 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 13710 , loss: 3.486510 Accuracy: 0.772000\n",
      " Iteration: 13720 , loss: 3.441599 Accuracy: 0.844000\n",
      " Iteration: 13730 , loss: 3.484118 Accuracy: 0.780000\n",
      " Iteration: 13740 , loss: 3.462589 Accuracy: 0.808000\n",
      " Iteration: 13750 , loss: 3.424414 Accuracy: 0.852000\n",
      "The postprocessing average accuracy is: 0.9188034188034188 and the number of correct results is: 215\n",
      " Iteration: 13760 , loss: 3.511489 Accuracy: 0.772000\n",
      " Iteration: 13770 , loss: 3.427741 Accuracy: 0.848000\n",
      " Iteration: 13780 , loss: 3.447787 Accuracy: 0.816000\n",
      " Iteration: 13790 , loss: 3.465636 Accuracy: 0.796000\n",
      " Iteration: 13800 , loss: 3.480035 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.905982905982906 and the number of correct results is: 212\n",
      " Iteration: 13810 , loss: 3.466232 Accuracy: 0.800000\n",
      " Iteration: 13820 , loss: 3.487756 Accuracy: 0.784000\n",
      " Iteration: 13830 , loss: 3.450205 Accuracy: 0.812000\n",
      " Iteration: 13840 , loss: 3.461942 Accuracy: 0.820000\n",
      " Iteration: 13850 , loss: 3.474033 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8974358974358975 and the number of correct results is: 210\n",
      " Iteration: 13860 , loss: 3.494648 Accuracy: 0.752000\n",
      " Iteration: 13870 , loss: 3.455079 Accuracy: 0.804000\n",
      " Iteration: 13880 , loss: 3.462861 Accuracy: 0.784000\n",
      " Iteration: 13890 , loss: 3.499543 Accuracy: 0.748000\n",
      " Iteration: 13900 , loss: 3.456483 Accuracy: 0.832000\n",
      "The postprocessing average accuracy is: 0.9230769230769231 and the number of correct results is: 216\n",
      "\n",
      "Optimization of Split 1 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 2 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 4.174129 Accuracy: 0.016000\n",
      "The postprocessing average accuracy is: 0.008583690987124463 and the number of correct results is: 2\n",
      " Iteration: 10 , loss: 4.168032 Accuracy: 0.028000\n",
      " Iteration: 20 , loss: 4.160259 Accuracy: 0.088000\n",
      " Iteration: 30 , loss: 4.146799 Accuracy: 0.148000\n",
      " Iteration: 40 , loss: 4.124868 Accuracy: 0.168000\n",
      " Iteration: 50 , loss: 4.124053 Accuracy: 0.188000\n",
      "The postprocessing average accuracy is: 0.2145922746781116 and the number of correct results is: 50\n",
      " Iteration: 60 , loss: 4.118530 Accuracy: 0.196000\n",
      " Iteration: 70 , loss: 4.098938 Accuracy: 0.192000\n",
      " Iteration: 80 , loss: 4.100463 Accuracy: 0.212000\n",
      " Iteration: 90 , loss: 4.081011 Accuracy: 0.236000\n",
      " Iteration: 100 , loss: 4.058080 Accuracy: 0.256000\n",
      "The postprocessing average accuracy is: 0.39914163090128757 and the number of correct results is: 93\n",
      " Iteration: 110 , loss: 4.084935 Accuracy: 0.200000\n",
      " Iteration: 120 , loss: 4.078427 Accuracy: 0.188000\n",
      " Iteration: 130 , loss: 4.043169 Accuracy: 0.264000\n",
      " Iteration: 140 , loss: 4.038456 Accuracy: 0.252000\n",
      " Iteration: 150 , loss: 4.032803 Accuracy: 0.304000\n",
      "The postprocessing average accuracy is: 0.47639484978540775 and the number of correct results is: 111\n",
      " Iteration: 160 , loss: 4.038739 Accuracy: 0.288000\n",
      " Iteration: 170 , loss: 4.023639 Accuracy: 0.236000\n",
      " Iteration: 180 , loss: 4.040052 Accuracy: 0.260000\n",
      " Iteration: 190 , loss: 4.003603 Accuracy: 0.328000\n",
      " Iteration: 200 , loss: 4.011301 Accuracy: 0.336000\n",
      "The postprocessing average accuracy is: 0.5321888412017167 and the number of correct results is: 124\n",
      " Iteration: 210 , loss: 4.001382 Accuracy: 0.344000\n",
      " Iteration: 220 , loss: 3.954272 Accuracy: 0.348000\n",
      " Iteration: 230 , loss: 3.979234 Accuracy: 0.348000\n",
      " Iteration: 240 , loss: 3.970422 Accuracy: 0.332000\n",
      " Iteration: 250 , loss: 3.975566 Accuracy: 0.368000\n",
      "The postprocessing average accuracy is: 0.6137339055793991 and the number of correct results is: 143\n",
      " Iteration: 260 , loss: 3.964531 Accuracy: 0.376000\n",
      " Iteration: 270 , loss: 3.942121 Accuracy: 0.408000\n",
      " Iteration: 280 , loss: 3.962767 Accuracy: 0.356000\n",
      " Iteration: 290 , loss: 3.971946 Accuracy: 0.328000\n",
      " Iteration: 300 , loss: 3.944543 Accuracy: 0.404000\n",
      "The postprocessing average accuracy is: 0.6609442060085837 and the number of correct results is: 154\n",
      " Iteration: 310 , loss: 3.969484 Accuracy: 0.332000\n",
      " Iteration: 320 , loss: 3.937578 Accuracy: 0.384000\n",
      " Iteration: 330 , loss: 3.916960 Accuracy: 0.412000\n",
      " Iteration: 340 , loss: 3.925204 Accuracy: 0.380000\n",
      " Iteration: 350 , loss: 3.919373 Accuracy: 0.380000\n",
      "The postprocessing average accuracy is: 0.6609442060085837 and the number of correct results is: 154\n",
      " Iteration: 360 , loss: 3.906929 Accuracy: 0.452000\n",
      " Iteration: 370 , loss: 3.906070 Accuracy: 0.420000\n",
      " Iteration: 380 , loss: 3.926961 Accuracy: 0.392000\n",
      " Iteration: 390 , loss: 3.915543 Accuracy: 0.440000\n",
      " Iteration: 400 , loss: 3.920786 Accuracy: 0.428000\n",
      "The postprocessing average accuracy is: 0.6995708154506438 and the number of correct results is: 163\n",
      " Iteration: 410 , loss: 3.884315 Accuracy: 0.436000\n",
      " Iteration: 420 , loss: 3.904263 Accuracy: 0.448000\n",
      " Iteration: 430 , loss: 3.915543 Accuracy: 0.404000\n",
      " Iteration: 440 , loss: 3.902568 Accuracy: 0.424000\n",
      " Iteration: 450 , loss: 3.903594 Accuracy: 0.440000\n",
      "The postprocessing average accuracy is: 0.7167381974248928 and the number of correct results is: 167\n",
      " Iteration: 460 , loss: 3.886366 Accuracy: 0.444000\n",
      " Iteration: 470 , loss: 3.874889 Accuracy: 0.500000\n",
      " Iteration: 480 , loss: 3.912767 Accuracy: 0.416000\n",
      " Iteration: 490 , loss: 3.885250 Accuracy: 0.432000\n",
      " Iteration: 500 , loss: 3.863923 Accuracy: 0.484000\n",
      "The postprocessing average accuracy is: 0.7167381974248928 and the number of correct results is: 167\n",
      " Iteration: 510 , loss: 3.845203 Accuracy: 0.516000\n",
      " Iteration: 520 , loss: 3.817858 Accuracy: 0.536000\n",
      " Iteration: 530 , loss: 3.877845 Accuracy: 0.452000\n",
      " Iteration: 540 , loss: 3.877414 Accuracy: 0.468000\n",
      " Iteration: 550 , loss: 3.826495 Accuracy: 0.504000\n",
      "The postprocessing average accuracy is: 0.6995708154506438 and the number of correct results is: 163\n",
      " Iteration: 560 , loss: 3.871598 Accuracy: 0.440000\n",
      " Iteration: 570 , loss: 3.836448 Accuracy: 0.488000\n",
      " Iteration: 580 , loss: 3.834672 Accuracy: 0.464000\n",
      " Iteration: 590 , loss: 3.868577 Accuracy: 0.476000\n",
      " Iteration: 600 , loss: 3.871746 Accuracy: 0.448000\n",
      "The postprocessing average accuracy is: 0.7381974248927039 and the number of correct results is: 172\n",
      " Iteration: 610 , loss: 3.815265 Accuracy: 0.520000\n",
      " Iteration: 620 , loss: 3.841028 Accuracy: 0.500000\n",
      " Iteration: 630 , loss: 3.795285 Accuracy: 0.524000\n",
      " Iteration: 640 , loss: 3.842070 Accuracy: 0.472000\n",
      " Iteration: 650 , loss: 3.832372 Accuracy: 0.524000\n",
      "The postprocessing average accuracy is: 0.759656652360515 and the number of correct results is: 177\n",
      " Iteration: 660 , loss: 3.826499 Accuracy: 0.512000\n",
      " Iteration: 670 , loss: 3.831028 Accuracy: 0.496000\n",
      " Iteration: 680 , loss: 3.875309 Accuracy: 0.452000\n",
      " Iteration: 690 , loss: 3.847528 Accuracy: 0.492000\n",
      " Iteration: 700 , loss: 3.839388 Accuracy: 0.456000\n",
      "The postprocessing average accuracy is: 0.776824034334764 and the number of correct results is: 181\n",
      " Iteration: 710 , loss: 3.824619 Accuracy: 0.488000\n",
      " Iteration: 720 , loss: 3.839901 Accuracy: 0.536000\n",
      " Iteration: 730 , loss: 3.840766 Accuracy: 0.520000\n",
      " Iteration: 740 , loss: 3.836550 Accuracy: 0.512000\n",
      " Iteration: 750 , loss: 3.818485 Accuracy: 0.520000\n",
      "The postprocessing average accuracy is: 0.7811158798283262 and the number of correct results is: 182\n",
      " Iteration: 760 , loss: 3.828149 Accuracy: 0.508000\n",
      " Iteration: 770 , loss: 3.864708 Accuracy: 0.436000\n",
      " Iteration: 780 , loss: 3.794315 Accuracy: 0.536000\n",
      " Iteration: 790 , loss: 3.823340 Accuracy: 0.476000\n",
      " Iteration: 800 , loss: 3.825565 Accuracy: 0.476000\n",
      "The postprocessing average accuracy is: 0.7939914163090128 and the number of correct results is: 185\n",
      " Iteration: 810 , loss: 3.790663 Accuracy: 0.532000\n",
      " Iteration: 820 , loss: 3.795789 Accuracy: 0.532000\n",
      " Iteration: 830 , loss: 3.833809 Accuracy: 0.508000\n",
      " Iteration: 840 , loss: 3.823847 Accuracy: 0.488000\n",
      " Iteration: 850 , loss: 3.799556 Accuracy: 0.552000\n",
      "The postprocessing average accuracy is: 0.8111587982832618 and the number of correct results is: 189\n",
      " Iteration: 860 , loss: 3.813416 Accuracy: 0.524000\n",
      " Iteration: 870 , loss: 3.749451 Accuracy: 0.604000\n",
      " Iteration: 880 , loss: 3.750319 Accuracy: 0.596000\n",
      " Iteration: 890 , loss: 3.790114 Accuracy: 0.592000\n",
      " Iteration: 900 , loss: 3.788119 Accuracy: 0.504000\n",
      "The postprocessing average accuracy is: 0.7939914163090128 and the number of correct results is: 185\n",
      " Iteration: 910 , loss: 3.790802 Accuracy: 0.548000\n",
      " Iteration: 920 , loss: 3.797748 Accuracy: 0.540000\n",
      " Iteration: 930 , loss: 3.783912 Accuracy: 0.516000\n",
      " Iteration: 940 , loss: 3.786337 Accuracy: 0.544000\n",
      " Iteration: 950 , loss: 3.792806 Accuracy: 0.568000\n",
      "The postprocessing average accuracy is: 0.8068669527896996 and the number of correct results is: 188\n",
      " Iteration: 960 , loss: 3.771949 Accuracy: 0.532000\n",
      " Iteration: 970 , loss: 3.783530 Accuracy: 0.528000\n",
      " Iteration: 980 , loss: 3.756002 Accuracy: 0.572000\n",
      " Iteration: 990 , loss: 3.787325 Accuracy: 0.532000\n",
      " Iteration: 1000 , loss: 3.784610 Accuracy: 0.560000\n",
      "The postprocessing average accuracy is: 0.8240343347639485 and the number of correct results is: 192\n",
      " Iteration: 1010 , loss: 3.759596 Accuracy: 0.552000\n",
      " Iteration: 1020 , loss: 3.720015 Accuracy: 0.604000\n",
      " Iteration: 1030 , loss: 3.776736 Accuracy: 0.568000\n",
      " Iteration: 1040 , loss: 3.749919 Accuracy: 0.620000\n",
      " Iteration: 1050 , loss: 3.785951 Accuracy: 0.548000\n",
      "The postprocessing average accuracy is: 0.8240343347639485 and the number of correct results is: 192\n",
      " Iteration: 1060 , loss: 3.756880 Accuracy: 0.560000\n",
      " Iteration: 1070 , loss: 3.762713 Accuracy: 0.548000\n",
      " Iteration: 1080 , loss: 3.737683 Accuracy: 0.608000\n",
      " Iteration: 1090 , loss: 3.726826 Accuracy: 0.628000\n",
      " Iteration: 1100 , loss: 3.764549 Accuracy: 0.600000\n",
      "The postprocessing average accuracy is: 0.8025751072961373 and the number of correct results is: 187\n",
      " Iteration: 1110 , loss: 3.775917 Accuracy: 0.552000\n",
      " Iteration: 1120 , loss: 3.749942 Accuracy: 0.588000\n",
      " Iteration: 1130 , loss: 3.765830 Accuracy: 0.552000\n",
      " Iteration: 1140 , loss: 3.774632 Accuracy: 0.596000\n",
      " Iteration: 1150 , loss: 3.753100 Accuracy: 0.540000\n",
      "The postprocessing average accuracy is: 0.8240343347639485 and the number of correct results is: 192\n",
      " Iteration: 1160 , loss: 3.767342 Accuracy: 0.560000\n",
      " Iteration: 1170 , loss: 3.789040 Accuracy: 0.516000\n",
      " Iteration: 1180 , loss: 3.761166 Accuracy: 0.564000\n",
      " Iteration: 1190 , loss: 3.750375 Accuracy: 0.600000\n",
      " Iteration: 1200 , loss: 3.777566 Accuracy: 0.552000\n",
      "The postprocessing average accuracy is: 0.8154506437768241 and the number of correct results is: 190\n",
      " Iteration: 1210 , loss: 3.754144 Accuracy: 0.552000\n",
      " Iteration: 1220 , loss: 3.765508 Accuracy: 0.508000\n",
      " Iteration: 1230 , loss: 3.733506 Accuracy: 0.580000\n",
      " Iteration: 1240 , loss: 3.753621 Accuracy: 0.568000\n",
      " Iteration: 1250 , loss: 3.727462 Accuracy: 0.580000\n",
      "The postprocessing average accuracy is: 0.8283261802575107 and the number of correct results is: 193\n",
      " Iteration: 1260 , loss: 3.736745 Accuracy: 0.576000\n",
      " Iteration: 1270 , loss: 3.745689 Accuracy: 0.556000\n",
      " Iteration: 1280 , loss: 3.700673 Accuracy: 0.604000\n",
      " Iteration: 1290 , loss: 3.724296 Accuracy: 0.612000\n",
      " Iteration: 1300 , loss: 3.729297 Accuracy: 0.556000\n",
      "The postprocessing average accuracy is: 0.8240343347639485 and the number of correct results is: 192\n",
      " Iteration: 1310 , loss: 3.743247 Accuracy: 0.548000\n",
      " Iteration: 1320 , loss: 3.704387 Accuracy: 0.632000\n",
      " Iteration: 1330 , loss: 3.729904 Accuracy: 0.588000\n",
      " Iteration: 1340 , loss: 3.721652 Accuracy: 0.588000\n",
      " Iteration: 1350 , loss: 3.729983 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.8326180257510729 and the number of correct results is: 194\n",
      " Iteration: 1360 , loss: 3.709559 Accuracy: 0.592000\n",
      " Iteration: 1370 , loss: 3.751479 Accuracy: 0.552000\n",
      " Iteration: 1380 , loss: 3.742206 Accuracy: 0.556000\n",
      " Iteration: 1390 , loss: 3.715558 Accuracy: 0.632000\n",
      " Iteration: 1400 , loss: 3.711384 Accuracy: 0.608000\n",
      "The postprocessing average accuracy is: 0.8326180257510729 and the number of correct results is: 194\n",
      " Iteration: 1410 , loss: 3.721174 Accuracy: 0.600000\n",
      " Iteration: 1420 , loss: 3.746315 Accuracy: 0.568000\n",
      " Iteration: 1430 , loss: 3.732273 Accuracy: 0.564000\n",
      " Iteration: 1440 , loss: 3.709460 Accuracy: 0.588000\n",
      " Iteration: 1450 , loss: 3.736841 Accuracy: 0.568000\n",
      "The postprocessing average accuracy is: 0.8497854077253219 and the number of correct results is: 198\n",
      " Iteration: 1460 , loss: 3.741066 Accuracy: 0.568000\n",
      " Iteration: 1470 , loss: 3.709260 Accuracy: 0.628000\n",
      " Iteration: 1480 , loss: 3.730299 Accuracy: 0.604000\n",
      " Iteration: 1490 , loss: 3.723865 Accuracy: 0.600000\n",
      " Iteration: 1500 , loss: 3.712154 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8326180257510729 and the number of correct results is: 194\n",
      " Iteration: 1510 , loss: 3.720734 Accuracy: 0.584000\n",
      " Iteration: 1520 , loss: 3.739383 Accuracy: 0.568000\n",
      " Iteration: 1530 , loss: 3.696322 Accuracy: 0.596000\n",
      " Iteration: 1540 , loss: 3.732950 Accuracy: 0.576000\n",
      " Iteration: 1550 , loss: 3.711127 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.8369098712446352 and the number of correct results is: 195\n",
      " Iteration: 1560 , loss: 3.681810 Accuracy: 0.632000\n",
      " Iteration: 1570 , loss: 3.687078 Accuracy: 0.640000\n",
      " Iteration: 1580 , loss: 3.714590 Accuracy: 0.600000\n",
      " Iteration: 1590 , loss: 3.716923 Accuracy: 0.576000\n",
      " Iteration: 1600 , loss: 3.695264 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 1610 , loss: 3.751559 Accuracy: 0.560000\n",
      " Iteration: 1620 , loss: 3.730093 Accuracy: 0.596000\n",
      " Iteration: 1630 , loss: 3.676742 Accuracy: 0.644000\n",
      " Iteration: 1640 , loss: 3.720382 Accuracy: 0.544000\n",
      " Iteration: 1650 , loss: 3.725765 Accuracy: 0.580000\n",
      "The postprocessing average accuracy is: 0.8497854077253219 and the number of correct results is: 198\n",
      " Iteration: 1660 , loss: 3.732330 Accuracy: 0.600000\n",
      " Iteration: 1670 , loss: 3.737408 Accuracy: 0.552000\n",
      " Iteration: 1680 , loss: 3.688236 Accuracy: 0.660000\n",
      " Iteration: 1690 , loss: 3.700741 Accuracy: 0.640000\n",
      " Iteration: 1700 , loss: 3.702655 Accuracy: 0.612000\n",
      "The postprocessing average accuracy is: 0.8626609442060086 and the number of correct results is: 201\n",
      " Iteration: 1710 , loss: 3.702123 Accuracy: 0.620000\n",
      " Iteration: 1720 , loss: 3.731198 Accuracy: 0.572000\n",
      " Iteration: 1730 , loss: 3.692624 Accuracy: 0.620000\n",
      " Iteration: 1740 , loss: 3.707985 Accuracy: 0.608000\n",
      " Iteration: 1750 , loss: 3.740668 Accuracy: 0.588000\n",
      "The postprocessing average accuracy is: 0.8240343347639485 and the number of correct results is: 192\n",
      " Iteration: 1760 , loss: 3.733705 Accuracy: 0.576000\n",
      " Iteration: 1770 , loss: 3.700379 Accuracy: 0.632000\n",
      " Iteration: 1780 , loss: 3.727867 Accuracy: 0.604000\n",
      " Iteration: 1790 , loss: 3.678013 Accuracy: 0.676000\n",
      " Iteration: 1800 , loss: 3.670969 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 1810 , loss: 3.717742 Accuracy: 0.608000\n",
      " Iteration: 1820 , loss: 3.697516 Accuracy: 0.636000\n",
      " Iteration: 1830 , loss: 3.682698 Accuracy: 0.648000\n",
      " Iteration: 1840 , loss: 3.720559 Accuracy: 0.584000\n",
      " Iteration: 1850 , loss: 3.669863 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8626609442060086 and the number of correct results is: 201\n",
      " Iteration: 1860 , loss: 3.669942 Accuracy: 0.628000\n",
      " Iteration: 1870 , loss: 3.695556 Accuracy: 0.636000\n",
      " Iteration: 1880 , loss: 3.715279 Accuracy: 0.588000\n",
      " Iteration: 1890 , loss: 3.716537 Accuracy: 0.576000\n",
      " Iteration: 1900 , loss: 3.682190 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8583690987124464 and the number of correct results is: 200\n",
      " Iteration: 1910 , loss: 3.661561 Accuracy: 0.672000\n",
      " Iteration: 1920 , loss: 3.691711 Accuracy: 0.592000\n",
      " Iteration: 1930 , loss: 3.694533 Accuracy: 0.624000\n",
      " Iteration: 1940 , loss: 3.707989 Accuracy: 0.600000\n",
      " Iteration: 1950 , loss: 3.694693 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8540772532188842 and the number of correct results is: 199\n",
      " Iteration: 1960 , loss: 3.687214 Accuracy: 0.632000\n",
      " Iteration: 1970 , loss: 3.683442 Accuracy: 0.624000\n",
      " Iteration: 1980 , loss: 3.676054 Accuracy: 0.648000\n",
      " Iteration: 1990 , loss: 3.680901 Accuracy: 0.604000\n",
      " Iteration: 2000 , loss: 3.726508 Accuracy: 0.572000\n",
      "The postprocessing average accuracy is: 0.8540772532188842 and the number of correct results is: 199\n",
      " Iteration: 2010 , loss: 3.659208 Accuracy: 0.644000\n",
      " Iteration: 2020 , loss: 3.682599 Accuracy: 0.656000\n",
      " Iteration: 2030 , loss: 3.664611 Accuracy: 0.652000\n",
      " Iteration: 2040 , loss: 3.672534 Accuracy: 0.644000\n",
      " Iteration: 2050 , loss: 3.687331 Accuracy: 0.616000\n",
      "The postprocessing average accuracy is: 0.8240343347639485 and the number of correct results is: 192\n",
      " Iteration: 2060 , loss: 3.692873 Accuracy: 0.624000\n",
      " Iteration: 2070 , loss: 3.667899 Accuracy: 0.668000\n",
      " Iteration: 2080 , loss: 3.710033 Accuracy: 0.608000\n",
      " Iteration: 2090 , loss: 3.677531 Accuracy: 0.616000\n",
      " Iteration: 2100 , loss: 3.712688 Accuracy: 0.576000\n",
      "The postprocessing average accuracy is: 0.8497854077253219 and the number of correct results is: 198\n",
      " Iteration: 2110 , loss: 3.671105 Accuracy: 0.676000\n",
      " Iteration: 2120 , loss: 3.654357 Accuracy: 0.616000\n",
      " Iteration: 2130 , loss: 3.679783 Accuracy: 0.636000\n",
      " Iteration: 2140 , loss: 3.693631 Accuracy: 0.628000\n",
      " Iteration: 2150 , loss: 3.666151 Accuracy: 0.648000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 2160 , loss: 3.666241 Accuracy: 0.672000\n",
      " Iteration: 2170 , loss: 3.675788 Accuracy: 0.660000\n",
      " Iteration: 2180 , loss: 3.635860 Accuracy: 0.684000\n",
      " Iteration: 2190 , loss: 3.671803 Accuracy: 0.624000\n",
      " Iteration: 2200 , loss: 3.689612 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.8454935622317596 and the number of correct results is: 197\n",
      " Iteration: 2210 , loss: 3.632667 Accuracy: 0.656000\n",
      " Iteration: 2220 , loss: 3.680447 Accuracy: 0.596000\n",
      " Iteration: 2230 , loss: 3.620388 Accuracy: 0.688000\n",
      " Iteration: 2240 , loss: 3.683788 Accuracy: 0.628000\n",
      " Iteration: 2250 , loss: 3.642775 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 2260 , loss: 3.672378 Accuracy: 0.644000\n",
      " Iteration: 2270 , loss: 3.645864 Accuracy: 0.648000\n",
      " Iteration: 2280 , loss: 3.655058 Accuracy: 0.660000\n",
      " Iteration: 2290 , loss: 3.668786 Accuracy: 0.660000\n",
      " Iteration: 2300 , loss: 3.644810 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 2310 , loss: 3.637901 Accuracy: 0.664000\n",
      " Iteration: 2320 , loss: 3.660026 Accuracy: 0.640000\n",
      " Iteration: 2330 , loss: 3.642973 Accuracy: 0.656000\n",
      " Iteration: 2340 , loss: 3.693962 Accuracy: 0.608000\n",
      " Iteration: 2350 , loss: 3.653579 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 2360 , loss: 3.659547 Accuracy: 0.676000\n",
      " Iteration: 2370 , loss: 3.633892 Accuracy: 0.684000\n",
      " Iteration: 2380 , loss: 3.651649 Accuracy: 0.652000\n",
      " Iteration: 2390 , loss: 3.650058 Accuracy: 0.640000\n",
      " Iteration: 2400 , loss: 3.664775 Accuracy: 0.648000\n",
      "The postprocessing average accuracy is: 0.871244635193133 and the number of correct results is: 203\n",
      " Iteration: 2410 , loss: 3.691871 Accuracy: 0.636000\n",
      " Iteration: 2420 , loss: 3.652248 Accuracy: 0.644000\n",
      " Iteration: 2430 , loss: 3.661247 Accuracy: 0.624000\n",
      " Iteration: 2440 , loss: 3.646443 Accuracy: 0.676000\n",
      " Iteration: 2450 , loss: 3.675472 Accuracy: 0.624000\n",
      "The postprocessing average accuracy is: 0.871244635193133 and the number of correct results is: 203\n",
      " Iteration: 2460 , loss: 3.689726 Accuracy: 0.584000\n",
      " Iteration: 2470 , loss: 3.632957 Accuracy: 0.692000\n",
      " Iteration: 2480 , loss: 3.657268 Accuracy: 0.648000\n",
      " Iteration: 2490 , loss: 3.676104 Accuracy: 0.612000\n",
      " Iteration: 2500 , loss: 3.616120 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 2510 , loss: 3.645635 Accuracy: 0.672000\n",
      " Iteration: 2520 , loss: 3.678261 Accuracy: 0.636000\n",
      " Iteration: 2530 , loss: 3.619113 Accuracy: 0.704000\n",
      " Iteration: 2540 , loss: 3.653101 Accuracy: 0.652000\n",
      " Iteration: 2550 , loss: 3.607191 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 2560 , loss: 3.635351 Accuracy: 0.656000\n",
      " Iteration: 2570 , loss: 3.671654 Accuracy: 0.648000\n",
      " Iteration: 2580 , loss: 3.677684 Accuracy: 0.616000\n",
      " Iteration: 2590 , loss: 3.648658 Accuracy: 0.644000\n",
      " Iteration: 2600 , loss: 3.648935 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8626609442060086 and the number of correct results is: 201\n",
      " Iteration: 2610 , loss: 3.632386 Accuracy: 0.688000\n",
      " Iteration: 2620 , loss: 3.656967 Accuracy: 0.632000\n",
      " Iteration: 2630 , loss: 3.609117 Accuracy: 0.700000\n",
      " Iteration: 2640 , loss: 3.632780 Accuracy: 0.680000\n",
      " Iteration: 2650 , loss: 3.648998 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8540772532188842 and the number of correct results is: 199\n",
      " Iteration: 2660 , loss: 3.669551 Accuracy: 0.620000\n",
      " Iteration: 2670 , loss: 3.647953 Accuracy: 0.660000\n",
      " Iteration: 2680 , loss: 3.621530 Accuracy: 0.664000\n",
      " Iteration: 2690 , loss: 3.617910 Accuracy: 0.744000\n",
      " Iteration: 2700 , loss: 3.625326 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 2710 , loss: 3.654941 Accuracy: 0.664000\n",
      " Iteration: 2720 , loss: 3.647625 Accuracy: 0.648000\n",
      " Iteration: 2730 , loss: 3.656406 Accuracy: 0.644000\n",
      " Iteration: 2740 , loss: 3.624847 Accuracy: 0.696000\n",
      " Iteration: 2750 , loss: 3.606405 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 2760 , loss: 3.589366 Accuracy: 0.740000\n",
      " Iteration: 2770 , loss: 3.599066 Accuracy: 0.720000\n",
      " Iteration: 2780 , loss: 3.636595 Accuracy: 0.652000\n",
      " Iteration: 2790 , loss: 3.665118 Accuracy: 0.648000\n",
      " Iteration: 2800 , loss: 3.627439 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 2810 , loss: 3.638726 Accuracy: 0.668000\n",
      " Iteration: 2820 , loss: 3.630831 Accuracy: 0.668000\n",
      " Iteration: 2830 , loss: 3.668238 Accuracy: 0.616000\n",
      " Iteration: 2840 , loss: 3.661683 Accuracy: 0.624000\n",
      " Iteration: 2850 , loss: 3.660125 Accuracy: 0.608000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 2860 , loss: 3.655336 Accuracy: 0.644000\n",
      " Iteration: 2870 , loss: 3.647579 Accuracy: 0.656000\n",
      " Iteration: 2880 , loss: 3.647542 Accuracy: 0.644000\n",
      " Iteration: 2890 , loss: 3.638753 Accuracy: 0.668000\n",
      " Iteration: 2900 , loss: 3.602715 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.871244635193133 and the number of correct results is: 203\n",
      " Iteration: 2910 , loss: 3.648933 Accuracy: 0.644000\n",
      " Iteration: 2920 , loss: 3.629096 Accuracy: 0.660000\n",
      " Iteration: 2930 , loss: 3.639682 Accuracy: 0.652000\n",
      " Iteration: 2940 , loss: 3.608620 Accuracy: 0.716000\n",
      " Iteration: 2950 , loss: 3.625275 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8626609442060086 and the number of correct results is: 201\n",
      " Iteration: 2960 , loss: 3.649062 Accuracy: 0.656000\n",
      " Iteration: 2970 , loss: 3.642947 Accuracy: 0.644000\n",
      " Iteration: 2980 , loss: 3.617692 Accuracy: 0.664000\n",
      " Iteration: 2990 , loss: 3.671266 Accuracy: 0.652000\n",
      " Iteration: 3000 , loss: 3.620438 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8497854077253219 and the number of correct results is: 198\n",
      " Iteration: 3010 , loss: 3.606947 Accuracy: 0.680000\n",
      " Iteration: 3020 , loss: 3.617928 Accuracy: 0.696000\n",
      " Iteration: 3030 , loss: 3.616099 Accuracy: 0.704000\n",
      " Iteration: 3040 , loss: 3.628696 Accuracy: 0.652000\n",
      " Iteration: 3050 , loss: 3.615395 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 3060 , loss: 3.654288 Accuracy: 0.632000\n",
      " Iteration: 3070 , loss: 3.616827 Accuracy: 0.704000\n",
      " Iteration: 3080 , loss: 3.620697 Accuracy: 0.660000\n",
      " Iteration: 3090 , loss: 3.604877 Accuracy: 0.692000\n",
      " Iteration: 3100 , loss: 3.637705 Accuracy: 0.664000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 3110 , loss: 3.625370 Accuracy: 0.688000\n",
      " Iteration: 3120 , loss: 3.637083 Accuracy: 0.680000\n",
      " Iteration: 3130 , loss: 3.616548 Accuracy: 0.684000\n",
      " Iteration: 3140 , loss: 3.621862 Accuracy: 0.704000\n",
      " Iteration: 3150 , loss: 3.611678 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8626609442060086 and the number of correct results is: 201\n",
      " Iteration: 3160 , loss: 3.622103 Accuracy: 0.664000\n",
      " Iteration: 3170 , loss: 3.611021 Accuracy: 0.700000\n",
      " Iteration: 3180 , loss: 3.632103 Accuracy: 0.704000\n",
      " Iteration: 3190 , loss: 3.603952 Accuracy: 0.704000\n",
      " Iteration: 3200 , loss: 3.633406 Accuracy: 0.664000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 3210 , loss: 3.616767 Accuracy: 0.688000\n",
      " Iteration: 3220 , loss: 3.597118 Accuracy: 0.720000\n",
      " Iteration: 3230 , loss: 3.593358 Accuracy: 0.712000\n",
      " Iteration: 3240 , loss: 3.640774 Accuracy: 0.664000\n",
      " Iteration: 3250 , loss: 3.648888 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 3260 , loss: 3.627345 Accuracy: 0.664000\n",
      " Iteration: 3270 , loss: 3.618018 Accuracy: 0.676000\n",
      " Iteration: 3280 , loss: 3.617460 Accuracy: 0.672000\n",
      " Iteration: 3290 , loss: 3.586082 Accuracy: 0.708000\n",
      " Iteration: 3300 , loss: 3.627773 Accuracy: 0.648000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3310 , loss: 3.653153 Accuracy: 0.644000\n",
      " Iteration: 3320 , loss: 3.660687 Accuracy: 0.668000\n",
      " Iteration: 3330 , loss: 3.647429 Accuracy: 0.644000\n",
      " Iteration: 3340 , loss: 3.587311 Accuracy: 0.724000\n",
      " Iteration: 3350 , loss: 3.631468 Accuracy: 0.656000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 3360 , loss: 3.560575 Accuracy: 0.732000\n",
      " Iteration: 3370 , loss: 3.634268 Accuracy: 0.680000\n",
      " Iteration: 3380 , loss: 3.620739 Accuracy: 0.664000\n",
      " Iteration: 3390 , loss: 3.649321 Accuracy: 0.684000\n",
      " Iteration: 3400 , loss: 3.617800 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.871244635193133 and the number of correct results is: 203\n",
      " Iteration: 3410 , loss: 3.638813 Accuracy: 0.660000\n",
      " Iteration: 3420 , loss: 3.598472 Accuracy: 0.704000\n",
      " Iteration: 3430 , loss: 3.610209 Accuracy: 0.708000\n",
      " Iteration: 3440 , loss: 3.610567 Accuracy: 0.680000\n",
      " Iteration: 3450 , loss: 3.608076 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 3460 , loss: 3.603716 Accuracy: 0.688000\n",
      " Iteration: 3470 , loss: 3.620424 Accuracy: 0.684000\n",
      " Iteration: 3480 , loss: 3.629690 Accuracy: 0.668000\n",
      " Iteration: 3490 , loss: 3.630611 Accuracy: 0.680000\n",
      " Iteration: 3500 , loss: 3.614453 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8755364806866953 and the number of correct results is: 204\n",
      " Iteration: 3510 , loss: 3.588072 Accuracy: 0.716000\n",
      " Iteration: 3520 , loss: 3.620473 Accuracy: 0.672000\n",
      " Iteration: 3530 , loss: 3.588855 Accuracy: 0.728000\n",
      " Iteration: 3540 , loss: 3.589032 Accuracy: 0.708000\n",
      " Iteration: 3550 , loss: 3.635675 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3560 , loss: 3.610941 Accuracy: 0.672000\n",
      " Iteration: 3570 , loss: 3.616111 Accuracy: 0.680000\n",
      " Iteration: 3580 , loss: 3.605581 Accuracy: 0.668000\n",
      " Iteration: 3590 , loss: 3.592822 Accuracy: 0.724000\n",
      " Iteration: 3600 , loss: 3.606120 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3610 , loss: 3.608651 Accuracy: 0.700000\n",
      " Iteration: 3620 , loss: 3.629846 Accuracy: 0.660000\n",
      " Iteration: 3630 , loss: 3.596940 Accuracy: 0.704000\n",
      " Iteration: 3640 , loss: 3.594761 Accuracy: 0.712000\n",
      " Iteration: 3650 , loss: 3.581188 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 3660 , loss: 3.632570 Accuracy: 0.680000\n",
      " Iteration: 3670 , loss: 3.601886 Accuracy: 0.660000\n",
      " Iteration: 3680 , loss: 3.600324 Accuracy: 0.664000\n",
      " Iteration: 3690 , loss: 3.593372 Accuracy: 0.720000\n",
      " Iteration: 3700 , loss: 3.613291 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8669527896995708 and the number of correct results is: 202\n",
      " Iteration: 3710 , loss: 3.636380 Accuracy: 0.708000\n",
      " Iteration: 3720 , loss: 3.589260 Accuracy: 0.696000\n",
      " Iteration: 3730 , loss: 3.603599 Accuracy: 0.668000\n",
      " Iteration: 3740 , loss: 3.605748 Accuracy: 0.704000\n",
      " Iteration: 3750 , loss: 3.587331 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3760 , loss: 3.629983 Accuracy: 0.672000\n",
      " Iteration: 3770 , loss: 3.599881 Accuracy: 0.696000\n",
      " Iteration: 3780 , loss: 3.547865 Accuracy: 0.744000\n",
      " Iteration: 3790 , loss: 3.649734 Accuracy: 0.676000\n",
      " Iteration: 3800 , loss: 3.584140 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3810 , loss: 3.605438 Accuracy: 0.716000\n",
      " Iteration: 3820 , loss: 3.583644 Accuracy: 0.736000\n",
      " Iteration: 3830 , loss: 3.592613 Accuracy: 0.712000\n",
      " Iteration: 3840 , loss: 3.585585 Accuracy: 0.696000\n",
      " Iteration: 3850 , loss: 3.605373 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 3860 , loss: 3.590963 Accuracy: 0.708000\n",
      " Iteration: 3870 , loss: 3.600223 Accuracy: 0.700000\n",
      " Iteration: 3880 , loss: 3.541653 Accuracy: 0.764000\n",
      " Iteration: 3890 , loss: 3.585368 Accuracy: 0.696000\n",
      " Iteration: 3900 , loss: 3.597339 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3910 , loss: 3.589590 Accuracy: 0.708000\n",
      " Iteration: 3920 , loss: 3.610605 Accuracy: 0.660000\n",
      " Iteration: 3930 , loss: 3.611676 Accuracy: 0.672000\n",
      " Iteration: 3940 , loss: 3.594961 Accuracy: 0.732000\n",
      " Iteration: 3950 , loss: 3.609049 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 3960 , loss: 3.574792 Accuracy: 0.708000\n",
      " Iteration: 3970 , loss: 3.603995 Accuracy: 0.668000\n",
      " Iteration: 3980 , loss: 3.614555 Accuracy: 0.688000\n",
      " Iteration: 3990 , loss: 3.553547 Accuracy: 0.756000\n",
      " Iteration: 4000 , loss: 3.624864 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 4010 , loss: 3.557406 Accuracy: 0.756000\n",
      " Iteration: 4020 , loss: 3.612882 Accuracy: 0.684000\n",
      " Iteration: 4030 , loss: 3.600569 Accuracy: 0.724000\n",
      " Iteration: 4040 , loss: 3.622717 Accuracy: 0.672000\n",
      " Iteration: 4050 , loss: 3.575151 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 4060 , loss: 3.607147 Accuracy: 0.684000\n",
      " Iteration: 4070 , loss: 3.611784 Accuracy: 0.680000\n",
      " Iteration: 4080 , loss: 3.607747 Accuracy: 0.664000\n",
      " Iteration: 4090 , loss: 3.579530 Accuracy: 0.740000\n",
      " Iteration: 4100 , loss: 3.537702 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 4110 , loss: 3.615878 Accuracy: 0.688000\n",
      " Iteration: 4120 , loss: 3.570858 Accuracy: 0.716000\n",
      " Iteration: 4130 , loss: 3.612022 Accuracy: 0.676000\n",
      " Iteration: 4140 , loss: 3.579297 Accuracy: 0.708000\n",
      " Iteration: 4150 , loss: 3.561140 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 4160 , loss: 3.560525 Accuracy: 0.740000\n",
      " Iteration: 4170 , loss: 3.571355 Accuracy: 0.696000\n",
      " Iteration: 4180 , loss: 3.589431 Accuracy: 0.712000\n",
      " Iteration: 4190 , loss: 3.562418 Accuracy: 0.740000\n",
      " Iteration: 4200 , loss: 3.569762 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 4210 , loss: 3.591798 Accuracy: 0.736000\n",
      " Iteration: 4220 , loss: 3.578416 Accuracy: 0.720000\n",
      " Iteration: 4230 , loss: 3.544538 Accuracy: 0.776000\n",
      " Iteration: 4240 , loss: 3.587402 Accuracy: 0.720000\n",
      " Iteration: 4250 , loss: 3.572235 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 4260 , loss: 3.593079 Accuracy: 0.712000\n",
      " Iteration: 4270 , loss: 3.612949 Accuracy: 0.664000\n",
      " Iteration: 4280 , loss: 3.606005 Accuracy: 0.680000\n",
      " Iteration: 4290 , loss: 3.592910 Accuracy: 0.696000\n",
      " Iteration: 4300 , loss: 3.637913 Accuracy: 0.644000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 4310 , loss: 3.594132 Accuracy: 0.692000\n",
      " Iteration: 4320 , loss: 3.600510 Accuracy: 0.668000\n",
      " Iteration: 4330 , loss: 3.604259 Accuracy: 0.688000\n",
      " Iteration: 4340 , loss: 3.591527 Accuracy: 0.720000\n",
      " Iteration: 4350 , loss: 3.619524 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 4360 , loss: 3.562427 Accuracy: 0.728000\n",
      " Iteration: 4370 , loss: 3.577548 Accuracy: 0.736000\n",
      " Iteration: 4380 , loss: 3.588643 Accuracy: 0.712000\n",
      " Iteration: 4390 , loss: 3.589731 Accuracy: 0.684000\n",
      " Iteration: 4400 , loss: 3.620726 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 4410 , loss: 3.515782 Accuracy: 0.768000\n",
      " Iteration: 4420 , loss: 3.551965 Accuracy: 0.716000\n",
      " Iteration: 4430 , loss: 3.566030 Accuracy: 0.724000\n",
      " Iteration: 4440 , loss: 3.533610 Accuracy: 0.792000\n",
      " Iteration: 4450 , loss: 3.567661 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 4460 , loss: 3.543646 Accuracy: 0.720000\n",
      " Iteration: 4470 , loss: 3.586615 Accuracy: 0.716000\n",
      " Iteration: 4480 , loss: 3.594836 Accuracy: 0.664000\n",
      " Iteration: 4490 , loss: 3.567662 Accuracy: 0.728000\n",
      " Iteration: 4500 , loss: 3.576890 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 4510 , loss: 3.574433 Accuracy: 0.716000\n",
      " Iteration: 4520 , loss: 3.537088 Accuracy: 0.752000\n",
      " Iteration: 4530 , loss: 3.569838 Accuracy: 0.752000\n",
      " Iteration: 4540 , loss: 3.614511 Accuracy: 0.688000\n",
      " Iteration: 4550 , loss: 3.580821 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 4560 , loss: 3.569091 Accuracy: 0.708000\n",
      " Iteration: 4570 , loss: 3.595760 Accuracy: 0.656000\n",
      " Iteration: 4580 , loss: 3.582514 Accuracy: 0.728000\n",
      " Iteration: 4590 , loss: 3.561837 Accuracy: 0.724000\n",
      " Iteration: 4600 , loss: 3.543099 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 4610 , loss: 3.571103 Accuracy: 0.736000\n",
      " Iteration: 4620 , loss: 3.548037 Accuracy: 0.748000\n",
      " Iteration: 4630 , loss: 3.537362 Accuracy: 0.812000\n",
      " Iteration: 4640 , loss: 3.558045 Accuracy: 0.736000\n",
      " Iteration: 4650 , loss: 3.591279 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 4660 , loss: 3.560083 Accuracy: 0.720000\n",
      " Iteration: 4670 , loss: 3.583223 Accuracy: 0.732000\n",
      " Iteration: 4680 , loss: 3.590116 Accuracy: 0.696000\n",
      " Iteration: 4690 , loss: 3.534497 Accuracy: 0.744000\n",
      " Iteration: 4700 , loss: 3.596353 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 4710 , loss: 3.564497 Accuracy: 0.760000\n",
      " Iteration: 4720 , loss: 3.585984 Accuracy: 0.708000\n",
      " Iteration: 4730 , loss: 3.566399 Accuracy: 0.712000\n",
      " Iteration: 4740 , loss: 3.552430 Accuracy: 0.744000\n",
      " Iteration: 4750 , loss: 3.588840 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 4760 , loss: 3.566540 Accuracy: 0.728000\n",
      " Iteration: 4770 , loss: 3.538804 Accuracy: 0.764000\n",
      " Iteration: 4780 , loss: 3.593276 Accuracy: 0.692000\n",
      " Iteration: 4790 , loss: 3.588547 Accuracy: 0.688000\n",
      " Iteration: 4800 , loss: 3.582202 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 4810 , loss: 3.539281 Accuracy: 0.756000\n",
      " Iteration: 4820 , loss: 3.587468 Accuracy: 0.716000\n",
      " Iteration: 4830 , loss: 3.558308 Accuracy: 0.720000\n",
      " Iteration: 4840 , loss: 3.572706 Accuracy: 0.712000\n",
      " Iteration: 4850 , loss: 3.566464 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 4860 , loss: 3.553759 Accuracy: 0.744000\n",
      " Iteration: 4870 , loss: 3.550283 Accuracy: 0.740000\n",
      " Iteration: 4880 , loss: 3.563581 Accuracy: 0.724000\n",
      " Iteration: 4890 , loss: 3.581125 Accuracy: 0.704000\n",
      " Iteration: 4900 , loss: 3.616012 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 4910 , loss: 3.571731 Accuracy: 0.716000\n",
      " Iteration: 4920 , loss: 3.550244 Accuracy: 0.748000\n",
      " Iteration: 4930 , loss: 3.574858 Accuracy: 0.708000\n",
      " Iteration: 4940 , loss: 3.549591 Accuracy: 0.732000\n",
      " Iteration: 4950 , loss: 3.532782 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 4960 , loss: 3.598480 Accuracy: 0.644000\n",
      " Iteration: 4970 , loss: 3.581786 Accuracy: 0.720000\n",
      " Iteration: 4980 , loss: 3.570055 Accuracy: 0.708000\n",
      " Iteration: 4990 , loss: 3.564422 Accuracy: 0.748000\n",
      " Iteration: 5000 , loss: 3.594215 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 5010 , loss: 3.586200 Accuracy: 0.704000\n",
      " Iteration: 5020 , loss: 3.554298 Accuracy: 0.724000\n",
      " Iteration: 5030 , loss: 3.563773 Accuracy: 0.744000\n",
      " Iteration: 5040 , loss: 3.595546 Accuracy: 0.688000\n",
      " Iteration: 5050 , loss: 3.552347 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 5060 , loss: 3.551993 Accuracy: 0.732000\n",
      " Iteration: 5070 , loss: 3.540681 Accuracy: 0.776000\n",
      " Iteration: 5080 , loss: 3.579570 Accuracy: 0.716000\n",
      " Iteration: 5090 , loss: 3.586708 Accuracy: 0.692000\n",
      " Iteration: 5100 , loss: 3.590133 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 5110 , loss: 3.575251 Accuracy: 0.752000\n",
      " Iteration: 5120 , loss: 3.549679 Accuracy: 0.748000\n",
      " Iteration: 5130 , loss: 3.553282 Accuracy: 0.740000\n",
      " Iteration: 5140 , loss: 3.580298 Accuracy: 0.708000\n",
      " Iteration: 5150 , loss: 3.581883 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 5160 , loss: 3.543390 Accuracy: 0.748000\n",
      " Iteration: 5170 , loss: 3.546376 Accuracy: 0.756000\n",
      " Iteration: 5180 , loss: 3.564781 Accuracy: 0.736000\n",
      " Iteration: 5190 , loss: 3.555398 Accuracy: 0.740000\n",
      " Iteration: 5200 , loss: 3.546671 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 5210 , loss: 3.554500 Accuracy: 0.740000\n",
      " Iteration: 5220 , loss: 3.538377 Accuracy: 0.748000\n",
      " Iteration: 5230 , loss: 3.587473 Accuracy: 0.716000\n",
      " Iteration: 5240 , loss: 3.566352 Accuracy: 0.720000\n",
      " Iteration: 5250 , loss: 3.550894 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 5260 , loss: 3.546200 Accuracy: 0.736000\n",
      " Iteration: 5270 , loss: 3.597052 Accuracy: 0.692000\n",
      " Iteration: 5280 , loss: 3.554245 Accuracy: 0.728000\n",
      " Iteration: 5290 , loss: 3.523083 Accuracy: 0.776000\n",
      " Iteration: 5300 , loss: 3.549360 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 5310 , loss: 3.571518 Accuracy: 0.716000\n",
      " Iteration: 5320 , loss: 3.586553 Accuracy: 0.684000\n",
      " Iteration: 5330 , loss: 3.534473 Accuracy: 0.728000\n",
      " Iteration: 5340 , loss: 3.550340 Accuracy: 0.748000\n",
      " Iteration: 5350 , loss: 3.578815 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 5360 , loss: 3.547759 Accuracy: 0.716000\n",
      " Iteration: 5370 , loss: 3.586842 Accuracy: 0.700000\n",
      " Iteration: 5380 , loss: 3.548633 Accuracy: 0.740000\n",
      " Iteration: 5390 , loss: 3.599203 Accuracy: 0.672000\n",
      " Iteration: 5400 , loss: 3.590925 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 5410 , loss: 3.542109 Accuracy: 0.768000\n",
      " Iteration: 5420 , loss: 3.553033 Accuracy: 0.704000\n",
      " Iteration: 5430 , loss: 3.519017 Accuracy: 0.792000\n",
      " Iteration: 5440 , loss: 3.534389 Accuracy: 0.760000\n",
      " Iteration: 5450 , loss: 3.561278 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 5460 , loss: 3.569719 Accuracy: 0.696000\n",
      " Iteration: 5470 , loss: 3.542256 Accuracy: 0.752000\n",
      " Iteration: 5480 , loss: 3.590156 Accuracy: 0.680000\n",
      " Iteration: 5490 , loss: 3.562270 Accuracy: 0.708000\n",
      " Iteration: 5500 , loss: 3.588008 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 5510 , loss: 3.534186 Accuracy: 0.772000\n",
      " Iteration: 5520 , loss: 3.536395 Accuracy: 0.740000\n",
      " Iteration: 5530 , loss: 3.577517 Accuracy: 0.672000\n",
      " Iteration: 5540 , loss: 3.536351 Accuracy: 0.740000\n",
      " Iteration: 5550 , loss: 3.516394 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 5560 , loss: 3.529209 Accuracy: 0.752000\n",
      " Iteration: 5570 , loss: 3.541168 Accuracy: 0.764000\n",
      " Iteration: 5580 , loss: 3.555712 Accuracy: 0.736000\n",
      " Iteration: 5590 , loss: 3.522107 Accuracy: 0.764000\n",
      " Iteration: 5600 , loss: 3.539145 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 5610 , loss: 3.551949 Accuracy: 0.736000\n",
      " Iteration: 5620 , loss: 3.548318 Accuracy: 0.716000\n",
      " Iteration: 5630 , loss: 3.536627 Accuracy: 0.748000\n",
      " Iteration: 5640 , loss: 3.565589 Accuracy: 0.716000\n",
      " Iteration: 5650 , loss: 3.566488 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 5660 , loss: 3.582740 Accuracy: 0.680000\n",
      " Iteration: 5670 , loss: 3.556014 Accuracy: 0.748000\n",
      " Iteration: 5680 , loss: 3.562082 Accuracy: 0.716000\n",
      " Iteration: 5690 , loss: 3.539239 Accuracy: 0.740000\n",
      " Iteration: 5700 , loss: 3.543246 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 5710 , loss: 3.542786 Accuracy: 0.736000\n",
      " Iteration: 5720 , loss: 3.536386 Accuracy: 0.768000\n",
      " Iteration: 5730 , loss: 3.563328 Accuracy: 0.728000\n",
      " Iteration: 5740 , loss: 3.528727 Accuracy: 0.768000\n",
      " Iteration: 5750 , loss: 3.527211 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 5760 , loss: 3.530919 Accuracy: 0.748000\n",
      " Iteration: 5770 , loss: 3.540618 Accuracy: 0.748000\n",
      " Iteration: 5780 , loss: 3.563411 Accuracy: 0.728000\n",
      " Iteration: 5790 , loss: 3.582993 Accuracy: 0.700000\n",
      " Iteration: 5800 , loss: 3.555613 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 5810 , loss: 3.532880 Accuracy: 0.784000\n",
      " Iteration: 5820 , loss: 3.528574 Accuracy: 0.784000\n",
      " Iteration: 5830 , loss: 3.548290 Accuracy: 0.752000\n",
      " Iteration: 5840 , loss: 3.532950 Accuracy: 0.772000\n",
      " Iteration: 5850 , loss: 3.547444 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 5860 , loss: 3.540764 Accuracy: 0.776000\n",
      " Iteration: 5870 , loss: 3.582728 Accuracy: 0.700000\n",
      " Iteration: 5880 , loss: 3.562782 Accuracy: 0.728000\n",
      " Iteration: 5890 , loss: 3.572699 Accuracy: 0.736000\n",
      " Iteration: 5900 , loss: 3.568097 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 5910 , loss: 3.536721 Accuracy: 0.756000\n",
      " Iteration: 5920 , loss: 3.526972 Accuracy: 0.744000\n",
      " Iteration: 5930 , loss: 3.550884 Accuracy: 0.736000\n",
      " Iteration: 5940 , loss: 3.560671 Accuracy: 0.732000\n",
      " Iteration: 5950 , loss: 3.544346 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 5960 , loss: 3.550059 Accuracy: 0.752000\n",
      " Iteration: 5970 , loss: 3.545780 Accuracy: 0.736000\n",
      " Iteration: 5980 , loss: 3.582220 Accuracy: 0.692000\n",
      " Iteration: 5990 , loss: 3.542737 Accuracy: 0.736000\n",
      " Iteration: 6000 , loss: 3.558545 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 6010 , loss: 3.542823 Accuracy: 0.748000\n",
      " Iteration: 6020 , loss: 3.540471 Accuracy: 0.756000\n",
      " Iteration: 6030 , loss: 3.544468 Accuracy: 0.724000\n",
      " Iteration: 6040 , loss: 3.567780 Accuracy: 0.716000\n",
      " Iteration: 6050 , loss: 3.582881 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 6060 , loss: 3.524676 Accuracy: 0.768000\n",
      " Iteration: 6070 , loss: 3.540168 Accuracy: 0.732000\n",
      " Iteration: 6080 , loss: 3.574715 Accuracy: 0.712000\n",
      " Iteration: 6090 , loss: 3.541497 Accuracy: 0.760000\n",
      " Iteration: 6100 , loss: 3.533809 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 6110 , loss: 3.540441 Accuracy: 0.736000\n",
      " Iteration: 6120 , loss: 3.598057 Accuracy: 0.660000\n",
      " Iteration: 6130 , loss: 3.552069 Accuracy: 0.744000\n",
      " Iteration: 6140 , loss: 3.572268 Accuracy: 0.672000\n",
      " Iteration: 6150 , loss: 3.512900 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 6160 , loss: 3.534385 Accuracy: 0.720000\n",
      " Iteration: 6170 , loss: 3.540059 Accuracy: 0.736000\n",
      " Iteration: 6180 , loss: 3.537237 Accuracy: 0.752000\n",
      " Iteration: 6190 , loss: 3.554658 Accuracy: 0.752000\n",
      " Iteration: 6200 , loss: 3.572940 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 6210 , loss: 3.575279 Accuracy: 0.708000\n",
      " Iteration: 6220 , loss: 3.555876 Accuracy: 0.712000\n",
      " Iteration: 6230 , loss: 3.569845 Accuracy: 0.696000\n",
      " Iteration: 6240 , loss: 3.527915 Accuracy: 0.784000\n",
      " Iteration: 6250 , loss: 3.544788 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 6260 , loss: 3.554378 Accuracy: 0.700000\n",
      " Iteration: 6270 , loss: 3.542169 Accuracy: 0.724000\n",
      " Iteration: 6280 , loss: 3.506585 Accuracy: 0.764000\n",
      " Iteration: 6290 , loss: 3.555169 Accuracy: 0.708000\n",
      " Iteration: 6300 , loss: 3.551976 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 6310 , loss: 3.548378 Accuracy: 0.736000\n",
      " Iteration: 6320 , loss: 3.548733 Accuracy: 0.744000\n",
      " Iteration: 6330 , loss: 3.573964 Accuracy: 0.704000\n",
      " Iteration: 6340 , loss: 3.529834 Accuracy: 0.768000\n",
      " Iteration: 6350 , loss: 3.550578 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 6360 , loss: 3.564709 Accuracy: 0.708000\n",
      " Iteration: 6370 , loss: 3.521630 Accuracy: 0.768000\n",
      " Iteration: 6380 , loss: 3.576266 Accuracy: 0.696000\n",
      " Iteration: 6390 , loss: 3.563558 Accuracy: 0.740000\n",
      " Iteration: 6400 , loss: 3.543268 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 6410 , loss: 3.564793 Accuracy: 0.736000\n",
      " Iteration: 6420 , loss: 3.552701 Accuracy: 0.744000\n",
      " Iteration: 6430 , loss: 3.531487 Accuracy: 0.772000\n",
      " Iteration: 6440 , loss: 3.564331 Accuracy: 0.716000\n",
      " Iteration: 6450 , loss: 3.537895 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 6460 , loss: 3.536871 Accuracy: 0.744000\n",
      " Iteration: 6470 , loss: 3.527666 Accuracy: 0.756000\n",
      " Iteration: 6480 , loss: 3.520600 Accuracy: 0.760000\n",
      " Iteration: 6490 , loss: 3.514759 Accuracy: 0.756000\n",
      " Iteration: 6500 , loss: 3.557744 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 6510 , loss: 3.548118 Accuracy: 0.712000\n",
      " Iteration: 6520 , loss: 3.501229 Accuracy: 0.796000\n",
      " Iteration: 6530 , loss: 3.529531 Accuracy: 0.744000\n",
      " Iteration: 6540 , loss: 3.495252 Accuracy: 0.788000\n",
      " Iteration: 6550 , loss: 3.563761 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8798283261802575 and the number of correct results is: 205\n",
      " Iteration: 6560 , loss: 3.557414 Accuracy: 0.680000\n",
      " Iteration: 6570 , loss: 3.530035 Accuracy: 0.772000\n",
      " Iteration: 6580 , loss: 3.528588 Accuracy: 0.764000\n",
      " Iteration: 6590 , loss: 3.537587 Accuracy: 0.760000\n",
      " Iteration: 6600 , loss: 3.546384 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 6610 , loss: 3.494978 Accuracy: 0.788000\n",
      " Iteration: 6620 , loss: 3.555960 Accuracy: 0.728000\n",
      " Iteration: 6630 , loss: 3.500304 Accuracy: 0.788000\n",
      " Iteration: 6640 , loss: 3.513603 Accuracy: 0.764000\n",
      " Iteration: 6650 , loss: 3.548647 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 6660 , loss: 3.515305 Accuracy: 0.788000\n",
      " Iteration: 6670 , loss: 3.537746 Accuracy: 0.752000\n",
      " Iteration: 6680 , loss: 3.526733 Accuracy: 0.740000\n",
      " Iteration: 6690 , loss: 3.557858 Accuracy: 0.696000\n",
      " Iteration: 6700 , loss: 3.513414 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 6710 , loss: 3.544138 Accuracy: 0.756000\n",
      " Iteration: 6720 , loss: 3.512981 Accuracy: 0.804000\n",
      " Iteration: 6730 , loss: 3.506360 Accuracy: 0.784000\n",
      " Iteration: 6740 , loss: 3.555812 Accuracy: 0.752000\n",
      " Iteration: 6750 , loss: 3.535965 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 6760 , loss: 3.572024 Accuracy: 0.700000\n",
      " Iteration: 6770 , loss: 3.571560 Accuracy: 0.712000\n",
      " Iteration: 6780 , loss: 3.542932 Accuracy: 0.736000\n",
      " Iteration: 6790 , loss: 3.540967 Accuracy: 0.728000\n",
      " Iteration: 6800 , loss: 3.542439 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 6810 , loss: 3.551953 Accuracy: 0.756000\n",
      " Iteration: 6820 , loss: 3.554088 Accuracy: 0.696000\n",
      " Iteration: 6830 , loss: 3.514413 Accuracy: 0.784000\n",
      " Iteration: 6840 , loss: 3.550856 Accuracy: 0.748000\n",
      " Iteration: 6850 , loss: 3.551250 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 6860 , loss: 3.526539 Accuracy: 0.776000\n",
      " Iteration: 6870 , loss: 3.508554 Accuracy: 0.780000\n",
      " Iteration: 6880 , loss: 3.535850 Accuracy: 0.704000\n",
      " Iteration: 6890 , loss: 3.559813 Accuracy: 0.716000\n",
      " Iteration: 6900 , loss: 3.525060 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 6910 , loss: 3.573709 Accuracy: 0.724000\n",
      " Iteration: 6920 , loss: 3.506824 Accuracy: 0.788000\n",
      " Iteration: 6930 , loss: 3.540015 Accuracy: 0.752000\n",
      " Iteration: 6940 , loss: 3.548541 Accuracy: 0.752000\n",
      " Iteration: 6950 , loss: 3.514490 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 6960 , loss: 3.511946 Accuracy: 0.772000\n",
      " Iteration: 6970 , loss: 3.496898 Accuracy: 0.816000\n",
      " Iteration: 6980 , loss: 3.543058 Accuracy: 0.740000\n",
      " Iteration: 6990 , loss: 3.550595 Accuracy: 0.728000\n",
      " Iteration: 7000 , loss: 3.534865 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 7010 , loss: 3.501405 Accuracy: 0.776000\n",
      " Iteration: 7020 , loss: 3.514852 Accuracy: 0.744000\n",
      " Iteration: 7030 , loss: 3.561918 Accuracy: 0.700000\n",
      " Iteration: 7040 , loss: 3.502391 Accuracy: 0.792000\n",
      " Iteration: 7050 , loss: 3.523750 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 7060 , loss: 3.521093 Accuracy: 0.764000\n",
      " Iteration: 7070 , loss: 3.516238 Accuracy: 0.792000\n",
      " Iteration: 7080 , loss: 3.510492 Accuracy: 0.768000\n",
      " Iteration: 7090 , loss: 3.510317 Accuracy: 0.752000\n",
      " Iteration: 7100 , loss: 3.522560 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 7110 , loss: 3.518811 Accuracy: 0.744000\n",
      " Iteration: 7120 , loss: 3.555295 Accuracy: 0.728000\n",
      " Iteration: 7130 , loss: 3.549220 Accuracy: 0.728000\n",
      " Iteration: 7140 , loss: 3.555495 Accuracy: 0.736000\n",
      " Iteration: 7150 , loss: 3.525712 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 7160 , loss: 3.535031 Accuracy: 0.752000\n",
      " Iteration: 7170 , loss: 3.526826 Accuracy: 0.760000\n",
      " Iteration: 7180 , loss: 3.483038 Accuracy: 0.824000\n",
      " Iteration: 7190 , loss: 3.540617 Accuracy: 0.736000\n",
      " Iteration: 7200 , loss: 3.515840 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 7210 , loss: 3.512731 Accuracy: 0.792000\n",
      " Iteration: 7220 , loss: 3.512223 Accuracy: 0.760000\n",
      " Iteration: 7230 , loss: 3.545273 Accuracy: 0.728000\n",
      " Iteration: 7240 , loss: 3.558066 Accuracy: 0.724000\n",
      " Iteration: 7250 , loss: 3.508569 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 7260 , loss: 3.494205 Accuracy: 0.780000\n",
      " Iteration: 7270 , loss: 3.559296 Accuracy: 0.740000\n",
      " Iteration: 7280 , loss: 3.574861 Accuracy: 0.700000\n",
      " Iteration: 7290 , loss: 3.519246 Accuracy: 0.800000\n",
      " Iteration: 7300 , loss: 3.489963 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 7310 , loss: 3.538085 Accuracy: 0.756000\n",
      " Iteration: 7320 , loss: 3.498843 Accuracy: 0.800000\n",
      " Iteration: 7330 , loss: 3.497102 Accuracy: 0.792000\n",
      " Iteration: 7340 , loss: 3.536327 Accuracy: 0.756000\n",
      " Iteration: 7350 , loss: 3.587481 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 7360 , loss: 3.539628 Accuracy: 0.748000\n",
      " Iteration: 7370 , loss: 3.545107 Accuracy: 0.732000\n",
      " Iteration: 7380 , loss: 3.552175 Accuracy: 0.700000\n",
      " Iteration: 7390 , loss: 3.506920 Accuracy: 0.776000\n",
      " Iteration: 7400 , loss: 3.530311 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 7410 , loss: 3.521889 Accuracy: 0.768000\n",
      " Iteration: 7420 , loss: 3.503038 Accuracy: 0.764000\n",
      " Iteration: 7430 , loss: 3.505188 Accuracy: 0.804000\n",
      " Iteration: 7440 , loss: 3.511278 Accuracy: 0.776000\n",
      " Iteration: 7450 , loss: 3.505606 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 7460 , loss: 3.536383 Accuracy: 0.728000\n",
      " Iteration: 7470 , loss: 3.548780 Accuracy: 0.708000\n",
      " Iteration: 7480 , loss: 3.534458 Accuracy: 0.740000\n",
      " Iteration: 7490 , loss: 3.533528 Accuracy: 0.768000\n",
      " Iteration: 7500 , loss: 3.530488 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 7510 , loss: 3.535484 Accuracy: 0.720000\n",
      " Iteration: 7520 , loss: 3.513279 Accuracy: 0.792000\n",
      " Iteration: 7530 , loss: 3.548124 Accuracy: 0.716000\n",
      " Iteration: 7540 , loss: 3.520089 Accuracy: 0.748000\n",
      " Iteration: 7550 , loss: 3.528678 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 7560 , loss: 3.553371 Accuracy: 0.728000\n",
      " Iteration: 7570 , loss: 3.497356 Accuracy: 0.792000\n",
      " Iteration: 7580 , loss: 3.509263 Accuracy: 0.788000\n",
      " Iteration: 7590 , loss: 3.532731 Accuracy: 0.716000\n",
      " Iteration: 7600 , loss: 3.515696 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8841201716738197 and the number of correct results is: 206\n",
      " Iteration: 7610 , loss: 3.527996 Accuracy: 0.776000\n",
      " Iteration: 7620 , loss: 3.500014 Accuracy: 0.772000\n",
      " Iteration: 7630 , loss: 3.527742 Accuracy: 0.728000\n",
      " Iteration: 7640 , loss: 3.539304 Accuracy: 0.748000\n",
      " Iteration: 7650 , loss: 3.520903 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 7660 , loss: 3.547574 Accuracy: 0.752000\n",
      " Iteration: 7670 , loss: 3.496352 Accuracy: 0.752000\n",
      " Iteration: 7680 , loss: 3.510140 Accuracy: 0.788000\n",
      " Iteration: 7690 , loss: 3.539806 Accuracy: 0.728000\n",
      " Iteration: 7700 , loss: 3.548553 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 7710 , loss: 3.501209 Accuracy: 0.800000\n",
      " Iteration: 7720 , loss: 3.514905 Accuracy: 0.740000\n",
      " Iteration: 7730 , loss: 3.526664 Accuracy: 0.732000\n",
      " Iteration: 7740 , loss: 3.502196 Accuracy: 0.784000\n",
      " Iteration: 7750 , loss: 3.492320 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 7760 , loss: 3.536567 Accuracy: 0.736000\n",
      " Iteration: 7770 , loss: 3.506923 Accuracy: 0.760000\n",
      " Iteration: 7780 , loss: 3.538794 Accuracy: 0.716000\n",
      " Iteration: 7790 , loss: 3.487738 Accuracy: 0.792000\n",
      " Iteration: 7800 , loss: 3.527346 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 7810 , loss: 3.520457 Accuracy: 0.756000\n",
      " Iteration: 7820 , loss: 3.513294 Accuracy: 0.748000\n",
      " Iteration: 7830 , loss: 3.495998 Accuracy: 0.776000\n",
      " Iteration: 7840 , loss: 3.543009 Accuracy: 0.728000\n",
      " Iteration: 7850 , loss: 3.488765 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 7860 , loss: 3.496667 Accuracy: 0.808000\n",
      " Iteration: 7870 , loss: 3.525072 Accuracy: 0.752000\n",
      " Iteration: 7880 , loss: 3.510903 Accuracy: 0.800000\n",
      " Iteration: 7890 , loss: 3.536720 Accuracy: 0.728000\n",
      " Iteration: 7900 , loss: 3.503182 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 7910 , loss: 3.523236 Accuracy: 0.720000\n",
      " Iteration: 7920 , loss: 3.544733 Accuracy: 0.736000\n",
      " Iteration: 7930 , loss: 3.504066 Accuracy: 0.788000\n",
      " Iteration: 7940 , loss: 3.527813 Accuracy: 0.732000\n",
      " Iteration: 7950 , loss: 3.527044 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 7960 , loss: 3.521971 Accuracy: 0.740000\n",
      " Iteration: 7970 , loss: 3.550245 Accuracy: 0.736000\n",
      " Iteration: 7980 , loss: 3.554719 Accuracy: 0.732000\n",
      " Iteration: 7990 , loss: 3.516057 Accuracy: 0.768000\n",
      " Iteration: 8000 , loss: 3.505060 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 8010 , loss: 3.524449 Accuracy: 0.752000\n",
      " Iteration: 8020 , loss: 3.494318 Accuracy: 0.776000\n",
      " Iteration: 8030 , loss: 3.506032 Accuracy: 0.744000\n",
      " Iteration: 8040 , loss: 3.576287 Accuracy: 0.712000\n",
      " Iteration: 8050 , loss: 3.516280 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8884120171673819 and the number of correct results is: 207\n",
      " Iteration: 8060 , loss: 3.518176 Accuracy: 0.756000\n",
      " Iteration: 8070 , loss: 3.517735 Accuracy: 0.752000\n",
      " Iteration: 8080 , loss: 3.533321 Accuracy: 0.736000\n",
      " Iteration: 8090 , loss: 3.529573 Accuracy: 0.736000\n",
      " Iteration: 8100 , loss: 3.536530 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8110 , loss: 3.509077 Accuracy: 0.764000\n",
      " Iteration: 8120 , loss: 3.524920 Accuracy: 0.740000\n",
      " Iteration: 8130 , loss: 3.527889 Accuracy: 0.752000\n",
      " Iteration: 8140 , loss: 3.523527 Accuracy: 0.788000\n",
      " Iteration: 8150 , loss: 3.550536 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 8160 , loss: 3.498586 Accuracy: 0.796000\n",
      " Iteration: 8170 , loss: 3.495324 Accuracy: 0.768000\n",
      " Iteration: 8180 , loss: 3.501237 Accuracy: 0.804000\n",
      " Iteration: 8190 , loss: 3.514829 Accuracy: 0.736000\n",
      " Iteration: 8200 , loss: 3.499517 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8210 , loss: 3.518490 Accuracy: 0.740000\n",
      " Iteration: 8220 , loss: 3.529972 Accuracy: 0.756000\n",
      " Iteration: 8230 , loss: 3.520608 Accuracy: 0.740000\n",
      " Iteration: 8240 , loss: 3.517105 Accuracy: 0.780000\n",
      " Iteration: 8250 , loss: 3.499549 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8260 , loss: 3.472605 Accuracy: 0.844000\n",
      " Iteration: 8270 , loss: 3.470897 Accuracy: 0.812000\n",
      " Iteration: 8280 , loss: 3.507137 Accuracy: 0.744000\n",
      " Iteration: 8290 , loss: 3.502917 Accuracy: 0.796000\n",
      " Iteration: 8300 , loss: 3.522698 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8310 , loss: 3.515024 Accuracy: 0.780000\n",
      " Iteration: 8320 , loss: 3.537910 Accuracy: 0.724000\n",
      " Iteration: 8330 , loss: 3.476568 Accuracy: 0.828000\n",
      " Iteration: 8340 , loss: 3.513337 Accuracy: 0.780000\n",
      " Iteration: 8350 , loss: 3.553949 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 8360 , loss: 3.482488 Accuracy: 0.792000\n",
      " Iteration: 8370 , loss: 3.523175 Accuracy: 0.756000\n",
      " Iteration: 8380 , loss: 3.487226 Accuracy: 0.784000\n",
      " Iteration: 8390 , loss: 3.495762 Accuracy: 0.744000\n",
      " Iteration: 8400 , loss: 3.531284 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 8410 , loss: 3.486096 Accuracy: 0.792000\n",
      " Iteration: 8420 , loss: 3.500680 Accuracy: 0.784000\n",
      " Iteration: 8430 , loss: 3.544570 Accuracy: 0.724000\n",
      " Iteration: 8440 , loss: 3.515187 Accuracy: 0.776000\n",
      " Iteration: 8450 , loss: 3.536833 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 8460 , loss: 3.512090 Accuracy: 0.760000\n",
      " Iteration: 8470 , loss: 3.491820 Accuracy: 0.816000\n",
      " Iteration: 8480 , loss: 3.522167 Accuracy: 0.772000\n",
      " Iteration: 8490 , loss: 3.554330 Accuracy: 0.704000\n",
      " Iteration: 8500 , loss: 3.521732 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 8510 , loss: 3.557882 Accuracy: 0.700000\n",
      " Iteration: 8520 , loss: 3.543957 Accuracy: 0.748000\n",
      " Iteration: 8530 , loss: 3.520037 Accuracy: 0.764000\n",
      " Iteration: 8540 , loss: 3.480639 Accuracy: 0.800000\n",
      " Iteration: 8550 , loss: 3.521331 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8560 , loss: 3.474701 Accuracy: 0.824000\n",
      " Iteration: 8570 , loss: 3.526802 Accuracy: 0.744000\n",
      " Iteration: 8580 , loss: 3.522114 Accuracy: 0.748000\n",
      " Iteration: 8590 , loss: 3.525242 Accuracy: 0.756000\n",
      " Iteration: 8600 , loss: 3.500159 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8610 , loss: 3.520903 Accuracy: 0.784000\n",
      " Iteration: 8620 , loss: 3.504844 Accuracy: 0.788000\n",
      " Iteration: 8630 , loss: 3.468311 Accuracy: 0.812000\n",
      " Iteration: 8640 , loss: 3.510467 Accuracy: 0.764000\n",
      " Iteration: 8650 , loss: 3.494148 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 8660 , loss: 3.512285 Accuracy: 0.756000\n",
      " Iteration: 8670 , loss: 3.506561 Accuracy: 0.756000\n",
      " Iteration: 8680 , loss: 3.483211 Accuracy: 0.796000\n",
      " Iteration: 8690 , loss: 3.524467 Accuracy: 0.752000\n",
      " Iteration: 8700 , loss: 3.532232 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8710 , loss: 3.497699 Accuracy: 0.776000\n",
      " Iteration: 8720 , loss: 3.521713 Accuracy: 0.740000\n",
      " Iteration: 8730 , loss: 3.474029 Accuracy: 0.812000\n",
      " Iteration: 8740 , loss: 3.511590 Accuracy: 0.744000\n",
      " Iteration: 8750 , loss: 3.532043 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8927038626609443 and the number of correct results is: 208\n",
      " Iteration: 8760 , loss: 3.505537 Accuracy: 0.748000\n",
      " Iteration: 8770 , loss: 3.472357 Accuracy: 0.804000\n",
      " Iteration: 8780 , loss: 3.498277 Accuracy: 0.756000\n",
      " Iteration: 8790 , loss: 3.505828 Accuracy: 0.756000\n",
      " Iteration: 8800 , loss: 3.512569 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 8810 , loss: 3.491098 Accuracy: 0.784000\n",
      " Iteration: 8820 , loss: 3.512079 Accuracy: 0.756000\n",
      " Iteration: 8830 , loss: 3.529260 Accuracy: 0.724000\n",
      " Iteration: 8840 , loss: 3.483165 Accuracy: 0.792000\n",
      " Iteration: 8850 , loss: 3.471051 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 8860 , loss: 3.545127 Accuracy: 0.736000\n",
      " Iteration: 8870 , loss: 3.503387 Accuracy: 0.764000\n",
      " Iteration: 8880 , loss: 3.497252 Accuracy: 0.788000\n",
      " Iteration: 8890 , loss: 3.502665 Accuracy: 0.792000\n",
      " Iteration: 8900 , loss: 3.527447 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 8910 , loss: 3.523337 Accuracy: 0.764000\n",
      " Iteration: 8920 , loss: 3.541475 Accuracy: 0.740000\n",
      " Iteration: 8930 , loss: 3.475441 Accuracy: 0.804000\n",
      " Iteration: 8940 , loss: 3.553374 Accuracy: 0.704000\n",
      " Iteration: 8950 , loss: 3.535870 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 8960 , loss: 3.486865 Accuracy: 0.792000\n",
      " Iteration: 8970 , loss: 3.551385 Accuracy: 0.716000\n",
      " Iteration: 8980 , loss: 3.489827 Accuracy: 0.772000\n",
      " Iteration: 8990 , loss: 3.502081 Accuracy: 0.748000\n",
      " Iteration: 9000 , loss: 3.496365 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 9010 , loss: 3.507633 Accuracy: 0.784000\n",
      " Iteration: 9020 , loss: 3.501701 Accuracy: 0.784000\n",
      " Iteration: 9030 , loss: 3.488311 Accuracy: 0.792000\n",
      " Iteration: 9040 , loss: 3.529027 Accuracy: 0.780000\n",
      " Iteration: 9050 , loss: 3.501493 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 9060 , loss: 3.503996 Accuracy: 0.780000\n",
      " Iteration: 9070 , loss: 3.482003 Accuracy: 0.780000\n",
      " Iteration: 9080 , loss: 3.489525 Accuracy: 0.764000\n",
      " Iteration: 9090 , loss: 3.533442 Accuracy: 0.728000\n",
      " Iteration: 9100 , loss: 3.494299 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 9110 , loss: 3.494584 Accuracy: 0.760000\n",
      " Iteration: 9120 , loss: 3.506953 Accuracy: 0.776000\n",
      " Iteration: 9130 , loss: 3.529513 Accuracy: 0.748000\n",
      " Iteration: 9140 , loss: 3.491301 Accuracy: 0.780000\n",
      " Iteration: 9150 , loss: 3.511383 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 9160 , loss: 3.517544 Accuracy: 0.772000\n",
      " Iteration: 9170 , loss: 3.505973 Accuracy: 0.760000\n",
      " Iteration: 9180 , loss: 3.498681 Accuracy: 0.776000\n",
      " Iteration: 9190 , loss: 3.519004 Accuracy: 0.748000\n",
      " Iteration: 9200 , loss: 3.519000 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 9210 , loss: 3.521887 Accuracy: 0.760000\n",
      " Iteration: 9220 , loss: 3.524455 Accuracy: 0.748000\n",
      " Iteration: 9230 , loss: 3.485872 Accuracy: 0.784000\n",
      " Iteration: 9240 , loss: 3.539291 Accuracy: 0.716000\n",
      " Iteration: 9250 , loss: 3.505026 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 9260 , loss: 3.515084 Accuracy: 0.744000\n",
      " Iteration: 9270 , loss: 3.512821 Accuracy: 0.772000\n",
      " Iteration: 9280 , loss: 3.478773 Accuracy: 0.788000\n",
      " Iteration: 9290 , loss: 3.523615 Accuracy: 0.756000\n",
      " Iteration: 9300 , loss: 3.497103 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 9310 , loss: 3.487812 Accuracy: 0.768000\n",
      " Iteration: 9320 , loss: 3.484278 Accuracy: 0.780000\n",
      " Iteration: 9330 , loss: 3.505955 Accuracy: 0.776000\n",
      " Iteration: 9340 , loss: 3.501265 Accuracy: 0.752000\n",
      " Iteration: 9350 , loss: 3.492279 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 9360 , loss: 3.556848 Accuracy: 0.704000\n",
      " Iteration: 9370 , loss: 3.522575 Accuracy: 0.728000\n",
      " Iteration: 9380 , loss: 3.468158 Accuracy: 0.824000\n",
      " Iteration: 9390 , loss: 3.479312 Accuracy: 0.792000\n",
      " Iteration: 9400 , loss: 3.540112 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 9410 , loss: 3.475445 Accuracy: 0.796000\n",
      " Iteration: 9420 , loss: 3.508896 Accuracy: 0.784000\n",
      " Iteration: 9430 , loss: 3.487007 Accuracy: 0.796000\n",
      " Iteration: 9440 , loss: 3.491889 Accuracy: 0.760000\n",
      " Iteration: 9450 , loss: 3.529230 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 9460 , loss: 3.497376 Accuracy: 0.772000\n",
      " Iteration: 9470 , loss: 3.534220 Accuracy: 0.736000\n",
      " Iteration: 9480 , loss: 3.475473 Accuracy: 0.800000\n",
      " Iteration: 9490 , loss: 3.486478 Accuracy: 0.784000\n",
      " Iteration: 9500 , loss: 3.526284 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 9510 , loss: 3.523720 Accuracy: 0.760000\n",
      " Iteration: 9520 , loss: 3.508369 Accuracy: 0.760000\n",
      " Iteration: 9530 , loss: 3.506244 Accuracy: 0.772000\n",
      " Iteration: 9540 , loss: 3.528088 Accuracy: 0.740000\n",
      " Iteration: 9550 , loss: 3.473242 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 9560 , loss: 3.505783 Accuracy: 0.752000\n",
      " Iteration: 9570 , loss: 3.500477 Accuracy: 0.792000\n",
      " Iteration: 9580 , loss: 3.486119 Accuracy: 0.780000\n",
      " Iteration: 9590 , loss: 3.513778 Accuracy: 0.780000\n",
      " Iteration: 9600 , loss: 3.472178 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 9610 , loss: 3.497013 Accuracy: 0.796000\n",
      " Iteration: 9620 , loss: 3.498756 Accuracy: 0.760000\n",
      " Iteration: 9630 , loss: 3.510773 Accuracy: 0.772000\n",
      " Iteration: 9640 , loss: 3.530531 Accuracy: 0.764000\n",
      " Iteration: 9650 , loss: 3.493292 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 9660 , loss: 3.467479 Accuracy: 0.792000\n",
      " Iteration: 9670 , loss: 3.468103 Accuracy: 0.784000\n",
      " Iteration: 9680 , loss: 3.515242 Accuracy: 0.760000\n",
      " Iteration: 9690 , loss: 3.539294 Accuracy: 0.736000\n",
      " Iteration: 9700 , loss: 3.491395 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 9710 , loss: 3.513402 Accuracy: 0.768000\n",
      " Iteration: 9720 , loss: 3.485538 Accuracy: 0.812000\n",
      " Iteration: 9730 , loss: 3.504064 Accuracy: 0.756000\n",
      " Iteration: 9740 , loss: 3.509935 Accuracy: 0.760000\n",
      " Iteration: 9750 , loss: 3.548625 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 9760 , loss: 3.486839 Accuracy: 0.768000\n",
      " Iteration: 9770 , loss: 3.530959 Accuracy: 0.720000\n",
      " Iteration: 9780 , loss: 3.498291 Accuracy: 0.788000\n",
      " Iteration: 9790 , loss: 3.482595 Accuracy: 0.796000\n",
      " Iteration: 9800 , loss: 3.519953 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 9810 , loss: 3.497147 Accuracy: 0.748000\n",
      " Iteration: 9820 , loss: 3.494173 Accuracy: 0.772000\n",
      " Iteration: 9830 , loss: 3.476237 Accuracy: 0.824000\n",
      " Iteration: 9840 , loss: 3.501977 Accuracy: 0.756000\n",
      " Iteration: 9850 , loss: 3.503275 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 9860 , loss: 3.465890 Accuracy: 0.836000\n",
      " Iteration: 9870 , loss: 3.505683 Accuracy: 0.748000\n",
      " Iteration: 9880 , loss: 3.528479 Accuracy: 0.716000\n",
      " Iteration: 9890 , loss: 3.503607 Accuracy: 0.768000\n",
      " Iteration: 9900 , loss: 3.493603 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 9910 , loss: 3.481126 Accuracy: 0.776000\n",
      " Iteration: 9920 , loss: 3.480484 Accuracy: 0.788000\n",
      " Iteration: 9930 , loss: 3.499396 Accuracy: 0.780000\n",
      " Iteration: 9940 , loss: 3.509466 Accuracy: 0.760000\n",
      " Iteration: 9950 , loss: 3.518489 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 9960 , loss: 3.513045 Accuracy: 0.736000\n",
      " Iteration: 9970 , loss: 3.528346 Accuracy: 0.736000\n",
      " Iteration: 9980 , loss: 3.503884 Accuracy: 0.752000\n",
      " Iteration: 9990 , loss: 3.485347 Accuracy: 0.788000\n",
      " Iteration: 10000 , loss: 3.506730 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 10010 , loss: 3.504408 Accuracy: 0.800000\n",
      " Iteration: 10020 , loss: 3.507830 Accuracy: 0.736000\n",
      " Iteration: 10030 , loss: 3.494697 Accuracy: 0.784000\n",
      " Iteration: 10040 , loss: 3.498411 Accuracy: 0.804000\n",
      " Iteration: 10050 , loss: 3.488005 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 10060 , loss: 3.505658 Accuracy: 0.756000\n",
      " Iteration: 10070 , loss: 3.499964 Accuracy: 0.764000\n",
      " Iteration: 10080 , loss: 3.487746 Accuracy: 0.780000\n",
      " Iteration: 10090 , loss: 3.509492 Accuracy: 0.772000\n",
      " Iteration: 10100 , loss: 3.470209 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 10110 , loss: 3.489238 Accuracy: 0.780000\n",
      " Iteration: 10120 , loss: 3.513255 Accuracy: 0.748000\n",
      " Iteration: 10130 , loss: 3.490572 Accuracy: 0.800000\n",
      " Iteration: 10140 , loss: 3.481143 Accuracy: 0.788000\n",
      " Iteration: 10150 , loss: 3.514498 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 10160 , loss: 3.513124 Accuracy: 0.772000\n",
      " Iteration: 10170 , loss: 3.486260 Accuracy: 0.768000\n",
      " Iteration: 10180 , loss: 3.523412 Accuracy: 0.748000\n",
      " Iteration: 10190 , loss: 3.469227 Accuracy: 0.796000\n",
      " Iteration: 10200 , loss: 3.509125 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9399141630901288 and the number of correct results is: 219\n",
      " Iteration: 10210 , loss: 3.513853 Accuracy: 0.756000\n",
      " Iteration: 10220 , loss: 3.479672 Accuracy: 0.780000\n",
      " Iteration: 10230 , loss: 3.507972 Accuracy: 0.740000\n",
      " Iteration: 10240 , loss: 3.501539 Accuracy: 0.784000\n",
      " Iteration: 10250 , loss: 3.498875 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 10260 , loss: 3.484899 Accuracy: 0.792000\n",
      " Iteration: 10270 , loss: 3.498025 Accuracy: 0.788000\n",
      " Iteration: 10280 , loss: 3.471412 Accuracy: 0.796000\n",
      " Iteration: 10290 , loss: 3.503465 Accuracy: 0.768000\n",
      " Iteration: 10300 , loss: 3.489068 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 10310 , loss: 3.475706 Accuracy: 0.776000\n",
      " Iteration: 10320 , loss: 3.523036 Accuracy: 0.768000\n",
      " Iteration: 10330 , loss: 3.489242 Accuracy: 0.824000\n",
      " Iteration: 10340 , loss: 3.504348 Accuracy: 0.768000\n",
      " Iteration: 10350 , loss: 3.488079 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 10360 , loss: 3.533805 Accuracy: 0.756000\n",
      " Iteration: 10370 , loss: 3.519077 Accuracy: 0.740000\n",
      " Iteration: 10380 , loss: 3.463692 Accuracy: 0.828000\n",
      " Iteration: 10390 , loss: 3.487217 Accuracy: 0.780000\n",
      " Iteration: 10400 , loss: 3.499625 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 10410 , loss: 3.478270 Accuracy: 0.800000\n",
      " Iteration: 10420 , loss: 3.478675 Accuracy: 0.764000\n",
      " Iteration: 10430 , loss: 3.474921 Accuracy: 0.776000\n",
      " Iteration: 10440 , loss: 3.473197 Accuracy: 0.804000\n",
      " Iteration: 10450 , loss: 3.473680 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.944206008583691 and the number of correct results is: 220\n",
      " Iteration: 10460 , loss: 3.506320 Accuracy: 0.752000\n",
      " Iteration: 10470 , loss: 3.510792 Accuracy: 0.780000\n",
      " Iteration: 10480 , loss: 3.509387 Accuracy: 0.748000\n",
      " Iteration: 10490 , loss: 3.500470 Accuracy: 0.728000\n",
      " Iteration: 10500 , loss: 3.451886 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 10510 , loss: 3.445905 Accuracy: 0.836000\n",
      " Iteration: 10520 , loss: 3.474289 Accuracy: 0.812000\n",
      " Iteration: 10530 , loss: 3.488885 Accuracy: 0.796000\n",
      " Iteration: 10540 , loss: 3.504770 Accuracy: 0.772000\n",
      " Iteration: 10550 , loss: 3.506237 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 10560 , loss: 3.481806 Accuracy: 0.804000\n",
      " Iteration: 10570 , loss: 3.484599 Accuracy: 0.772000\n",
      " Iteration: 10580 , loss: 3.500538 Accuracy: 0.772000\n",
      " Iteration: 10590 , loss: 3.507879 Accuracy: 0.772000\n",
      " Iteration: 10600 , loss: 3.482901 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 10610 , loss: 3.500509 Accuracy: 0.760000\n",
      " Iteration: 10620 , loss: 3.511867 Accuracy: 0.744000\n",
      " Iteration: 10630 , loss: 3.545493 Accuracy: 0.716000\n",
      " Iteration: 10640 , loss: 3.479055 Accuracy: 0.780000\n",
      " Iteration: 10650 , loss: 3.449861 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 10660 , loss: 3.511244 Accuracy: 0.760000\n",
      " Iteration: 10670 , loss: 3.507592 Accuracy: 0.744000\n",
      " Iteration: 10680 , loss: 3.500163 Accuracy: 0.780000\n",
      " Iteration: 10690 , loss: 3.490310 Accuracy: 0.784000\n",
      " Iteration: 10700 , loss: 3.479824 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 10710 , loss: 3.476433 Accuracy: 0.792000\n",
      " Iteration: 10720 , loss: 3.510357 Accuracy: 0.760000\n",
      " Iteration: 10730 , loss: 3.464887 Accuracy: 0.812000\n",
      " Iteration: 10740 , loss: 3.493948 Accuracy: 0.788000\n",
      " Iteration: 10750 , loss: 3.472881 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 10760 , loss: 3.505316 Accuracy: 0.752000\n",
      " Iteration: 10770 , loss: 3.483655 Accuracy: 0.780000\n",
      " Iteration: 10780 , loss: 3.475618 Accuracy: 0.776000\n",
      " Iteration: 10790 , loss: 3.506200 Accuracy: 0.752000\n",
      " Iteration: 10800 , loss: 3.488502 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 10810 , loss: 3.471807 Accuracy: 0.824000\n",
      " Iteration: 10820 , loss: 3.451787 Accuracy: 0.848000\n",
      " Iteration: 10830 , loss: 3.470908 Accuracy: 0.804000\n",
      " Iteration: 10840 , loss: 3.485261 Accuracy: 0.788000\n",
      " Iteration: 10850 , loss: 3.490905 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 10860 , loss: 3.511469 Accuracy: 0.768000\n",
      " Iteration: 10870 , loss: 3.508579 Accuracy: 0.764000\n",
      " Iteration: 10880 , loss: 3.493671 Accuracy: 0.776000\n",
      " Iteration: 10890 , loss: 3.486046 Accuracy: 0.784000\n",
      " Iteration: 10900 , loss: 3.483541 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 10910 , loss: 3.462774 Accuracy: 0.784000\n",
      " Iteration: 10920 , loss: 3.479937 Accuracy: 0.792000\n",
      " Iteration: 10930 , loss: 3.463094 Accuracy: 0.820000\n",
      " Iteration: 10940 , loss: 3.442757 Accuracy: 0.832000\n",
      " Iteration: 10950 , loss: 3.508816 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 10960 , loss: 3.463911 Accuracy: 0.808000\n",
      " Iteration: 10970 , loss: 3.455921 Accuracy: 0.812000\n",
      " Iteration: 10980 , loss: 3.479008 Accuracy: 0.784000\n",
      " Iteration: 10990 , loss: 3.476875 Accuracy: 0.776000\n",
      " Iteration: 11000 , loss: 3.484205 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11010 , loss: 3.492594 Accuracy: 0.796000\n",
      " Iteration: 11020 , loss: 3.517665 Accuracy: 0.740000\n",
      " Iteration: 11030 , loss: 3.486849 Accuracy: 0.800000\n",
      " Iteration: 11040 , loss: 3.461715 Accuracy: 0.844000\n",
      " Iteration: 11050 , loss: 3.499658 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 11060 , loss: 3.522296 Accuracy: 0.768000\n",
      " Iteration: 11070 , loss: 3.519510 Accuracy: 0.764000\n",
      " Iteration: 11080 , loss: 3.470701 Accuracy: 0.808000\n",
      " Iteration: 11090 , loss: 3.464703 Accuracy: 0.804000\n",
      " Iteration: 11100 , loss: 3.504418 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 11110 , loss: 3.451897 Accuracy: 0.804000\n",
      " Iteration: 11120 , loss: 3.478502 Accuracy: 0.796000\n",
      " Iteration: 11130 , loss: 3.524529 Accuracy: 0.760000\n",
      " Iteration: 11140 , loss: 3.491547 Accuracy: 0.792000\n",
      " Iteration: 11150 , loss: 3.487925 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11160 , loss: 3.494679 Accuracy: 0.752000\n",
      " Iteration: 11170 , loss: 3.463281 Accuracy: 0.800000\n",
      " Iteration: 11180 , loss: 3.491410 Accuracy: 0.776000\n",
      " Iteration: 11190 , loss: 3.445626 Accuracy: 0.844000\n",
      " Iteration: 11200 , loss: 3.488422 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 11210 , loss: 3.479048 Accuracy: 0.776000\n",
      " Iteration: 11220 , loss: 3.470284 Accuracy: 0.800000\n",
      " Iteration: 11230 , loss: 3.497254 Accuracy: 0.776000\n",
      " Iteration: 11240 , loss: 3.494274 Accuracy: 0.796000\n",
      " Iteration: 11250 , loss: 3.485854 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11260 , loss: 3.480974 Accuracy: 0.780000\n",
      " Iteration: 11270 , loss: 3.480816 Accuracy: 0.800000\n",
      " Iteration: 11280 , loss: 3.483412 Accuracy: 0.792000\n",
      " Iteration: 11290 , loss: 3.476033 Accuracy: 0.796000\n",
      " Iteration: 11300 , loss: 3.498403 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 11310 , loss: 3.441322 Accuracy: 0.820000\n",
      " Iteration: 11320 , loss: 3.508451 Accuracy: 0.772000\n",
      " Iteration: 11330 , loss: 3.485963 Accuracy: 0.776000\n",
      " Iteration: 11340 , loss: 3.472791 Accuracy: 0.804000\n",
      " Iteration: 11350 , loss: 3.498775 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 11360 , loss: 3.479351 Accuracy: 0.816000\n",
      " Iteration: 11370 , loss: 3.509434 Accuracy: 0.760000\n",
      " Iteration: 11380 , loss: 3.473580 Accuracy: 0.796000\n",
      " Iteration: 11390 , loss: 3.514523 Accuracy: 0.760000\n",
      " Iteration: 11400 , loss: 3.489659 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 11410 , loss: 3.500094 Accuracy: 0.768000\n",
      " Iteration: 11420 , loss: 3.476021 Accuracy: 0.776000\n",
      " Iteration: 11430 , loss: 3.480711 Accuracy: 0.780000\n",
      " Iteration: 11440 , loss: 3.452894 Accuracy: 0.852000\n",
      " Iteration: 11450 , loss: 3.449044 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 11460 , loss: 3.488336 Accuracy: 0.756000\n",
      " Iteration: 11470 , loss: 3.441860 Accuracy: 0.824000\n",
      " Iteration: 11480 , loss: 3.489344 Accuracy: 0.772000\n",
      " Iteration: 11490 , loss: 3.496526 Accuracy: 0.780000\n",
      " Iteration: 11500 , loss: 3.473349 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11510 , loss: 3.518411 Accuracy: 0.736000\n",
      " Iteration: 11520 , loss: 3.484808 Accuracy: 0.780000\n",
      " Iteration: 11530 , loss: 3.486917 Accuracy: 0.780000\n",
      " Iteration: 11540 , loss: 3.542625 Accuracy: 0.704000\n",
      " Iteration: 11550 , loss: 3.495205 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 11560 , loss: 3.472435 Accuracy: 0.824000\n",
      " Iteration: 11570 , loss: 3.471807 Accuracy: 0.796000\n",
      " Iteration: 11580 , loss: 3.497594 Accuracy: 0.800000\n",
      " Iteration: 11590 , loss: 3.480652 Accuracy: 0.780000\n",
      " Iteration: 11600 , loss: 3.503408 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 11610 , loss: 3.469922 Accuracy: 0.792000\n",
      " Iteration: 11620 , loss: 3.471894 Accuracy: 0.820000\n",
      " Iteration: 11630 , loss: 3.461580 Accuracy: 0.804000\n",
      " Iteration: 11640 , loss: 3.491786 Accuracy: 0.772000\n",
      " Iteration: 11650 , loss: 3.493726 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11660 , loss: 3.493880 Accuracy: 0.748000\n",
      " Iteration: 11670 , loss: 3.465919 Accuracy: 0.808000\n",
      " Iteration: 11680 , loss: 3.467121 Accuracy: 0.792000\n",
      " Iteration: 11690 , loss: 3.454352 Accuracy: 0.800000\n",
      " Iteration: 11700 , loss: 3.487918 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 11710 , loss: 3.438611 Accuracy: 0.824000\n",
      " Iteration: 11720 , loss: 3.480923 Accuracy: 0.776000\n",
      " Iteration: 11730 , loss: 3.491722 Accuracy: 0.776000\n",
      " Iteration: 11740 , loss: 3.444933 Accuracy: 0.828000\n",
      " Iteration: 11750 , loss: 3.530175 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 11760 , loss: 3.475109 Accuracy: 0.820000\n",
      " Iteration: 11770 , loss: 3.507601 Accuracy: 0.744000\n",
      " Iteration: 11780 , loss: 3.461181 Accuracy: 0.808000\n",
      " Iteration: 11790 , loss: 3.493093 Accuracy: 0.772000\n",
      " Iteration: 11800 , loss: 3.448060 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11810 , loss: 3.501136 Accuracy: 0.764000\n",
      " Iteration: 11820 , loss: 3.499479 Accuracy: 0.776000\n",
      " Iteration: 11830 , loss: 3.509358 Accuracy: 0.748000\n",
      " Iteration: 11840 , loss: 3.479785 Accuracy: 0.772000\n",
      " Iteration: 11850 , loss: 3.456308 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 11860 , loss: 3.499424 Accuracy: 0.780000\n",
      " Iteration: 11870 , loss: 3.505845 Accuracy: 0.744000\n",
      " Iteration: 11880 , loss: 3.478358 Accuracy: 0.784000\n",
      " Iteration: 11890 , loss: 3.481331 Accuracy: 0.784000\n",
      " Iteration: 11900 , loss: 3.474554 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 11910 , loss: 3.455518 Accuracy: 0.804000\n",
      " Iteration: 11920 , loss: 3.509380 Accuracy: 0.744000\n",
      " Iteration: 11930 , loss: 3.483416 Accuracy: 0.788000\n",
      " Iteration: 11940 , loss: 3.433453 Accuracy: 0.840000\n",
      " Iteration: 11950 , loss: 3.481493 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 11960 , loss: 3.471625 Accuracy: 0.812000\n",
      " Iteration: 11970 , loss: 3.479262 Accuracy: 0.784000\n",
      " Iteration: 11980 , loss: 3.461604 Accuracy: 0.812000\n",
      " Iteration: 11990 , loss: 3.473503 Accuracy: 0.812000\n",
      " Iteration: 12000 , loss: 3.438658 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 12010 , loss: 3.473537 Accuracy: 0.804000\n",
      " Iteration: 12020 , loss: 3.496970 Accuracy: 0.768000\n",
      " Iteration: 12030 , loss: 3.489262 Accuracy: 0.764000\n",
      " Iteration: 12040 , loss: 3.458580 Accuracy: 0.816000\n",
      " Iteration: 12050 , loss: 3.530685 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 12060 , loss: 3.475536 Accuracy: 0.804000\n",
      " Iteration: 12070 , loss: 3.496439 Accuracy: 0.768000\n",
      " Iteration: 12080 , loss: 3.503209 Accuracy: 0.760000\n",
      " Iteration: 12090 , loss: 3.475646 Accuracy: 0.792000\n",
      " Iteration: 12100 , loss: 3.501895 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 12110 , loss: 3.438584 Accuracy: 0.840000\n",
      " Iteration: 12120 , loss: 3.460195 Accuracy: 0.828000\n",
      " Iteration: 12130 , loss: 3.469102 Accuracy: 0.796000\n",
      " Iteration: 12140 , loss: 3.507160 Accuracy: 0.748000\n",
      " Iteration: 12150 , loss: 3.500680 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 12160 , loss: 3.432498 Accuracy: 0.848000\n",
      " Iteration: 12170 , loss: 3.418908 Accuracy: 0.840000\n",
      " Iteration: 12180 , loss: 3.475100 Accuracy: 0.788000\n",
      " Iteration: 12190 , loss: 3.471604 Accuracy: 0.812000\n",
      " Iteration: 12200 , loss: 3.466707 Accuracy: 0.824000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 12210 , loss: 3.436810 Accuracy: 0.828000\n",
      " Iteration: 12220 , loss: 3.475142 Accuracy: 0.788000\n",
      " Iteration: 12230 , loss: 3.467787 Accuracy: 0.816000\n",
      " Iteration: 12240 , loss: 3.497997 Accuracy: 0.756000\n",
      " Iteration: 12250 , loss: 3.498182 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 12260 , loss: 3.474368 Accuracy: 0.800000\n",
      " Iteration: 12270 , loss: 3.486028 Accuracy: 0.772000\n",
      " Iteration: 12280 , loss: 3.485432 Accuracy: 0.756000\n",
      " Iteration: 12290 , loss: 3.500228 Accuracy: 0.744000\n",
      " Iteration: 12300 , loss: 3.468200 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 12310 , loss: 3.456413 Accuracy: 0.824000\n",
      " Iteration: 12320 , loss: 3.492304 Accuracy: 0.764000\n",
      " Iteration: 12330 , loss: 3.472233 Accuracy: 0.796000\n",
      " Iteration: 12340 , loss: 3.439008 Accuracy: 0.852000\n",
      " Iteration: 12350 , loss: 3.461504 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 12360 , loss: 3.489157 Accuracy: 0.796000\n",
      " Iteration: 12370 , loss: 3.487554 Accuracy: 0.784000\n",
      " Iteration: 12380 , loss: 3.437617 Accuracy: 0.828000\n",
      " Iteration: 12390 , loss: 3.466257 Accuracy: 0.800000\n",
      " Iteration: 12400 , loss: 3.495506 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 12410 , loss: 3.456258 Accuracy: 0.812000\n",
      " Iteration: 12420 , loss: 3.469021 Accuracy: 0.776000\n",
      " Iteration: 12430 , loss: 3.477241 Accuracy: 0.796000\n",
      " Iteration: 12440 , loss: 3.487832 Accuracy: 0.756000\n",
      " Iteration: 12450 , loss: 3.518342 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9012875536480687 and the number of correct results is: 210\n",
      " Iteration: 12460 , loss: 3.458430 Accuracy: 0.820000\n",
      " Iteration: 12470 , loss: 3.511020 Accuracy: 0.756000\n",
      " Iteration: 12480 , loss: 3.481102 Accuracy: 0.796000\n",
      " Iteration: 12490 , loss: 3.450644 Accuracy: 0.800000\n",
      " Iteration: 12500 , loss: 3.456455 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 12510 , loss: 3.460618 Accuracy: 0.812000\n",
      " Iteration: 12520 , loss: 3.479399 Accuracy: 0.796000\n",
      " Iteration: 12530 , loss: 3.513029 Accuracy: 0.756000\n",
      " Iteration: 12540 , loss: 3.495189 Accuracy: 0.772000\n",
      " Iteration: 12550 , loss: 3.482197 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 12560 , loss: 3.462194 Accuracy: 0.772000\n",
      " Iteration: 12570 , loss: 3.456323 Accuracy: 0.808000\n",
      " Iteration: 12580 , loss: 3.460949 Accuracy: 0.788000\n",
      " Iteration: 12590 , loss: 3.494355 Accuracy: 0.748000\n",
      " Iteration: 12600 , loss: 3.444529 Accuracy: 0.856000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 12610 , loss: 3.496724 Accuracy: 0.788000\n",
      " Iteration: 12620 , loss: 3.470418 Accuracy: 0.772000\n",
      " Iteration: 12630 , loss: 3.474325 Accuracy: 0.804000\n",
      " Iteration: 12640 , loss: 3.474877 Accuracy: 0.796000\n",
      " Iteration: 12650 , loss: 3.514823 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 12660 , loss: 3.477624 Accuracy: 0.796000\n",
      " Iteration: 12670 , loss: 3.454654 Accuracy: 0.828000\n",
      " Iteration: 12680 , loss: 3.474230 Accuracy: 0.804000\n",
      " Iteration: 12690 , loss: 3.464768 Accuracy: 0.768000\n",
      " Iteration: 12700 , loss: 3.458082 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 12710 , loss: 3.488856 Accuracy: 0.744000\n",
      " Iteration: 12720 , loss: 3.501749 Accuracy: 0.740000\n",
      " Iteration: 12730 , loss: 3.498762 Accuracy: 0.776000\n",
      " Iteration: 12740 , loss: 3.479144 Accuracy: 0.788000\n",
      " Iteration: 12750 , loss: 3.495173 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.944206008583691 and the number of correct results is: 220\n",
      " Iteration: 12760 , loss: 3.484437 Accuracy: 0.772000\n",
      " Iteration: 12770 , loss: 3.478256 Accuracy: 0.768000\n",
      " Iteration: 12780 , loss: 3.472266 Accuracy: 0.796000\n",
      " Iteration: 12790 , loss: 3.489925 Accuracy: 0.768000\n",
      " Iteration: 12800 , loss: 3.462174 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 12810 , loss: 3.467198 Accuracy: 0.764000\n",
      " Iteration: 12820 , loss: 3.461355 Accuracy: 0.808000\n",
      " Iteration: 12830 , loss: 3.485418 Accuracy: 0.764000\n",
      " Iteration: 12840 , loss: 3.495285 Accuracy: 0.736000\n",
      " Iteration: 12850 , loss: 3.482538 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 12860 , loss: 3.480575 Accuracy: 0.804000\n",
      " Iteration: 12870 , loss: 3.441463 Accuracy: 0.808000\n",
      " Iteration: 12880 , loss: 3.476009 Accuracy: 0.788000\n",
      " Iteration: 12890 , loss: 3.501086 Accuracy: 0.768000\n",
      " Iteration: 12900 , loss: 3.500628 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      " Iteration: 12910 , loss: 3.476765 Accuracy: 0.780000\n",
      " Iteration: 12920 , loss: 3.452044 Accuracy: 0.844000\n",
      " Iteration: 12930 , loss: 3.468874 Accuracy: 0.780000\n",
      " Iteration: 12940 , loss: 3.487061 Accuracy: 0.796000\n",
      " Iteration: 12950 , loss: 3.438680 Accuracy: 0.848000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 12960 , loss: 3.425884 Accuracy: 0.856000\n",
      " Iteration: 12970 , loss: 3.436939 Accuracy: 0.860000\n",
      " Iteration: 12980 , loss: 3.495712 Accuracy: 0.760000\n",
      " Iteration: 12990 , loss: 3.454052 Accuracy: 0.808000\n",
      " Iteration: 13000 , loss: 3.445182 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 13010 , loss: 3.465159 Accuracy: 0.800000\n",
      " Iteration: 13020 , loss: 3.495156 Accuracy: 0.764000\n",
      " Iteration: 13030 , loss: 3.452623 Accuracy: 0.828000\n",
      " Iteration: 13040 , loss: 3.466521 Accuracy: 0.796000\n",
      " Iteration: 13050 , loss: 3.491402 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 13060 , loss: 3.465374 Accuracy: 0.788000\n",
      " Iteration: 13070 , loss: 3.480335 Accuracy: 0.792000\n",
      " Iteration: 13080 , loss: 3.451832 Accuracy: 0.824000\n",
      " Iteration: 13090 , loss: 3.452762 Accuracy: 0.808000\n",
      " Iteration: 13100 , loss: 3.458745 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 13110 , loss: 3.472889 Accuracy: 0.776000\n",
      " Iteration: 13120 , loss: 3.486402 Accuracy: 0.772000\n",
      " Iteration: 13130 , loss: 3.439378 Accuracy: 0.844000\n",
      " Iteration: 13140 , loss: 3.516355 Accuracy: 0.752000\n",
      " Iteration: 13150 , loss: 3.483925 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 13160 , loss: 3.453293 Accuracy: 0.792000\n",
      " Iteration: 13170 , loss: 3.477791 Accuracy: 0.796000\n",
      " Iteration: 13180 , loss: 3.447459 Accuracy: 0.816000\n",
      " Iteration: 13190 , loss: 3.441109 Accuracy: 0.844000\n",
      " Iteration: 13200 , loss: 3.474172 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8969957081545065 and the number of correct results is: 209\n",
      " Iteration: 13210 , loss: 3.477574 Accuracy: 0.780000\n",
      " Iteration: 13220 , loss: 3.485322 Accuracy: 0.768000\n",
      " Iteration: 13230 , loss: 3.476114 Accuracy: 0.788000\n",
      " Iteration: 13240 , loss: 3.503076 Accuracy: 0.768000\n",
      " Iteration: 13250 , loss: 3.464139 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 13260 , loss: 3.483116 Accuracy: 0.796000\n",
      " Iteration: 13270 , loss: 3.448127 Accuracy: 0.816000\n",
      " Iteration: 13280 , loss: 3.475150 Accuracy: 0.788000\n",
      " Iteration: 13290 , loss: 3.443277 Accuracy: 0.824000\n",
      " Iteration: 13300 , loss: 3.469140 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9399141630901288 and the number of correct results is: 219\n",
      " Iteration: 13310 , loss: 3.453755 Accuracy: 0.816000\n",
      " Iteration: 13320 , loss: 3.449503 Accuracy: 0.788000\n",
      " Iteration: 13330 , loss: 3.467453 Accuracy: 0.780000\n",
      " Iteration: 13340 , loss: 3.458624 Accuracy: 0.816000\n",
      " Iteration: 13350 , loss: 3.428522 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 13360 , loss: 3.445893 Accuracy: 0.816000\n",
      " Iteration: 13370 , loss: 3.449350 Accuracy: 0.804000\n",
      " Iteration: 13380 , loss: 3.437157 Accuracy: 0.848000\n",
      " Iteration: 13390 , loss: 3.471605 Accuracy: 0.816000\n",
      " Iteration: 13400 , loss: 3.445297 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.9313304721030042 and the number of correct results is: 217\n",
      " Iteration: 13410 , loss: 3.475997 Accuracy: 0.800000\n",
      " Iteration: 13420 , loss: 3.472276 Accuracy: 0.812000\n",
      " Iteration: 13430 , loss: 3.471847 Accuracy: 0.796000\n",
      " Iteration: 13440 , loss: 3.447465 Accuracy: 0.816000\n",
      " Iteration: 13450 , loss: 3.480217 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 13460 , loss: 3.463187 Accuracy: 0.816000\n",
      " Iteration: 13470 , loss: 3.476390 Accuracy: 0.812000\n",
      " Iteration: 13480 , loss: 3.472364 Accuracy: 0.820000\n",
      " Iteration: 13490 , loss: 3.479945 Accuracy: 0.800000\n",
      " Iteration: 13500 , loss: 3.464708 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9141630901287554 and the number of correct results is: 213\n",
      " Iteration: 13510 , loss: 3.432096 Accuracy: 0.848000\n",
      " Iteration: 13520 , loss: 3.481205 Accuracy: 0.796000\n",
      " Iteration: 13530 , loss: 3.464677 Accuracy: 0.800000\n",
      " Iteration: 13540 , loss: 3.486598 Accuracy: 0.772000\n",
      " Iteration: 13550 , loss: 3.476667 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9184549356223176 and the number of correct results is: 214\n",
      " Iteration: 13560 , loss: 3.433707 Accuracy: 0.832000\n",
      " Iteration: 13570 , loss: 3.482848 Accuracy: 0.792000\n",
      " Iteration: 13580 , loss: 3.444323 Accuracy: 0.832000\n",
      " Iteration: 13590 , loss: 3.451325 Accuracy: 0.812000\n",
      " Iteration: 13600 , loss: 3.466892 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9055793991416309 and the number of correct results is: 211\n",
      " Iteration: 13610 , loss: 3.453039 Accuracy: 0.808000\n",
      " Iteration: 13620 , loss: 3.489396 Accuracy: 0.792000\n",
      " Iteration: 13630 , loss: 3.484584 Accuracy: 0.780000\n",
      " Iteration: 13640 , loss: 3.447769 Accuracy: 0.840000\n",
      " Iteration: 13650 , loss: 3.508456 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 13660 , loss: 3.491020 Accuracy: 0.788000\n",
      " Iteration: 13670 , loss: 3.482315 Accuracy: 0.776000\n",
      " Iteration: 13680 , loss: 3.496169 Accuracy: 0.776000\n",
      " Iteration: 13690 , loss: 3.499154 Accuracy: 0.756000\n",
      " Iteration: 13700 , loss: 3.467960 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.9227467811158798 and the number of correct results is: 215\n",
      " Iteration: 13710 , loss: 3.465404 Accuracy: 0.848000\n",
      " Iteration: 13720 , loss: 3.490527 Accuracy: 0.772000\n",
      " Iteration: 13730 , loss: 3.485357 Accuracy: 0.760000\n",
      " Iteration: 13740 , loss: 3.465567 Accuracy: 0.812000\n",
      " Iteration: 13750 , loss: 3.461732 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 13760 , loss: 3.488412 Accuracy: 0.792000\n",
      " Iteration: 13770 , loss: 3.434144 Accuracy: 0.820000\n",
      " Iteration: 13780 , loss: 3.437200 Accuracy: 0.828000\n",
      " Iteration: 13790 , loss: 3.501075 Accuracy: 0.780000\n",
      " Iteration: 13800 , loss: 3.492327 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9356223175965666 and the number of correct results is: 218\n",
      " Iteration: 13810 , loss: 3.494207 Accuracy: 0.776000\n",
      " Iteration: 13820 , loss: 3.457123 Accuracy: 0.808000\n",
      " Iteration: 13830 , loss: 3.513305 Accuracy: 0.748000\n",
      " Iteration: 13840 , loss: 3.478053 Accuracy: 0.784000\n",
      " Iteration: 13850 , loss: 3.448680 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.927038626609442 and the number of correct results is: 216\n",
      " Iteration: 13860 , loss: 3.445024 Accuracy: 0.820000\n",
      " Iteration: 13870 , loss: 3.476156 Accuracy: 0.784000\n",
      " Iteration: 13880 , loss: 3.462046 Accuracy: 0.788000\n",
      " Iteration: 13890 , loss: 3.517989 Accuracy: 0.752000\n",
      " Iteration: 13900 , loss: 3.441308 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.9098712446351931 and the number of correct results is: 212\n",
      "\n",
      "Optimization of Split 2 Finished\n",
      "\n",
      "\n",
      "\n",
      " Optimization of Split 3 Started\n",
      "\n",
      "\n",
      " Iteration: 0 , loss: 4.172275 Accuracy: 0.020000\n",
      "The postprocessing average accuracy is: 0.016666666666666666 and the number of correct results is: 4\n",
      " Iteration: 10 , loss: 4.163625 Accuracy: 0.056000\n",
      " Iteration: 20 , loss: 4.152014 Accuracy: 0.104000\n",
      " Iteration: 30 , loss: 4.154005 Accuracy: 0.144000\n",
      " Iteration: 40 , loss: 4.140340 Accuracy: 0.128000\n",
      " Iteration: 50 , loss: 4.140897 Accuracy: 0.144000\n",
      "The postprocessing average accuracy is: 0.19583333333333333 and the number of correct results is: 47\n",
      " Iteration: 60 , loss: 4.125969 Accuracy: 0.176000\n",
      " Iteration: 70 , loss: 4.117779 Accuracy: 0.156000\n",
      " Iteration: 80 , loss: 4.101875 Accuracy: 0.204000\n",
      " Iteration: 90 , loss: 4.080738 Accuracy: 0.248000\n",
      " Iteration: 100 , loss: 4.082658 Accuracy: 0.208000\n",
      "The postprocessing average accuracy is: 0.39166666666666666 and the number of correct results is: 94\n",
      " Iteration: 110 , loss: 4.071521 Accuracy: 0.220000\n",
      " Iteration: 120 , loss: 4.070492 Accuracy: 0.232000\n",
      " Iteration: 130 , loss: 4.054368 Accuracy: 0.260000\n",
      " Iteration: 140 , loss: 4.056132 Accuracy: 0.280000\n",
      " Iteration: 150 , loss: 4.053738 Accuracy: 0.272000\n",
      "The postprocessing average accuracy is: 0.4875 and the number of correct results is: 117\n",
      " Iteration: 160 , loss: 4.063943 Accuracy: 0.252000\n",
      " Iteration: 170 , loss: 4.045977 Accuracy: 0.252000\n",
      " Iteration: 180 , loss: 4.016529 Accuracy: 0.296000\n",
      " Iteration: 190 , loss: 4.024887 Accuracy: 0.312000\n",
      " Iteration: 200 , loss: 4.021600 Accuracy: 0.272000\n",
      "The postprocessing average accuracy is: 0.5333333333333333 and the number of correct results is: 128\n",
      " Iteration: 210 , loss: 4.008187 Accuracy: 0.292000\n",
      " Iteration: 220 , loss: 3.980649 Accuracy: 0.360000\n",
      " Iteration: 230 , loss: 3.985057 Accuracy: 0.328000\n",
      " Iteration: 240 , loss: 4.009623 Accuracy: 0.328000\n",
      " Iteration: 250 , loss: 3.969626 Accuracy: 0.388000\n",
      "The postprocessing average accuracy is: 0.6208333333333333 and the number of correct results is: 149\n",
      " Iteration: 260 , loss: 3.982802 Accuracy: 0.368000\n",
      " Iteration: 270 , loss: 3.975651 Accuracy: 0.308000\n",
      " Iteration: 280 , loss: 3.979341 Accuracy: 0.368000\n",
      " Iteration: 290 , loss: 3.963745 Accuracy: 0.392000\n",
      " Iteration: 300 , loss: 3.931776 Accuracy: 0.412000\n",
      "The postprocessing average accuracy is: 0.6083333333333333 and the number of correct results is: 146\n",
      " Iteration: 310 , loss: 3.926255 Accuracy: 0.432000\n",
      " Iteration: 320 , loss: 3.963320 Accuracy: 0.368000\n",
      " Iteration: 330 , loss: 3.920856 Accuracy: 0.404000\n",
      " Iteration: 340 , loss: 3.949507 Accuracy: 0.376000\n",
      " Iteration: 350 , loss: 3.933252 Accuracy: 0.352000\n",
      "The postprocessing average accuracy is: 0.6583333333333333 and the number of correct results is: 158\n",
      " Iteration: 360 , loss: 3.962968 Accuracy: 0.344000\n",
      " Iteration: 370 , loss: 3.923736 Accuracy: 0.388000\n",
      " Iteration: 380 , loss: 3.930148 Accuracy: 0.388000\n",
      " Iteration: 390 , loss: 3.946791 Accuracy: 0.356000\n",
      " Iteration: 400 , loss: 3.902930 Accuracy: 0.424000\n",
      "The postprocessing average accuracy is: 0.675 and the number of correct results is: 162\n",
      " Iteration: 410 , loss: 3.907007 Accuracy: 0.424000\n",
      " Iteration: 420 , loss: 3.929207 Accuracy: 0.396000\n",
      " Iteration: 430 , loss: 3.891772 Accuracy: 0.428000\n",
      " Iteration: 440 , loss: 3.914975 Accuracy: 0.420000\n",
      " Iteration: 450 , loss: 3.918862 Accuracy: 0.412000\n",
      "The postprocessing average accuracy is: 0.6916666666666667 and the number of correct results is: 166\n",
      " Iteration: 460 , loss: 3.891221 Accuracy: 0.448000\n",
      " Iteration: 470 , loss: 3.895325 Accuracy: 0.460000\n",
      " Iteration: 480 , loss: 3.901668 Accuracy: 0.448000\n",
      " Iteration: 490 , loss: 3.885237 Accuracy: 0.416000\n",
      " Iteration: 500 , loss: 3.900642 Accuracy: 0.424000\n",
      "The postprocessing average accuracy is: 0.7166666666666667 and the number of correct results is: 172\n",
      " Iteration: 510 , loss: 3.903291 Accuracy: 0.396000\n",
      " Iteration: 520 , loss: 3.871902 Accuracy: 0.456000\n",
      " Iteration: 530 , loss: 3.867113 Accuracy: 0.480000\n",
      " Iteration: 540 , loss: 3.864460 Accuracy: 0.496000\n",
      " Iteration: 550 , loss: 3.863269 Accuracy: 0.468000\n",
      "The postprocessing average accuracy is: 0.6875 and the number of correct results is: 165\n",
      " Iteration: 560 , loss: 3.826241 Accuracy: 0.484000\n",
      " Iteration: 570 , loss: 3.832519 Accuracy: 0.508000\n",
      " Iteration: 580 , loss: 3.868460 Accuracy: 0.496000\n",
      " Iteration: 590 , loss: 3.861793 Accuracy: 0.480000\n",
      " Iteration: 600 , loss: 3.857507 Accuracy: 0.464000\n",
      "The postprocessing average accuracy is: 0.7416666666666667 and the number of correct results is: 178\n",
      " Iteration: 610 , loss: 3.862283 Accuracy: 0.436000\n",
      " Iteration: 620 , loss: 3.862688 Accuracy: 0.504000\n",
      " Iteration: 630 , loss: 3.886636 Accuracy: 0.416000\n",
      " Iteration: 640 , loss: 3.851186 Accuracy: 0.484000\n",
      " Iteration: 650 , loss: 3.830199 Accuracy: 0.508000\n",
      "The postprocessing average accuracy is: 0.7416666666666667 and the number of correct results is: 178\n",
      " Iteration: 660 , loss: 3.858219 Accuracy: 0.488000\n",
      " Iteration: 670 , loss: 3.842804 Accuracy: 0.484000\n",
      " Iteration: 680 , loss: 3.856007 Accuracy: 0.480000\n",
      " Iteration: 690 , loss: 3.868416 Accuracy: 0.440000\n",
      " Iteration: 700 , loss: 3.873439 Accuracy: 0.468000\n",
      "The postprocessing average accuracy is: 0.7708333333333334 and the number of correct results is: 185\n",
      " Iteration: 710 , loss: 3.874650 Accuracy: 0.452000\n",
      " Iteration: 720 , loss: 3.820649 Accuracy: 0.556000\n",
      " Iteration: 730 , loss: 3.844541 Accuracy: 0.472000\n",
      " Iteration: 740 , loss: 3.843050 Accuracy: 0.468000\n",
      " Iteration: 750 , loss: 3.803935 Accuracy: 0.520000\n",
      "The postprocessing average accuracy is: 0.7291666666666666 and the number of correct results is: 175\n",
      " Iteration: 760 , loss: 3.791903 Accuracy: 0.548000\n",
      " Iteration: 770 , loss: 3.847781 Accuracy: 0.488000\n",
      " Iteration: 780 , loss: 3.799489 Accuracy: 0.508000\n",
      " Iteration: 790 , loss: 3.803566 Accuracy: 0.536000\n",
      " Iteration: 800 , loss: 3.823911 Accuracy: 0.500000\n",
      "The postprocessing average accuracy is: 0.7791666666666667 and the number of correct results is: 187\n",
      " Iteration: 810 , loss: 3.833292 Accuracy: 0.492000\n",
      " Iteration: 820 , loss: 3.792135 Accuracy: 0.528000\n",
      " Iteration: 830 , loss: 3.840286 Accuracy: 0.484000\n",
      " Iteration: 840 , loss: 3.825051 Accuracy: 0.488000\n",
      " Iteration: 850 , loss: 3.823275 Accuracy: 0.508000\n",
      "The postprocessing average accuracy is: 0.7666666666666667 and the number of correct results is: 184\n",
      " Iteration: 860 , loss: 3.819685 Accuracy: 0.488000\n",
      " Iteration: 870 , loss: 3.816680 Accuracy: 0.524000\n",
      " Iteration: 880 , loss: 3.762851 Accuracy: 0.568000\n",
      " Iteration: 890 , loss: 3.784178 Accuracy: 0.536000\n",
      " Iteration: 900 , loss: 3.808502 Accuracy: 0.484000\n",
      "The postprocessing average accuracy is: 0.7708333333333334 and the number of correct results is: 185\n",
      " Iteration: 910 , loss: 3.778844 Accuracy: 0.600000\n",
      " Iteration: 920 , loss: 3.777495 Accuracy: 0.576000\n",
      " Iteration: 930 , loss: 3.777421 Accuracy: 0.536000\n",
      " Iteration: 940 , loss: 3.783508 Accuracy: 0.572000\n",
      " Iteration: 950 , loss: 3.779489 Accuracy: 0.568000\n",
      "The postprocessing average accuracy is: 0.775 and the number of correct results is: 186\n",
      " Iteration: 960 , loss: 3.743158 Accuracy: 0.576000\n",
      " Iteration: 970 , loss: 3.787122 Accuracy: 0.504000\n",
      " Iteration: 980 , loss: 3.802247 Accuracy: 0.540000\n",
      " Iteration: 990 , loss: 3.768249 Accuracy: 0.568000\n",
      " Iteration: 1000 , loss: 3.798766 Accuracy: 0.496000\n",
      "The postprocessing average accuracy is: 0.7708333333333334 and the number of correct results is: 185\n",
      " Iteration: 1010 , loss: 3.801635 Accuracy: 0.516000\n",
      " Iteration: 1020 , loss: 3.771920 Accuracy: 0.556000\n",
      " Iteration: 1030 , loss: 3.793172 Accuracy: 0.532000\n",
      " Iteration: 1040 , loss: 3.762791 Accuracy: 0.584000\n",
      " Iteration: 1050 , loss: 3.788518 Accuracy: 0.552000\n",
      "The postprocessing average accuracy is: 0.7708333333333334 and the number of correct results is: 185\n",
      " Iteration: 1060 , loss: 3.773937 Accuracy: 0.512000\n",
      " Iteration: 1070 , loss: 3.792177 Accuracy: 0.516000\n",
      " Iteration: 1080 , loss: 3.736140 Accuracy: 0.596000\n",
      " Iteration: 1090 , loss: 3.765157 Accuracy: 0.580000\n",
      " Iteration: 1100 , loss: 3.757421 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.7625 and the number of correct results is: 183\n",
      " Iteration: 1110 , loss: 3.772547 Accuracy: 0.564000\n",
      " Iteration: 1120 , loss: 3.739427 Accuracy: 0.576000\n",
      " Iteration: 1130 , loss: 3.745319 Accuracy: 0.624000\n",
      " Iteration: 1140 , loss: 3.755621 Accuracy: 0.556000\n",
      " Iteration: 1150 , loss: 3.755025 Accuracy: 0.556000\n",
      "The postprocessing average accuracy is: 0.7833333333333333 and the number of correct results is: 188\n",
      " Iteration: 1160 , loss: 3.764409 Accuracy: 0.568000\n",
      " Iteration: 1170 , loss: 3.785869 Accuracy: 0.524000\n",
      " Iteration: 1180 , loss: 3.740359 Accuracy: 0.568000\n",
      " Iteration: 1190 , loss: 3.746211 Accuracy: 0.572000\n",
      " Iteration: 1200 , loss: 3.735842 Accuracy: 0.576000\n",
      "The postprocessing average accuracy is: 0.7791666666666667 and the number of correct results is: 187\n",
      " Iteration: 1210 , loss: 3.754487 Accuracy: 0.588000\n",
      " Iteration: 1220 , loss: 3.778110 Accuracy: 0.556000\n",
      " Iteration: 1230 , loss: 3.768559 Accuracy: 0.572000\n",
      " Iteration: 1240 , loss: 3.754130 Accuracy: 0.560000\n",
      " Iteration: 1250 , loss: 3.747250 Accuracy: 0.604000\n",
      "The postprocessing average accuracy is: 0.8166666666666667 and the number of correct results is: 196\n",
      " Iteration: 1260 , loss: 3.759429 Accuracy: 0.564000\n",
      " Iteration: 1270 , loss: 3.802401 Accuracy: 0.468000\n",
      " Iteration: 1280 , loss: 3.752751 Accuracy: 0.576000\n",
      " Iteration: 1290 , loss: 3.762940 Accuracy: 0.524000\n",
      " Iteration: 1300 , loss: 3.744093 Accuracy: 0.588000\n",
      "The postprocessing average accuracy is: 0.7916666666666666 and the number of correct results is: 190\n",
      " Iteration: 1310 , loss: 3.718526 Accuracy: 0.600000\n",
      " Iteration: 1320 , loss: 3.762810 Accuracy: 0.512000\n",
      " Iteration: 1330 , loss: 3.781281 Accuracy: 0.528000\n",
      " Iteration: 1340 , loss: 3.738560 Accuracy: 0.592000\n",
      " Iteration: 1350 , loss: 3.746672 Accuracy: 0.564000\n",
      "The postprocessing average accuracy is: 0.8041666666666667 and the number of correct results is: 193\n",
      " Iteration: 1360 , loss: 3.750692 Accuracy: 0.552000\n",
      " Iteration: 1370 , loss: 3.725280 Accuracy: 0.636000\n",
      " Iteration: 1380 , loss: 3.735966 Accuracy: 0.564000\n",
      " Iteration: 1390 , loss: 3.729286 Accuracy: 0.592000\n",
      " Iteration: 1400 , loss: 3.734500 Accuracy: 0.580000\n",
      "The postprocessing average accuracy is: 0.7958333333333333 and the number of correct results is: 191\n",
      " Iteration: 1410 , loss: 3.729072 Accuracy: 0.568000\n",
      " Iteration: 1420 , loss: 3.731467 Accuracy: 0.604000\n",
      " Iteration: 1430 , loss: 3.700660 Accuracy: 0.608000\n",
      " Iteration: 1440 , loss: 3.713432 Accuracy: 0.600000\n",
      " Iteration: 1450 , loss: 3.744138 Accuracy: 0.580000\n",
      "The postprocessing average accuracy is: 0.8166666666666667 and the number of correct results is: 196\n",
      " Iteration: 1460 , loss: 3.755531 Accuracy: 0.580000\n",
      " Iteration: 1470 , loss: 3.711459 Accuracy: 0.616000\n",
      " Iteration: 1480 , loss: 3.734666 Accuracy: 0.616000\n",
      " Iteration: 1490 , loss: 3.745099 Accuracy: 0.616000\n",
      " Iteration: 1500 , loss: 3.738634 Accuracy: 0.588000\n",
      "The postprocessing average accuracy is: 0.8041666666666667 and the number of correct results is: 193\n",
      " Iteration: 1510 , loss: 3.692096 Accuracy: 0.652000\n",
      " Iteration: 1520 , loss: 3.717029 Accuracy: 0.560000\n",
      " Iteration: 1530 , loss: 3.707015 Accuracy: 0.596000\n",
      " Iteration: 1540 , loss: 3.777184 Accuracy: 0.540000\n",
      " Iteration: 1550 , loss: 3.738185 Accuracy: 0.544000\n",
      "The postprocessing average accuracy is: 0.8 and the number of correct results is: 192\n",
      " Iteration: 1560 , loss: 3.738122 Accuracy: 0.540000\n",
      " Iteration: 1570 , loss: 3.718693 Accuracy: 0.604000\n",
      " Iteration: 1580 , loss: 3.715526 Accuracy: 0.624000\n",
      " Iteration: 1590 , loss: 3.719677 Accuracy: 0.576000\n",
      " Iteration: 1600 , loss: 3.700886 Accuracy: 0.632000\n",
      "The postprocessing average accuracy is: 0.8208333333333333 and the number of correct results is: 197\n",
      " Iteration: 1610 , loss: 3.698705 Accuracy: 0.608000\n",
      " Iteration: 1620 , loss: 3.714752 Accuracy: 0.580000\n",
      " Iteration: 1630 , loss: 3.740233 Accuracy: 0.564000\n",
      " Iteration: 1640 , loss: 3.695119 Accuracy: 0.600000\n",
      " Iteration: 1650 , loss: 3.719911 Accuracy: 0.612000\n",
      "The postprocessing average accuracy is: 0.8208333333333333 and the number of correct results is: 197\n",
      " Iteration: 1660 , loss: 3.705752 Accuracy: 0.620000\n",
      " Iteration: 1670 , loss: 3.699040 Accuracy: 0.640000\n",
      " Iteration: 1680 , loss: 3.703834 Accuracy: 0.616000\n",
      " Iteration: 1690 , loss: 3.661066 Accuracy: 0.664000\n",
      " Iteration: 1700 , loss: 3.708261 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.8166666666666667 and the number of correct results is: 196\n",
      " Iteration: 1710 , loss: 3.684313 Accuracy: 0.652000\n",
      " Iteration: 1720 , loss: 3.674118 Accuracy: 0.648000\n",
      " Iteration: 1730 , loss: 3.674206 Accuracy: 0.628000\n",
      " Iteration: 1740 , loss: 3.706716 Accuracy: 0.584000\n",
      " Iteration: 1750 , loss: 3.705802 Accuracy: 0.620000\n",
      "The postprocessing average accuracy is: 0.8291666666666667 and the number of correct results is: 199\n",
      " Iteration: 1760 , loss: 3.713958 Accuracy: 0.604000\n",
      " Iteration: 1770 , loss: 3.724900 Accuracy: 0.548000\n",
      " Iteration: 1780 , loss: 3.708569 Accuracy: 0.600000\n",
      " Iteration: 1790 , loss: 3.713575 Accuracy: 0.592000\n",
      " Iteration: 1800 , loss: 3.688626 Accuracy: 0.612000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 1810 , loss: 3.717118 Accuracy: 0.604000\n",
      " Iteration: 1820 , loss: 3.728516 Accuracy: 0.604000\n",
      " Iteration: 1830 , loss: 3.722241 Accuracy: 0.608000\n",
      " Iteration: 1840 , loss: 3.709079 Accuracy: 0.588000\n",
      " Iteration: 1850 , loss: 3.684801 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8083333333333333 and the number of correct results is: 194\n",
      " Iteration: 1860 , loss: 3.707892 Accuracy: 0.620000\n",
      " Iteration: 1870 , loss: 3.669272 Accuracy: 0.640000\n",
      " Iteration: 1880 , loss: 3.699410 Accuracy: 0.580000\n",
      " Iteration: 1890 , loss: 3.691186 Accuracy: 0.596000\n",
      " Iteration: 1900 , loss: 3.714268 Accuracy: 0.592000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 1910 , loss: 3.648983 Accuracy: 0.672000\n",
      " Iteration: 1920 , loss: 3.745932 Accuracy: 0.572000\n",
      " Iteration: 1930 , loss: 3.721724 Accuracy: 0.580000\n",
      " Iteration: 1940 , loss: 3.689025 Accuracy: 0.652000\n",
      " Iteration: 1950 , loss: 3.716350 Accuracy: 0.588000\n",
      "The postprocessing average accuracy is: 0.8375 and the number of correct results is: 201\n",
      " Iteration: 1960 , loss: 3.674400 Accuracy: 0.644000\n",
      " Iteration: 1970 , loss: 3.670345 Accuracy: 0.644000\n",
      " Iteration: 1980 , loss: 3.697071 Accuracy: 0.612000\n",
      " Iteration: 1990 , loss: 3.662652 Accuracy: 0.652000\n",
      " Iteration: 2000 , loss: 3.681668 Accuracy: 0.648000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 2010 , loss: 3.695054 Accuracy: 0.608000\n",
      " Iteration: 2020 , loss: 3.649052 Accuracy: 0.692000\n",
      " Iteration: 2030 , loss: 3.683784 Accuracy: 0.636000\n",
      " Iteration: 2040 , loss: 3.719870 Accuracy: 0.584000\n",
      " Iteration: 2050 , loss: 3.712993 Accuracy: 0.624000\n",
      "The postprocessing average accuracy is: 0.8208333333333333 and the number of correct results is: 197\n",
      " Iteration: 2060 , loss: 3.675735 Accuracy: 0.596000\n",
      " Iteration: 2070 , loss: 3.712599 Accuracy: 0.600000\n",
      " Iteration: 2080 , loss: 3.670498 Accuracy: 0.632000\n",
      " Iteration: 2090 , loss: 3.688075 Accuracy: 0.592000\n",
      " Iteration: 2100 , loss: 3.662496 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8416666666666667 and the number of correct results is: 202\n",
      " Iteration: 2110 , loss: 3.740030 Accuracy: 0.576000\n",
      " Iteration: 2120 , loss: 3.683893 Accuracy: 0.604000\n",
      " Iteration: 2130 , loss: 3.657487 Accuracy: 0.632000\n",
      " Iteration: 2140 , loss: 3.716375 Accuracy: 0.592000\n",
      " Iteration: 2150 , loss: 3.722584 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.8166666666666667 and the number of correct results is: 196\n",
      " Iteration: 2160 , loss: 3.683325 Accuracy: 0.624000\n",
      " Iteration: 2170 , loss: 3.659240 Accuracy: 0.672000\n",
      " Iteration: 2180 , loss: 3.676813 Accuracy: 0.604000\n",
      " Iteration: 2190 , loss: 3.677908 Accuracy: 0.616000\n",
      " Iteration: 2200 , loss: 3.707826 Accuracy: 0.596000\n",
      "The postprocessing average accuracy is: 0.8375 and the number of correct results is: 201\n",
      " Iteration: 2210 , loss: 3.683355 Accuracy: 0.608000\n",
      " Iteration: 2220 , loss: 3.688152 Accuracy: 0.624000\n",
      " Iteration: 2230 , loss: 3.654674 Accuracy: 0.672000\n",
      " Iteration: 2240 , loss: 3.708624 Accuracy: 0.588000\n",
      " Iteration: 2250 , loss: 3.659185 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.825 and the number of correct results is: 198\n",
      " Iteration: 2260 , loss: 3.669221 Accuracy: 0.628000\n",
      " Iteration: 2270 , loss: 3.663620 Accuracy: 0.632000\n",
      " Iteration: 2280 , loss: 3.656819 Accuracy: 0.676000\n",
      " Iteration: 2290 , loss: 3.694910 Accuracy: 0.664000\n",
      " Iteration: 2300 , loss: 3.666392 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.825 and the number of correct results is: 198\n",
      " Iteration: 2310 , loss: 3.685625 Accuracy: 0.640000\n",
      " Iteration: 2320 , loss: 3.660477 Accuracy: 0.660000\n",
      " Iteration: 2330 , loss: 3.677886 Accuracy: 0.616000\n",
      " Iteration: 2340 , loss: 3.681768 Accuracy: 0.588000\n",
      " Iteration: 2350 , loss: 3.676957 Accuracy: 0.616000\n",
      "The postprocessing average accuracy is: 0.8416666666666667 and the number of correct results is: 202\n",
      " Iteration: 2360 , loss: 3.676558 Accuracy: 0.648000\n",
      " Iteration: 2370 , loss: 3.638742 Accuracy: 0.656000\n",
      " Iteration: 2380 , loss: 3.661663 Accuracy: 0.644000\n",
      " Iteration: 2390 , loss: 3.652668 Accuracy: 0.692000\n",
      " Iteration: 2400 , loss: 3.671416 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 2410 , loss: 3.667099 Accuracy: 0.624000\n",
      " Iteration: 2420 , loss: 3.641589 Accuracy: 0.652000\n",
      " Iteration: 2430 , loss: 3.664592 Accuracy: 0.628000\n",
      " Iteration: 2440 , loss: 3.654700 Accuracy: 0.636000\n",
      " Iteration: 2450 , loss: 3.646006 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 2460 , loss: 3.608898 Accuracy: 0.692000\n",
      " Iteration: 2470 , loss: 3.623597 Accuracy: 0.656000\n",
      " Iteration: 2480 , loss: 3.677152 Accuracy: 0.640000\n",
      " Iteration: 2490 , loss: 3.645996 Accuracy: 0.668000\n",
      " Iteration: 2500 , loss: 3.694360 Accuracy: 0.604000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 2510 , loss: 3.666672 Accuracy: 0.640000\n",
      " Iteration: 2520 , loss: 3.685511 Accuracy: 0.604000\n",
      " Iteration: 2530 , loss: 3.638020 Accuracy: 0.656000\n",
      " Iteration: 2540 , loss: 3.636247 Accuracy: 0.648000\n",
      " Iteration: 2550 , loss: 3.693237 Accuracy: 0.620000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 2560 , loss: 3.646456 Accuracy: 0.660000\n",
      " Iteration: 2570 , loss: 3.640607 Accuracy: 0.656000\n",
      " Iteration: 2580 , loss: 3.626580 Accuracy: 0.688000\n",
      " Iteration: 2590 , loss: 3.616899 Accuracy: 0.668000\n",
      " Iteration: 2600 , loss: 3.589347 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 2610 , loss: 3.656607 Accuracy: 0.652000\n",
      " Iteration: 2620 , loss: 3.612343 Accuracy: 0.688000\n",
      " Iteration: 2630 , loss: 3.671202 Accuracy: 0.652000\n",
      " Iteration: 2640 , loss: 3.649495 Accuracy: 0.664000\n",
      " Iteration: 2650 , loss: 3.643350 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8375 and the number of correct results is: 201\n",
      " Iteration: 2660 , loss: 3.637721 Accuracy: 0.660000\n",
      " Iteration: 2670 , loss: 3.653661 Accuracy: 0.672000\n",
      " Iteration: 2680 , loss: 3.663637 Accuracy: 0.620000\n",
      " Iteration: 2690 , loss: 3.631785 Accuracy: 0.688000\n",
      " Iteration: 2700 , loss: 3.658695 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.8375 and the number of correct results is: 201\n",
      " Iteration: 2710 , loss: 3.622719 Accuracy: 0.700000\n",
      " Iteration: 2720 , loss: 3.654020 Accuracy: 0.632000\n",
      " Iteration: 2730 , loss: 3.678689 Accuracy: 0.644000\n",
      " Iteration: 2740 , loss: 3.635810 Accuracy: 0.696000\n",
      " Iteration: 2750 , loss: 3.640490 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.825 and the number of correct results is: 198\n",
      " Iteration: 2760 , loss: 3.659772 Accuracy: 0.632000\n",
      " Iteration: 2770 , loss: 3.667167 Accuracy: 0.636000\n",
      " Iteration: 2780 , loss: 3.675274 Accuracy: 0.604000\n",
      " Iteration: 2790 , loss: 3.620760 Accuracy: 0.696000\n",
      " Iteration: 2800 , loss: 3.671806 Accuracy: 0.624000\n",
      "The postprocessing average accuracy is: 0.8291666666666667 and the number of correct results is: 199\n",
      " Iteration: 2810 , loss: 3.606265 Accuracy: 0.696000\n",
      " Iteration: 2820 , loss: 3.622774 Accuracy: 0.692000\n",
      " Iteration: 2830 , loss: 3.635982 Accuracy: 0.652000\n",
      " Iteration: 2840 , loss: 3.646999 Accuracy: 0.644000\n",
      " Iteration: 2850 , loss: 3.600925 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8291666666666667 and the number of correct results is: 199\n",
      " Iteration: 2860 , loss: 3.634042 Accuracy: 0.676000\n",
      " Iteration: 2870 , loss: 3.617232 Accuracy: 0.676000\n",
      " Iteration: 2880 , loss: 3.635824 Accuracy: 0.680000\n",
      " Iteration: 2890 , loss: 3.655286 Accuracy: 0.652000\n",
      " Iteration: 2900 , loss: 3.650591 Accuracy: 0.636000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 2910 , loss: 3.612533 Accuracy: 0.692000\n",
      " Iteration: 2920 , loss: 3.653592 Accuracy: 0.660000\n",
      " Iteration: 2930 , loss: 3.639424 Accuracy: 0.684000\n",
      " Iteration: 2940 , loss: 3.646579 Accuracy: 0.656000\n",
      " Iteration: 2950 , loss: 3.610380 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8291666666666667 and the number of correct results is: 199\n",
      " Iteration: 2960 , loss: 3.670129 Accuracy: 0.656000\n",
      " Iteration: 2970 , loss: 3.587389 Accuracy: 0.716000\n",
      " Iteration: 2980 , loss: 3.671283 Accuracy: 0.640000\n",
      " Iteration: 2990 , loss: 3.631129 Accuracy: 0.652000\n",
      " Iteration: 3000 , loss: 3.620392 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 3010 , loss: 3.603168 Accuracy: 0.716000\n",
      " Iteration: 3020 , loss: 3.646207 Accuracy: 0.644000\n",
      " Iteration: 3030 , loss: 3.598151 Accuracy: 0.712000\n",
      " Iteration: 3040 , loss: 3.618795 Accuracy: 0.700000\n",
      " Iteration: 3050 , loss: 3.650743 Accuracy: 0.664000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 3060 , loss: 3.661115 Accuracy: 0.632000\n",
      " Iteration: 3070 , loss: 3.630005 Accuracy: 0.688000\n",
      " Iteration: 3080 , loss: 3.598648 Accuracy: 0.704000\n",
      " Iteration: 3090 , loss: 3.626561 Accuracy: 0.672000\n",
      " Iteration: 3100 , loss: 3.626055 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.8375 and the number of correct results is: 201\n",
      " Iteration: 3110 , loss: 3.609690 Accuracy: 0.692000\n",
      " Iteration: 3120 , loss: 3.632997 Accuracy: 0.656000\n",
      " Iteration: 3130 , loss: 3.643781 Accuracy: 0.636000\n",
      " Iteration: 3140 , loss: 3.645686 Accuracy: 0.644000\n",
      " Iteration: 3150 , loss: 3.649978 Accuracy: 0.640000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 3160 , loss: 3.622796 Accuracy: 0.660000\n",
      " Iteration: 3170 , loss: 3.620520 Accuracy: 0.668000\n",
      " Iteration: 3180 , loss: 3.613839 Accuracy: 0.692000\n",
      " Iteration: 3190 , loss: 3.600739 Accuracy: 0.708000\n",
      " Iteration: 3200 , loss: 3.623765 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.85 and the number of correct results is: 204\n",
      " Iteration: 3210 , loss: 3.642825 Accuracy: 0.632000\n",
      " Iteration: 3220 , loss: 3.635226 Accuracy: 0.660000\n",
      " Iteration: 3230 , loss: 3.633139 Accuracy: 0.696000\n",
      " Iteration: 3240 , loss: 3.626401 Accuracy: 0.672000\n",
      " Iteration: 3250 , loss: 3.613273 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 3260 , loss: 3.615284 Accuracy: 0.656000\n",
      " Iteration: 3270 , loss: 3.598428 Accuracy: 0.696000\n",
      " Iteration: 3280 , loss: 3.582422 Accuracy: 0.708000\n",
      " Iteration: 3290 , loss: 3.647485 Accuracy: 0.664000\n",
      " Iteration: 3300 , loss: 3.645875 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 3310 , loss: 3.658087 Accuracy: 0.624000\n",
      " Iteration: 3320 , loss: 3.627360 Accuracy: 0.664000\n",
      " Iteration: 3330 , loss: 3.646786 Accuracy: 0.668000\n",
      " Iteration: 3340 , loss: 3.633078 Accuracy: 0.664000\n",
      " Iteration: 3350 , loss: 3.600095 Accuracy: 0.680000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 3360 , loss: 3.655401 Accuracy: 0.660000\n",
      " Iteration: 3370 , loss: 3.616610 Accuracy: 0.680000\n",
      " Iteration: 3380 , loss: 3.600290 Accuracy: 0.668000\n",
      " Iteration: 3390 , loss: 3.619398 Accuracy: 0.680000\n",
      " Iteration: 3400 , loss: 3.611523 Accuracy: 0.652000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 3410 , loss: 3.628140 Accuracy: 0.660000\n",
      " Iteration: 3420 , loss: 3.624946 Accuracy: 0.692000\n",
      " Iteration: 3430 , loss: 3.573835 Accuracy: 0.712000\n",
      " Iteration: 3440 , loss: 3.633392 Accuracy: 0.648000\n",
      " Iteration: 3450 , loss: 3.636744 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 3460 , loss: 3.638324 Accuracy: 0.656000\n",
      " Iteration: 3470 , loss: 3.583648 Accuracy: 0.716000\n",
      " Iteration: 3480 , loss: 3.623272 Accuracy: 0.668000\n",
      " Iteration: 3490 , loss: 3.579701 Accuracy: 0.688000\n",
      " Iteration: 3500 , loss: 3.615610 Accuracy: 0.672000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 3510 , loss: 3.585397 Accuracy: 0.728000\n",
      " Iteration: 3520 , loss: 3.605374 Accuracy: 0.664000\n",
      " Iteration: 3530 , loss: 3.622219 Accuracy: 0.652000\n",
      " Iteration: 3540 , loss: 3.635990 Accuracy: 0.664000\n",
      " Iteration: 3550 , loss: 3.591171 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 3560 , loss: 3.632638 Accuracy: 0.644000\n",
      " Iteration: 3570 , loss: 3.604060 Accuracy: 0.692000\n",
      " Iteration: 3580 , loss: 3.636312 Accuracy: 0.660000\n",
      " Iteration: 3590 , loss: 3.615802 Accuracy: 0.648000\n",
      " Iteration: 3600 , loss: 3.598355 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 3610 , loss: 3.591303 Accuracy: 0.716000\n",
      " Iteration: 3620 , loss: 3.623283 Accuracy: 0.676000\n",
      " Iteration: 3630 , loss: 3.615061 Accuracy: 0.656000\n",
      " Iteration: 3640 , loss: 3.608246 Accuracy: 0.672000\n",
      " Iteration: 3650 , loss: 3.610588 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8416666666666667 and the number of correct results is: 202\n",
      " Iteration: 3660 , loss: 3.624817 Accuracy: 0.684000\n",
      " Iteration: 3670 , loss: 3.594704 Accuracy: 0.728000\n",
      " Iteration: 3680 , loss: 3.576324 Accuracy: 0.736000\n",
      " Iteration: 3690 , loss: 3.606833 Accuracy: 0.716000\n",
      " Iteration: 3700 , loss: 3.604651 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 3710 , loss: 3.631792 Accuracy: 0.640000\n",
      " Iteration: 3720 , loss: 3.623051 Accuracy: 0.640000\n",
      " Iteration: 3730 , loss: 3.615171 Accuracy: 0.680000\n",
      " Iteration: 3740 , loss: 3.604800 Accuracy: 0.676000\n",
      " Iteration: 3750 , loss: 3.615373 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 3760 , loss: 3.610153 Accuracy: 0.672000\n",
      " Iteration: 3770 , loss: 3.620627 Accuracy: 0.688000\n",
      " Iteration: 3780 , loss: 3.654318 Accuracy: 0.632000\n",
      " Iteration: 3790 , loss: 3.605068 Accuracy: 0.692000\n",
      " Iteration: 3800 , loss: 3.589585 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 3810 , loss: 3.607592 Accuracy: 0.712000\n",
      " Iteration: 3820 , loss: 3.587767 Accuracy: 0.704000\n",
      " Iteration: 3830 , loss: 3.567150 Accuracy: 0.720000\n",
      " Iteration: 3840 , loss: 3.620113 Accuracy: 0.664000\n",
      " Iteration: 3850 , loss: 3.578785 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 3860 , loss: 3.595632 Accuracy: 0.708000\n",
      " Iteration: 3870 , loss: 3.596158 Accuracy: 0.752000\n",
      " Iteration: 3880 , loss: 3.595781 Accuracy: 0.688000\n",
      " Iteration: 3890 , loss: 3.629056 Accuracy: 0.652000\n",
      " Iteration: 3900 , loss: 3.601429 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8375 and the number of correct results is: 201\n",
      " Iteration: 3910 , loss: 3.608443 Accuracy: 0.652000\n",
      " Iteration: 3920 , loss: 3.613180 Accuracy: 0.660000\n",
      " Iteration: 3930 , loss: 3.545298 Accuracy: 0.764000\n",
      " Iteration: 3940 , loss: 3.607506 Accuracy: 0.660000\n",
      " Iteration: 3950 , loss: 3.598016 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 3960 , loss: 3.587238 Accuracy: 0.696000\n",
      " Iteration: 3970 , loss: 3.594607 Accuracy: 0.704000\n",
      " Iteration: 3980 , loss: 3.602773 Accuracy: 0.680000\n",
      " Iteration: 3990 , loss: 3.595656 Accuracy: 0.688000\n",
      " Iteration: 4000 , loss: 3.606498 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 4010 , loss: 3.584768 Accuracy: 0.692000\n",
      " Iteration: 4020 , loss: 3.610602 Accuracy: 0.704000\n",
      " Iteration: 4030 , loss: 3.585834 Accuracy: 0.712000\n",
      " Iteration: 4040 , loss: 3.563211 Accuracy: 0.708000\n",
      " Iteration: 4050 , loss: 3.569574 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8458333333333333 and the number of correct results is: 203\n",
      " Iteration: 4060 , loss: 3.598130 Accuracy: 0.712000\n",
      " Iteration: 4070 , loss: 3.585255 Accuracy: 0.740000\n",
      " Iteration: 4080 , loss: 3.569815 Accuracy: 0.708000\n",
      " Iteration: 4090 , loss: 3.576176 Accuracy: 0.732000\n",
      " Iteration: 4100 , loss: 3.565693 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 4110 , loss: 3.563914 Accuracy: 0.752000\n",
      " Iteration: 4120 , loss: 3.614055 Accuracy: 0.660000\n",
      " Iteration: 4130 , loss: 3.594234 Accuracy: 0.688000\n",
      " Iteration: 4140 , loss: 3.569854 Accuracy: 0.732000\n",
      " Iteration: 4150 , loss: 3.575377 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 4160 , loss: 3.587972 Accuracy: 0.732000\n",
      " Iteration: 4170 , loss: 3.593817 Accuracy: 0.688000\n",
      " Iteration: 4180 , loss: 3.599809 Accuracy: 0.700000\n",
      " Iteration: 4190 , loss: 3.529148 Accuracy: 0.764000\n",
      " Iteration: 4200 , loss: 3.608302 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 4210 , loss: 3.601581 Accuracy: 0.688000\n",
      " Iteration: 4220 , loss: 3.567130 Accuracy: 0.748000\n",
      " Iteration: 4230 , loss: 3.613894 Accuracy: 0.656000\n",
      " Iteration: 4240 , loss: 3.584489 Accuracy: 0.688000\n",
      " Iteration: 4250 , loss: 3.604549 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.85 and the number of correct results is: 204\n",
      " Iteration: 4260 , loss: 3.591776 Accuracy: 0.732000\n",
      " Iteration: 4270 , loss: 3.600855 Accuracy: 0.696000\n",
      " Iteration: 4280 , loss: 3.530236 Accuracy: 0.764000\n",
      " Iteration: 4290 , loss: 3.579110 Accuracy: 0.732000\n",
      " Iteration: 4300 , loss: 3.590073 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 4310 , loss: 3.556656 Accuracy: 0.752000\n",
      " Iteration: 4320 , loss: 3.549782 Accuracy: 0.760000\n",
      " Iteration: 4330 , loss: 3.591341 Accuracy: 0.700000\n",
      " Iteration: 4340 , loss: 3.576853 Accuracy: 0.732000\n",
      " Iteration: 4350 , loss: 3.618589 Accuracy: 0.660000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 4360 , loss: 3.603801 Accuracy: 0.680000\n",
      " Iteration: 4370 , loss: 3.577383 Accuracy: 0.724000\n",
      " Iteration: 4380 , loss: 3.568133 Accuracy: 0.700000\n",
      " Iteration: 4390 , loss: 3.585839 Accuracy: 0.708000\n",
      " Iteration: 4400 , loss: 3.596546 Accuracy: 0.668000\n",
      "The postprocessing average accuracy is: 0.85 and the number of correct results is: 204\n",
      " Iteration: 4410 , loss: 3.564364 Accuracy: 0.720000\n",
      " Iteration: 4420 , loss: 3.549458 Accuracy: 0.732000\n",
      " Iteration: 4430 , loss: 3.604788 Accuracy: 0.664000\n",
      " Iteration: 4440 , loss: 3.571553 Accuracy: 0.696000\n",
      " Iteration: 4450 , loss: 3.586317 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.85 and the number of correct results is: 204\n",
      " Iteration: 4460 , loss: 3.549933 Accuracy: 0.756000\n",
      " Iteration: 4470 , loss: 3.572405 Accuracy: 0.716000\n",
      " Iteration: 4480 , loss: 3.584160 Accuracy: 0.692000\n",
      " Iteration: 4490 , loss: 3.571873 Accuracy: 0.716000\n",
      " Iteration: 4500 , loss: 3.646146 Accuracy: 0.676000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 4510 , loss: 3.586123 Accuracy: 0.716000\n",
      " Iteration: 4520 , loss: 3.580815 Accuracy: 0.724000\n",
      " Iteration: 4530 , loss: 3.568793 Accuracy: 0.740000\n",
      " Iteration: 4540 , loss: 3.582641 Accuracy: 0.688000\n",
      " Iteration: 4550 , loss: 3.611296 Accuracy: 0.696000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 4560 , loss: 3.600886 Accuracy: 0.684000\n",
      " Iteration: 4570 , loss: 3.581693 Accuracy: 0.732000\n",
      " Iteration: 4580 , loss: 3.567962 Accuracy: 0.728000\n",
      " Iteration: 4590 , loss: 3.595004 Accuracy: 0.684000\n",
      " Iteration: 4600 , loss: 3.558806 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 4610 , loss: 3.578857 Accuracy: 0.732000\n",
      " Iteration: 4620 , loss: 3.650209 Accuracy: 0.652000\n",
      " Iteration: 4630 , loss: 3.584945 Accuracy: 0.688000\n",
      " Iteration: 4640 , loss: 3.553452 Accuracy: 0.724000\n",
      " Iteration: 4650 , loss: 3.598447 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 4660 , loss: 3.596768 Accuracy: 0.672000\n",
      " Iteration: 4670 , loss: 3.599658 Accuracy: 0.652000\n",
      " Iteration: 4680 , loss: 3.571403 Accuracy: 0.684000\n",
      " Iteration: 4690 , loss: 3.611937 Accuracy: 0.648000\n",
      " Iteration: 4700 , loss: 3.563673 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 4710 , loss: 3.586203 Accuracy: 0.728000\n",
      " Iteration: 4720 , loss: 3.584346 Accuracy: 0.692000\n",
      " Iteration: 4730 , loss: 3.574504 Accuracy: 0.760000\n",
      " Iteration: 4740 , loss: 3.604639 Accuracy: 0.712000\n",
      " Iteration: 4750 , loss: 3.561999 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 4760 , loss: 3.582692 Accuracy: 0.712000\n",
      " Iteration: 4770 , loss: 3.552112 Accuracy: 0.704000\n",
      " Iteration: 4780 , loss: 3.569544 Accuracy: 0.724000\n",
      " Iteration: 4790 , loss: 3.606007 Accuracy: 0.696000\n",
      " Iteration: 4800 , loss: 3.572690 Accuracy: 0.684000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 4810 , loss: 3.594884 Accuracy: 0.688000\n",
      " Iteration: 4820 , loss: 3.578518 Accuracy: 0.696000\n",
      " Iteration: 4830 , loss: 3.603302 Accuracy: 0.680000\n",
      " Iteration: 4840 , loss: 3.570879 Accuracy: 0.736000\n",
      " Iteration: 4850 , loss: 3.591457 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 4860 , loss: 3.622166 Accuracy: 0.656000\n",
      " Iteration: 4870 , loss: 3.589068 Accuracy: 0.716000\n",
      " Iteration: 4880 , loss: 3.561835 Accuracy: 0.752000\n",
      " Iteration: 4890 , loss: 3.579627 Accuracy: 0.700000\n",
      " Iteration: 4900 , loss: 3.579937 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 4910 , loss: 3.553738 Accuracy: 0.744000\n",
      " Iteration: 4920 , loss: 3.556853 Accuracy: 0.720000\n",
      " Iteration: 4930 , loss: 3.583048 Accuracy: 0.704000\n",
      " Iteration: 4940 , loss: 3.572799 Accuracy: 0.696000\n",
      " Iteration: 4950 , loss: 3.549637 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 4960 , loss: 3.553404 Accuracy: 0.744000\n",
      " Iteration: 4970 , loss: 3.568441 Accuracy: 0.752000\n",
      " Iteration: 4980 , loss: 3.584467 Accuracy: 0.680000\n",
      " Iteration: 4990 , loss: 3.587720 Accuracy: 0.728000\n",
      " Iteration: 5000 , loss: 3.600624 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 5010 , loss: 3.571805 Accuracy: 0.728000\n",
      " Iteration: 5020 , loss: 3.582251 Accuracy: 0.688000\n",
      " Iteration: 5030 , loss: 3.600337 Accuracy: 0.636000\n",
      " Iteration: 5040 , loss: 3.546089 Accuracy: 0.736000\n",
      " Iteration: 5050 , loss: 3.565284 Accuracy: 0.712000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 5060 , loss: 3.568021 Accuracy: 0.684000\n",
      " Iteration: 5070 , loss: 3.556858 Accuracy: 0.752000\n",
      " Iteration: 5080 , loss: 3.531493 Accuracy: 0.744000\n",
      " Iteration: 5090 , loss: 3.530612 Accuracy: 0.760000\n",
      " Iteration: 5100 , loss: 3.544669 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 5110 , loss: 3.594409 Accuracy: 0.692000\n",
      " Iteration: 5120 , loss: 3.551048 Accuracy: 0.708000\n",
      " Iteration: 5130 , loss: 3.528808 Accuracy: 0.740000\n",
      " Iteration: 5140 , loss: 3.578333 Accuracy: 0.712000\n",
      " Iteration: 5150 , loss: 3.576854 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 5160 , loss: 3.530054 Accuracy: 0.752000\n",
      " Iteration: 5170 , loss: 3.562348 Accuracy: 0.720000\n",
      " Iteration: 5180 , loss: 3.562405 Accuracy: 0.728000\n",
      " Iteration: 5190 , loss: 3.558162 Accuracy: 0.736000\n",
      " Iteration: 5200 , loss: 3.562729 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 5210 , loss: 3.539697 Accuracy: 0.768000\n",
      " Iteration: 5220 , loss: 3.550032 Accuracy: 0.776000\n",
      " Iteration: 5230 , loss: 3.578560 Accuracy: 0.704000\n",
      " Iteration: 5240 , loss: 3.589464 Accuracy: 0.712000\n",
      " Iteration: 5250 , loss: 3.550560 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 5260 , loss: 3.579358 Accuracy: 0.708000\n",
      " Iteration: 5270 , loss: 3.557382 Accuracy: 0.748000\n",
      " Iteration: 5280 , loss: 3.551647 Accuracy: 0.736000\n",
      " Iteration: 5290 , loss: 3.552018 Accuracy: 0.736000\n",
      " Iteration: 5300 , loss: 3.597516 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 5310 , loss: 3.550495 Accuracy: 0.720000\n",
      " Iteration: 5320 , loss: 3.574575 Accuracy: 0.716000\n",
      " Iteration: 5330 , loss: 3.573013 Accuracy: 0.716000\n",
      " Iteration: 5340 , loss: 3.580910 Accuracy: 0.712000\n",
      " Iteration: 5350 , loss: 3.580206 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 5360 , loss: 3.516130 Accuracy: 0.768000\n",
      " Iteration: 5370 , loss: 3.570400 Accuracy: 0.720000\n",
      " Iteration: 5380 , loss: 3.547709 Accuracy: 0.728000\n",
      " Iteration: 5390 , loss: 3.595116 Accuracy: 0.680000\n",
      " Iteration: 5400 , loss: 3.598498 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 5410 , loss: 3.590105 Accuracy: 0.700000\n",
      " Iteration: 5420 , loss: 3.581095 Accuracy: 0.728000\n",
      " Iteration: 5430 , loss: 3.525060 Accuracy: 0.732000\n",
      " Iteration: 5440 , loss: 3.566769 Accuracy: 0.712000\n",
      " Iteration: 5450 , loss: 3.572946 Accuracy: 0.692000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 5460 , loss: 3.561900 Accuracy: 0.744000\n",
      " Iteration: 5470 , loss: 3.578491 Accuracy: 0.740000\n",
      " Iteration: 5480 , loss: 3.523959 Accuracy: 0.764000\n",
      " Iteration: 5490 , loss: 3.532356 Accuracy: 0.748000\n",
      " Iteration: 5500 , loss: 3.531801 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 5510 , loss: 3.548499 Accuracy: 0.712000\n",
      " Iteration: 5520 , loss: 3.553699 Accuracy: 0.704000\n",
      " Iteration: 5530 , loss: 3.588458 Accuracy: 0.676000\n",
      " Iteration: 5540 , loss: 3.555457 Accuracy: 0.728000\n",
      " Iteration: 5550 , loss: 3.553635 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 5560 , loss: 3.504249 Accuracy: 0.784000\n",
      " Iteration: 5570 , loss: 3.543439 Accuracy: 0.748000\n",
      " Iteration: 5580 , loss: 3.589690 Accuracy: 0.692000\n",
      " Iteration: 5590 , loss: 3.561766 Accuracy: 0.720000\n",
      " Iteration: 5600 , loss: 3.553867 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 5610 , loss: 3.570487 Accuracy: 0.676000\n",
      " Iteration: 5620 , loss: 3.559826 Accuracy: 0.720000\n",
      " Iteration: 5630 , loss: 3.507005 Accuracy: 0.752000\n",
      " Iteration: 5640 , loss: 3.495410 Accuracy: 0.768000\n",
      " Iteration: 5650 , loss: 3.538346 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 5660 , loss: 3.531885 Accuracy: 0.780000\n",
      " Iteration: 5670 , loss: 3.517605 Accuracy: 0.776000\n",
      " Iteration: 5680 , loss: 3.546063 Accuracy: 0.760000\n",
      " Iteration: 5690 , loss: 3.557727 Accuracy: 0.756000\n",
      " Iteration: 5700 , loss: 3.546484 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 5710 , loss: 3.568769 Accuracy: 0.716000\n",
      " Iteration: 5720 , loss: 3.564994 Accuracy: 0.728000\n",
      " Iteration: 5730 , loss: 3.584497 Accuracy: 0.712000\n",
      " Iteration: 5740 , loss: 3.590970 Accuracy: 0.716000\n",
      " Iteration: 5750 , loss: 3.538501 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 5760 , loss: 3.542473 Accuracy: 0.756000\n",
      " Iteration: 5770 , loss: 3.543088 Accuracy: 0.740000\n",
      " Iteration: 5780 , loss: 3.544735 Accuracy: 0.736000\n",
      " Iteration: 5790 , loss: 3.566986 Accuracy: 0.704000\n",
      " Iteration: 5800 , loss: 3.569094 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 5810 , loss: 3.540889 Accuracy: 0.748000\n",
      " Iteration: 5820 , loss: 3.533171 Accuracy: 0.772000\n",
      " Iteration: 5830 , loss: 3.530309 Accuracy: 0.744000\n",
      " Iteration: 5840 , loss: 3.548540 Accuracy: 0.720000\n",
      " Iteration: 5850 , loss: 3.547767 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 5860 , loss: 3.562386 Accuracy: 0.724000\n",
      " Iteration: 5870 , loss: 3.544637 Accuracy: 0.712000\n",
      " Iteration: 5880 , loss: 3.557815 Accuracy: 0.740000\n",
      " Iteration: 5890 , loss: 3.556222 Accuracy: 0.740000\n",
      " Iteration: 5900 , loss: 3.551236 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 5910 , loss: 3.557415 Accuracy: 0.740000\n",
      " Iteration: 5920 , loss: 3.563412 Accuracy: 0.740000\n",
      " Iteration: 5930 , loss: 3.544602 Accuracy: 0.736000\n",
      " Iteration: 5940 , loss: 3.561219 Accuracy: 0.748000\n",
      " Iteration: 5950 , loss: 3.524903 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 5960 , loss: 3.547330 Accuracy: 0.736000\n",
      " Iteration: 5970 , loss: 3.556141 Accuracy: 0.708000\n",
      " Iteration: 5980 , loss: 3.534114 Accuracy: 0.720000\n",
      " Iteration: 5990 , loss: 3.538675 Accuracy: 0.740000\n",
      " Iteration: 6000 , loss: 3.589442 Accuracy: 0.688000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 6010 , loss: 3.552850 Accuracy: 0.740000\n",
      " Iteration: 6020 , loss: 3.544330 Accuracy: 0.748000\n",
      " Iteration: 6030 , loss: 3.516343 Accuracy: 0.788000\n",
      " Iteration: 6040 , loss: 3.547438 Accuracy: 0.736000\n",
      " Iteration: 6050 , loss: 3.561087 Accuracy: 0.724000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 6060 , loss: 3.513227 Accuracy: 0.792000\n",
      " Iteration: 6070 , loss: 3.563986 Accuracy: 0.716000\n",
      " Iteration: 6080 , loss: 3.555127 Accuracy: 0.720000\n",
      " Iteration: 6090 , loss: 3.539948 Accuracy: 0.748000\n",
      " Iteration: 6100 , loss: 3.532400 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 6110 , loss: 3.565603 Accuracy: 0.708000\n",
      " Iteration: 6120 , loss: 3.491548 Accuracy: 0.804000\n",
      " Iteration: 6130 , loss: 3.559140 Accuracy: 0.736000\n",
      " Iteration: 6140 , loss: 3.540896 Accuracy: 0.760000\n",
      " Iteration: 6150 , loss: 3.541599 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 6160 , loss: 3.571142 Accuracy: 0.704000\n",
      " Iteration: 6170 , loss: 3.554419 Accuracy: 0.764000\n",
      " Iteration: 6180 , loss: 3.535421 Accuracy: 0.752000\n",
      " Iteration: 6190 , loss: 3.563180 Accuracy: 0.716000\n",
      " Iteration: 6200 , loss: 3.550474 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 6210 , loss: 3.574450 Accuracy: 0.720000\n",
      " Iteration: 6220 , loss: 3.587572 Accuracy: 0.692000\n",
      " Iteration: 6230 , loss: 3.558246 Accuracy: 0.704000\n",
      " Iteration: 6240 , loss: 3.520554 Accuracy: 0.760000\n",
      " Iteration: 6250 , loss: 3.535112 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 6260 , loss: 3.515831 Accuracy: 0.740000\n",
      " Iteration: 6270 , loss: 3.565679 Accuracy: 0.700000\n",
      " Iteration: 6280 , loss: 3.565217 Accuracy: 0.708000\n",
      " Iteration: 6290 , loss: 3.533761 Accuracy: 0.760000\n",
      " Iteration: 6300 , loss: 3.543398 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 6310 , loss: 3.542851 Accuracy: 0.748000\n",
      " Iteration: 6320 , loss: 3.543537 Accuracy: 0.712000\n",
      " Iteration: 6330 , loss: 3.590665 Accuracy: 0.692000\n",
      " Iteration: 6340 , loss: 3.548641 Accuracy: 0.732000\n",
      " Iteration: 6350 , loss: 3.560146 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 6360 , loss: 3.508867 Accuracy: 0.808000\n",
      " Iteration: 6370 , loss: 3.555482 Accuracy: 0.756000\n",
      " Iteration: 6380 , loss: 3.541548 Accuracy: 0.740000\n",
      " Iteration: 6390 , loss: 3.559711 Accuracy: 0.704000\n",
      " Iteration: 6400 , loss: 3.539969 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 6410 , loss: 3.542395 Accuracy: 0.744000\n",
      " Iteration: 6420 , loss: 3.534277 Accuracy: 0.740000\n",
      " Iteration: 6430 , loss: 3.532302 Accuracy: 0.752000\n",
      " Iteration: 6440 , loss: 3.552295 Accuracy: 0.704000\n",
      " Iteration: 6450 , loss: 3.548742 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 6460 , loss: 3.538529 Accuracy: 0.736000\n",
      " Iteration: 6470 , loss: 3.563445 Accuracy: 0.740000\n",
      " Iteration: 6480 , loss: 3.528489 Accuracy: 0.732000\n",
      " Iteration: 6490 , loss: 3.576097 Accuracy: 0.704000\n",
      " Iteration: 6500 , loss: 3.556709 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 6510 , loss: 3.506491 Accuracy: 0.784000\n",
      " Iteration: 6520 , loss: 3.547496 Accuracy: 0.720000\n",
      " Iteration: 6530 , loss: 3.536349 Accuracy: 0.764000\n",
      " Iteration: 6540 , loss: 3.526907 Accuracy: 0.756000\n",
      " Iteration: 6550 , loss: 3.561080 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 6560 , loss: 3.568707 Accuracy: 0.716000\n",
      " Iteration: 6570 , loss: 3.555439 Accuracy: 0.708000\n",
      " Iteration: 6580 , loss: 3.527196 Accuracy: 0.760000\n",
      " Iteration: 6590 , loss: 3.549703 Accuracy: 0.720000\n",
      " Iteration: 6600 , loss: 3.562418 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 6610 , loss: 3.545731 Accuracy: 0.704000\n",
      " Iteration: 6620 , loss: 3.543925 Accuracy: 0.720000\n",
      " Iteration: 6630 , loss: 3.526165 Accuracy: 0.772000\n",
      " Iteration: 6640 , loss: 3.533673 Accuracy: 0.732000\n",
      " Iteration: 6650 , loss: 3.536750 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 6660 , loss: 3.530093 Accuracy: 0.744000\n",
      " Iteration: 6670 , loss: 3.487692 Accuracy: 0.824000\n",
      " Iteration: 6680 , loss: 3.526727 Accuracy: 0.732000\n",
      " Iteration: 6690 , loss: 3.523732 Accuracy: 0.764000\n",
      " Iteration: 6700 , loss: 3.538092 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 6710 , loss: 3.579263 Accuracy: 0.680000\n",
      " Iteration: 6720 , loss: 3.523681 Accuracy: 0.736000\n",
      " Iteration: 6730 , loss: 3.552274 Accuracy: 0.740000\n",
      " Iteration: 6740 , loss: 3.522786 Accuracy: 0.764000\n",
      " Iteration: 6750 , loss: 3.544283 Accuracy: 0.728000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 6760 , loss: 3.491131 Accuracy: 0.800000\n",
      " Iteration: 6770 , loss: 3.543676 Accuracy: 0.732000\n",
      " Iteration: 6780 , loss: 3.517394 Accuracy: 0.752000\n",
      " Iteration: 6790 , loss: 3.528518 Accuracy: 0.740000\n",
      " Iteration: 6800 , loss: 3.555990 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 6810 , loss: 3.534608 Accuracy: 0.736000\n",
      " Iteration: 6820 , loss: 3.527747 Accuracy: 0.764000\n",
      " Iteration: 6830 , loss: 3.518830 Accuracy: 0.732000\n",
      " Iteration: 6840 , loss: 3.527642 Accuracy: 0.768000\n",
      " Iteration: 6850 , loss: 3.555553 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 6860 , loss: 3.560937 Accuracy: 0.740000\n",
      " Iteration: 6870 , loss: 3.520499 Accuracy: 0.760000\n",
      " Iteration: 6880 , loss: 3.516831 Accuracy: 0.748000\n",
      " Iteration: 6890 , loss: 3.520363 Accuracy: 0.748000\n",
      " Iteration: 6900 , loss: 3.525418 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 6910 , loss: 3.529265 Accuracy: 0.760000\n",
      " Iteration: 6920 , loss: 3.530515 Accuracy: 0.744000\n",
      " Iteration: 6930 , loss: 3.526709 Accuracy: 0.752000\n",
      " Iteration: 6940 , loss: 3.525198 Accuracy: 0.780000\n",
      " Iteration: 6950 , loss: 3.541186 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 6960 , loss: 3.591195 Accuracy: 0.676000\n",
      " Iteration: 6970 , loss: 3.520453 Accuracy: 0.768000\n",
      " Iteration: 6980 , loss: 3.530888 Accuracy: 0.772000\n",
      " Iteration: 6990 , loss: 3.508742 Accuracy: 0.772000\n",
      " Iteration: 7000 , loss: 3.554398 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 7010 , loss: 3.523035 Accuracy: 0.760000\n",
      " Iteration: 7020 , loss: 3.507205 Accuracy: 0.764000\n",
      " Iteration: 7030 , loss: 3.559219 Accuracy: 0.724000\n",
      " Iteration: 7040 , loss: 3.553789 Accuracy: 0.696000\n",
      " Iteration: 7050 , loss: 3.524166 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 7060 , loss: 3.557858 Accuracy: 0.720000\n",
      " Iteration: 7070 , loss: 3.531645 Accuracy: 0.764000\n",
      " Iteration: 7080 , loss: 3.533448 Accuracy: 0.744000\n",
      " Iteration: 7090 , loss: 3.555115 Accuracy: 0.724000\n",
      " Iteration: 7100 , loss: 3.551395 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 7110 , loss: 3.576611 Accuracy: 0.708000\n",
      " Iteration: 7120 , loss: 3.508601 Accuracy: 0.752000\n",
      " Iteration: 7130 , loss: 3.538919 Accuracy: 0.736000\n",
      " Iteration: 7140 , loss: 3.493417 Accuracy: 0.764000\n",
      " Iteration: 7150 , loss: 3.513383 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 7160 , loss: 3.530982 Accuracy: 0.768000\n",
      " Iteration: 7170 , loss: 3.532274 Accuracy: 0.752000\n",
      " Iteration: 7180 , loss: 3.513821 Accuracy: 0.768000\n",
      " Iteration: 7190 , loss: 3.528711 Accuracy: 0.764000\n",
      " Iteration: 7200 , loss: 3.569865 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 7210 , loss: 3.519619 Accuracy: 0.748000\n",
      " Iteration: 7220 , loss: 3.488479 Accuracy: 0.800000\n",
      " Iteration: 7230 , loss: 3.494998 Accuracy: 0.784000\n",
      " Iteration: 7240 , loss: 3.523108 Accuracy: 0.756000\n",
      " Iteration: 7250 , loss: 3.519435 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 7260 , loss: 3.500400 Accuracy: 0.788000\n",
      " Iteration: 7270 , loss: 3.521691 Accuracy: 0.772000\n",
      " Iteration: 7280 , loss: 3.504491 Accuracy: 0.784000\n",
      " Iteration: 7290 , loss: 3.498221 Accuracy: 0.768000\n",
      " Iteration: 7300 , loss: 3.539586 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 7310 , loss: 3.541691 Accuracy: 0.732000\n",
      " Iteration: 7320 , loss: 3.506742 Accuracy: 0.776000\n",
      " Iteration: 7330 , loss: 3.522834 Accuracy: 0.736000\n",
      " Iteration: 7340 , loss: 3.562701 Accuracy: 0.724000\n",
      " Iteration: 7350 , loss: 3.555444 Accuracy: 0.740000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 7360 , loss: 3.525187 Accuracy: 0.748000\n",
      " Iteration: 7370 , loss: 3.526984 Accuracy: 0.764000\n",
      " Iteration: 7380 , loss: 3.558953 Accuracy: 0.736000\n",
      " Iteration: 7390 , loss: 3.536685 Accuracy: 0.740000\n",
      " Iteration: 7400 , loss: 3.556324 Accuracy: 0.700000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 7410 , loss: 3.519390 Accuracy: 0.732000\n",
      " Iteration: 7420 , loss: 3.533735 Accuracy: 0.760000\n",
      " Iteration: 7430 , loss: 3.538626 Accuracy: 0.760000\n",
      " Iteration: 7440 , loss: 3.531712 Accuracy: 0.720000\n",
      " Iteration: 7450 , loss: 3.514289 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 7460 , loss: 3.501055 Accuracy: 0.780000\n",
      " Iteration: 7470 , loss: 3.552344 Accuracy: 0.748000\n",
      " Iteration: 7480 , loss: 3.534934 Accuracy: 0.756000\n",
      " Iteration: 7490 , loss: 3.487111 Accuracy: 0.776000\n",
      " Iteration: 7500 , loss: 3.497433 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 7510 , loss: 3.522313 Accuracy: 0.776000\n",
      " Iteration: 7520 , loss: 3.511117 Accuracy: 0.780000\n",
      " Iteration: 7530 , loss: 3.523740 Accuracy: 0.776000\n",
      " Iteration: 7540 , loss: 3.541819 Accuracy: 0.736000\n",
      " Iteration: 7550 , loss: 3.534809 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 7560 , loss: 3.532683 Accuracy: 0.736000\n",
      " Iteration: 7570 , loss: 3.537500 Accuracy: 0.728000\n",
      " Iteration: 7580 , loss: 3.553623 Accuracy: 0.740000\n",
      " Iteration: 7590 , loss: 3.517979 Accuracy: 0.796000\n",
      " Iteration: 7600 , loss: 3.496152 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8583333333333333 and the number of correct results is: 206\n",
      " Iteration: 7610 , loss: 3.517425 Accuracy: 0.764000\n",
      " Iteration: 7620 , loss: 3.534470 Accuracy: 0.740000\n",
      " Iteration: 7630 , loss: 3.549925 Accuracy: 0.728000\n",
      " Iteration: 7640 , loss: 3.548943 Accuracy: 0.744000\n",
      " Iteration: 7650 , loss: 3.524953 Accuracy: 0.720000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 7660 , loss: 3.522269 Accuracy: 0.740000\n",
      " Iteration: 7670 , loss: 3.524179 Accuracy: 0.756000\n",
      " Iteration: 7680 , loss: 3.538521 Accuracy: 0.740000\n",
      " Iteration: 7690 , loss: 3.496437 Accuracy: 0.792000\n",
      " Iteration: 7700 , loss: 3.568476 Accuracy: 0.708000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 7710 , loss: 3.546755 Accuracy: 0.692000\n",
      " Iteration: 7720 , loss: 3.500676 Accuracy: 0.780000\n",
      " Iteration: 7730 , loss: 3.501991 Accuracy: 0.748000\n",
      " Iteration: 7740 , loss: 3.529732 Accuracy: 0.732000\n",
      " Iteration: 7750 , loss: 3.509239 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 7760 , loss: 3.547281 Accuracy: 0.716000\n",
      " Iteration: 7770 , loss: 3.496563 Accuracy: 0.808000\n",
      " Iteration: 7780 , loss: 3.529150 Accuracy: 0.728000\n",
      " Iteration: 7790 , loss: 3.513340 Accuracy: 0.760000\n",
      " Iteration: 7800 , loss: 3.486971 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 7810 , loss: 3.500065 Accuracy: 0.796000\n",
      " Iteration: 7820 , loss: 3.511981 Accuracy: 0.804000\n",
      " Iteration: 7830 , loss: 3.502420 Accuracy: 0.772000\n",
      " Iteration: 7840 , loss: 3.536822 Accuracy: 0.752000\n",
      " Iteration: 7850 , loss: 3.549248 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 7860 , loss: 3.522971 Accuracy: 0.736000\n",
      " Iteration: 7870 , loss: 3.556558 Accuracy: 0.712000\n",
      " Iteration: 7880 , loss: 3.558604 Accuracy: 0.704000\n",
      " Iteration: 7890 , loss: 3.521552 Accuracy: 0.748000\n",
      " Iteration: 7900 , loss: 3.501723 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 7910 , loss: 3.525655 Accuracy: 0.732000\n",
      " Iteration: 7920 , loss: 3.501540 Accuracy: 0.784000\n",
      " Iteration: 7930 , loss: 3.503811 Accuracy: 0.772000\n",
      " Iteration: 7940 , loss: 3.514364 Accuracy: 0.764000\n",
      " Iteration: 7950 , loss: 3.513394 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 7960 , loss: 3.538929 Accuracy: 0.736000\n",
      " Iteration: 7970 , loss: 3.540905 Accuracy: 0.728000\n",
      " Iteration: 7980 , loss: 3.523870 Accuracy: 0.736000\n",
      " Iteration: 7990 , loss: 3.550339 Accuracy: 0.720000\n",
      " Iteration: 8000 , loss: 3.529179 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 8010 , loss: 3.497389 Accuracy: 0.784000\n",
      " Iteration: 8020 , loss: 3.555241 Accuracy: 0.720000\n",
      " Iteration: 8030 , loss: 3.540237 Accuracy: 0.744000\n",
      " Iteration: 8040 , loss: 3.538152 Accuracy: 0.736000\n",
      " Iteration: 8050 , loss: 3.506443 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 8060 , loss: 3.516081 Accuracy: 0.784000\n",
      " Iteration: 8070 , loss: 3.516851 Accuracy: 0.756000\n",
      " Iteration: 8080 , loss: 3.529494 Accuracy: 0.728000\n",
      " Iteration: 8090 , loss: 3.514374 Accuracy: 0.768000\n",
      " Iteration: 8100 , loss: 3.530524 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 8110 , loss: 3.505245 Accuracy: 0.772000\n",
      " Iteration: 8120 , loss: 3.541665 Accuracy: 0.716000\n",
      " Iteration: 8130 , loss: 3.522613 Accuracy: 0.740000\n",
      " Iteration: 8140 , loss: 3.488837 Accuracy: 0.808000\n",
      " Iteration: 8150 , loss: 3.468013 Accuracy: 0.820000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 8160 , loss: 3.536727 Accuracy: 0.744000\n",
      " Iteration: 8170 , loss: 3.554759 Accuracy: 0.708000\n",
      " Iteration: 8180 , loss: 3.520368 Accuracy: 0.736000\n",
      " Iteration: 8190 , loss: 3.512731 Accuracy: 0.776000\n",
      " Iteration: 8200 , loss: 3.531926 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 8210 , loss: 3.519850 Accuracy: 0.788000\n",
      " Iteration: 8220 , loss: 3.530871 Accuracy: 0.736000\n",
      " Iteration: 8230 , loss: 3.548092 Accuracy: 0.744000\n",
      " Iteration: 8240 , loss: 3.536597 Accuracy: 0.732000\n",
      " Iteration: 8250 , loss: 3.493103 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 8260 , loss: 3.521048 Accuracy: 0.764000\n",
      " Iteration: 8270 , loss: 3.511229 Accuracy: 0.784000\n",
      " Iteration: 8280 , loss: 3.534489 Accuracy: 0.748000\n",
      " Iteration: 8290 , loss: 3.483257 Accuracy: 0.804000\n",
      " Iteration: 8300 , loss: 3.517063 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 8310 , loss: 3.489122 Accuracy: 0.820000\n",
      " Iteration: 8320 , loss: 3.514189 Accuracy: 0.780000\n",
      " Iteration: 8330 , loss: 3.502751 Accuracy: 0.780000\n",
      " Iteration: 8340 , loss: 3.491856 Accuracy: 0.780000\n",
      " Iteration: 8350 , loss: 3.543760 Accuracy: 0.732000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 8360 , loss: 3.530170 Accuracy: 0.736000\n",
      " Iteration: 8370 , loss: 3.512531 Accuracy: 0.756000\n",
      " Iteration: 8380 , loss: 3.494514 Accuracy: 0.768000\n",
      " Iteration: 8390 , loss: 3.528875 Accuracy: 0.760000\n",
      " Iteration: 8400 , loss: 3.514780 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 8410 , loss: 3.549594 Accuracy: 0.744000\n",
      " Iteration: 8420 , loss: 3.528086 Accuracy: 0.744000\n",
      " Iteration: 8430 , loss: 3.522864 Accuracy: 0.752000\n",
      " Iteration: 8440 , loss: 3.488928 Accuracy: 0.768000\n",
      " Iteration: 8450 , loss: 3.529179 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 8460 , loss: 3.562790 Accuracy: 0.708000\n",
      " Iteration: 8470 , loss: 3.515281 Accuracy: 0.804000\n",
      " Iteration: 8480 , loss: 3.507179 Accuracy: 0.764000\n",
      " Iteration: 8490 , loss: 3.475337 Accuracy: 0.808000\n",
      " Iteration: 8500 , loss: 3.502321 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8541666666666666 and the number of correct results is: 205\n",
      " Iteration: 8510 , loss: 3.547336 Accuracy: 0.704000\n",
      " Iteration: 8520 , loss: 3.551850 Accuracy: 0.720000\n",
      " Iteration: 8530 , loss: 3.531938 Accuracy: 0.772000\n",
      " Iteration: 8540 , loss: 3.525164 Accuracy: 0.744000\n",
      " Iteration: 8550 , loss: 3.507739 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 8560 , loss: 3.486173 Accuracy: 0.784000\n",
      " Iteration: 8570 , loss: 3.516984 Accuracy: 0.756000\n",
      " Iteration: 8580 , loss: 3.510005 Accuracy: 0.740000\n",
      " Iteration: 8590 , loss: 3.507973 Accuracy: 0.752000\n",
      " Iteration: 8600 , loss: 3.529281 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 8610 , loss: 3.520809 Accuracy: 0.756000\n",
      " Iteration: 8620 , loss: 3.502547 Accuracy: 0.796000\n",
      " Iteration: 8630 , loss: 3.514215 Accuracy: 0.736000\n",
      " Iteration: 8640 , loss: 3.504190 Accuracy: 0.792000\n",
      " Iteration: 8650 , loss: 3.509051 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 8660 , loss: 3.483777 Accuracy: 0.796000\n",
      " Iteration: 8670 , loss: 3.500452 Accuracy: 0.776000\n",
      " Iteration: 8680 , loss: 3.521817 Accuracy: 0.760000\n",
      " Iteration: 8690 , loss: 3.523942 Accuracy: 0.768000\n",
      " Iteration: 8700 , loss: 3.518050 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 8710 , loss: 3.531440 Accuracy: 0.728000\n",
      " Iteration: 8720 , loss: 3.517887 Accuracy: 0.756000\n",
      " Iteration: 8730 , loss: 3.528997 Accuracy: 0.740000\n",
      " Iteration: 8740 , loss: 3.490890 Accuracy: 0.788000\n",
      " Iteration: 8750 , loss: 3.526632 Accuracy: 0.716000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 8760 , loss: 3.497688 Accuracy: 0.760000\n",
      " Iteration: 8770 , loss: 3.503894 Accuracy: 0.768000\n",
      " Iteration: 8780 , loss: 3.527841 Accuracy: 0.736000\n",
      " Iteration: 8790 , loss: 3.504580 Accuracy: 0.780000\n",
      " Iteration: 8800 , loss: 3.503705 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 8810 , loss: 3.502470 Accuracy: 0.748000\n",
      " Iteration: 8820 , loss: 3.540159 Accuracy: 0.744000\n",
      " Iteration: 8830 , loss: 3.509893 Accuracy: 0.744000\n",
      " Iteration: 8840 , loss: 3.510543 Accuracy: 0.764000\n",
      " Iteration: 8850 , loss: 3.521898 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8625 and the number of correct results is: 207\n",
      " Iteration: 8860 , loss: 3.510583 Accuracy: 0.772000\n",
      " Iteration: 8870 , loss: 3.553520 Accuracy: 0.732000\n",
      " Iteration: 8880 , loss: 3.452458 Accuracy: 0.840000\n",
      " Iteration: 8890 , loss: 3.499156 Accuracy: 0.744000\n",
      " Iteration: 8900 , loss: 3.483502 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 8910 , loss: 3.448673 Accuracy: 0.828000\n",
      " Iteration: 8920 , loss: 3.535802 Accuracy: 0.712000\n",
      " Iteration: 8930 , loss: 3.496651 Accuracy: 0.808000\n",
      " Iteration: 8940 , loss: 3.513086 Accuracy: 0.760000\n",
      " Iteration: 8950 , loss: 3.486638 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 8960 , loss: 3.529626 Accuracy: 0.756000\n",
      " Iteration: 8970 , loss: 3.540194 Accuracy: 0.716000\n",
      " Iteration: 8980 , loss: 3.488286 Accuracy: 0.800000\n",
      " Iteration: 8990 , loss: 3.498481 Accuracy: 0.796000\n",
      " Iteration: 9000 , loss: 3.518543 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 9010 , loss: 3.533305 Accuracy: 0.744000\n",
      " Iteration: 9020 , loss: 3.508103 Accuracy: 0.784000\n",
      " Iteration: 9030 , loss: 3.526465 Accuracy: 0.724000\n",
      " Iteration: 9040 , loss: 3.501468 Accuracy: 0.780000\n",
      " Iteration: 9050 , loss: 3.525369 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 9060 , loss: 3.516303 Accuracy: 0.768000\n",
      " Iteration: 9070 , loss: 3.502463 Accuracy: 0.776000\n",
      " Iteration: 9080 , loss: 3.506371 Accuracy: 0.728000\n",
      " Iteration: 9090 , loss: 3.505551 Accuracy: 0.788000\n",
      " Iteration: 9100 , loss: 3.478957 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 9110 , loss: 3.526544 Accuracy: 0.772000\n",
      " Iteration: 9120 , loss: 3.480819 Accuracy: 0.804000\n",
      " Iteration: 9130 , loss: 3.511979 Accuracy: 0.756000\n",
      " Iteration: 9140 , loss: 3.505914 Accuracy: 0.772000\n",
      " Iteration: 9150 , loss: 3.485670 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 9160 , loss: 3.485497 Accuracy: 0.788000\n",
      " Iteration: 9170 , loss: 3.486459 Accuracy: 0.776000\n",
      " Iteration: 9180 , loss: 3.496557 Accuracy: 0.780000\n",
      " Iteration: 9190 , loss: 3.528522 Accuracy: 0.776000\n",
      " Iteration: 9200 , loss: 3.506557 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 9210 , loss: 3.482948 Accuracy: 0.812000\n",
      " Iteration: 9220 , loss: 3.505440 Accuracy: 0.804000\n",
      " Iteration: 9230 , loss: 3.523969 Accuracy: 0.736000\n",
      " Iteration: 9240 , loss: 3.533846 Accuracy: 0.748000\n",
      " Iteration: 9250 , loss: 3.513010 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 9260 , loss: 3.485981 Accuracy: 0.796000\n",
      " Iteration: 9270 , loss: 3.486007 Accuracy: 0.808000\n",
      " Iteration: 9280 , loss: 3.501251 Accuracy: 0.800000\n",
      " Iteration: 9290 , loss: 3.505995 Accuracy: 0.752000\n",
      " Iteration: 9300 , loss: 3.550609 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 9310 , loss: 3.494926 Accuracy: 0.788000\n",
      " Iteration: 9320 , loss: 3.489105 Accuracy: 0.792000\n",
      " Iteration: 9330 , loss: 3.549398 Accuracy: 0.740000\n",
      " Iteration: 9340 , loss: 3.533248 Accuracy: 0.748000\n",
      " Iteration: 9350 , loss: 3.519532 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 9360 , loss: 3.496528 Accuracy: 0.776000\n",
      " Iteration: 9370 , loss: 3.486070 Accuracy: 0.784000\n",
      " Iteration: 9380 , loss: 3.521462 Accuracy: 0.744000\n",
      " Iteration: 9390 , loss: 3.468240 Accuracy: 0.832000\n",
      " Iteration: 9400 , loss: 3.501752 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 9410 , loss: 3.478739 Accuracy: 0.788000\n",
      " Iteration: 9420 , loss: 3.483357 Accuracy: 0.784000\n",
      " Iteration: 9430 , loss: 3.503785 Accuracy: 0.776000\n",
      " Iteration: 9440 , loss: 3.489933 Accuracy: 0.764000\n",
      " Iteration: 9450 , loss: 3.476152 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 9460 , loss: 3.525271 Accuracy: 0.768000\n",
      " Iteration: 9470 , loss: 3.483699 Accuracy: 0.796000\n",
      " Iteration: 9480 , loss: 3.514413 Accuracy: 0.772000\n",
      " Iteration: 9490 , loss: 3.502153 Accuracy: 0.788000\n",
      " Iteration: 9500 , loss: 3.518544 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 9510 , loss: 3.522848 Accuracy: 0.740000\n",
      " Iteration: 9520 , loss: 3.517328 Accuracy: 0.748000\n",
      " Iteration: 9530 , loss: 3.521842 Accuracy: 0.768000\n",
      " Iteration: 9540 , loss: 3.488106 Accuracy: 0.784000\n",
      " Iteration: 9550 , loss: 3.474731 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 9560 , loss: 3.492747 Accuracy: 0.752000\n",
      " Iteration: 9570 , loss: 3.485080 Accuracy: 0.804000\n",
      " Iteration: 9580 , loss: 3.491174 Accuracy: 0.800000\n",
      " Iteration: 9590 , loss: 3.495189 Accuracy: 0.788000\n",
      " Iteration: 9600 , loss: 3.511111 Accuracy: 0.736000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 9610 , loss: 3.469168 Accuracy: 0.796000\n",
      " Iteration: 9620 , loss: 3.508994 Accuracy: 0.780000\n",
      " Iteration: 9630 , loss: 3.488566 Accuracy: 0.756000\n",
      " Iteration: 9640 , loss: 3.496065 Accuracy: 0.764000\n",
      " Iteration: 9650 , loss: 3.512014 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 9660 , loss: 3.486744 Accuracy: 0.780000\n",
      " Iteration: 9670 , loss: 3.513861 Accuracy: 0.772000\n",
      " Iteration: 9680 , loss: 3.508435 Accuracy: 0.760000\n",
      " Iteration: 9690 , loss: 3.509764 Accuracy: 0.748000\n",
      " Iteration: 9700 , loss: 3.527130 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 9710 , loss: 3.530455 Accuracy: 0.772000\n",
      " Iteration: 9720 , loss: 3.496225 Accuracy: 0.796000\n",
      " Iteration: 9730 , loss: 3.495806 Accuracy: 0.752000\n",
      " Iteration: 9740 , loss: 3.530269 Accuracy: 0.768000\n",
      " Iteration: 9750 , loss: 3.477998 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 9760 , loss: 3.509605 Accuracy: 0.764000\n",
      " Iteration: 9770 , loss: 3.484259 Accuracy: 0.796000\n",
      " Iteration: 9780 , loss: 3.470773 Accuracy: 0.792000\n",
      " Iteration: 9790 , loss: 3.469965 Accuracy: 0.788000\n",
      " Iteration: 9800 , loss: 3.531109 Accuracy: 0.748000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 9810 , loss: 3.475557 Accuracy: 0.788000\n",
      " Iteration: 9820 , loss: 3.510333 Accuracy: 0.764000\n",
      " Iteration: 9830 , loss: 3.515602 Accuracy: 0.772000\n",
      " Iteration: 9840 , loss: 3.524791 Accuracy: 0.740000\n",
      " Iteration: 9850 , loss: 3.503335 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 9860 , loss: 3.494385 Accuracy: 0.792000\n",
      " Iteration: 9870 , loss: 3.533139 Accuracy: 0.740000\n",
      " Iteration: 9880 , loss: 3.481511 Accuracy: 0.804000\n",
      " Iteration: 9890 , loss: 3.489234 Accuracy: 0.760000\n",
      " Iteration: 9900 , loss: 3.488881 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 9910 , loss: 3.500129 Accuracy: 0.768000\n",
      " Iteration: 9920 , loss: 3.532351 Accuracy: 0.744000\n",
      " Iteration: 9930 , loss: 3.487655 Accuracy: 0.780000\n",
      " Iteration: 9940 , loss: 3.491293 Accuracy: 0.788000\n",
      " Iteration: 9950 , loss: 3.541500 Accuracy: 0.704000\n",
      "The postprocessing average accuracy is: 0.8666666666666667 and the number of correct results is: 208\n",
      " Iteration: 9960 , loss: 3.528112 Accuracy: 0.728000\n",
      " Iteration: 9970 , loss: 3.529491 Accuracy: 0.748000\n",
      " Iteration: 9980 , loss: 3.467486 Accuracy: 0.820000\n",
      " Iteration: 9990 , loss: 3.527322 Accuracy: 0.744000\n",
      " Iteration: 10000 , loss: 3.486347 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 10010 , loss: 3.481763 Accuracy: 0.812000\n",
      " Iteration: 10020 , loss: 3.491900 Accuracy: 0.768000\n",
      " Iteration: 10030 , loss: 3.527970 Accuracy: 0.752000\n",
      " Iteration: 10040 , loss: 3.456577 Accuracy: 0.820000\n",
      " Iteration: 10050 , loss: 3.479358 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 10060 , loss: 3.484054 Accuracy: 0.800000\n",
      " Iteration: 10070 , loss: 3.508791 Accuracy: 0.752000\n",
      " Iteration: 10080 , loss: 3.498410 Accuracy: 0.792000\n",
      " Iteration: 10090 , loss: 3.519375 Accuracy: 0.772000\n",
      " Iteration: 10100 , loss: 3.487579 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 10110 , loss: 3.523125 Accuracy: 0.756000\n",
      " Iteration: 10120 , loss: 3.524080 Accuracy: 0.756000\n",
      " Iteration: 10130 , loss: 3.532782 Accuracy: 0.740000\n",
      " Iteration: 10140 , loss: 3.477505 Accuracy: 0.800000\n",
      " Iteration: 10150 , loss: 3.498871 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 10160 , loss: 3.451387 Accuracy: 0.840000\n",
      " Iteration: 10170 , loss: 3.490109 Accuracy: 0.788000\n",
      " Iteration: 10180 , loss: 3.528246 Accuracy: 0.740000\n",
      " Iteration: 10190 , loss: 3.501268 Accuracy: 0.776000\n",
      " Iteration: 10200 , loss: 3.489672 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9208333333333333 and the number of correct results is: 221\n",
      " Iteration: 10210 , loss: 3.497255 Accuracy: 0.788000\n",
      " Iteration: 10220 , loss: 3.459508 Accuracy: 0.820000\n",
      " Iteration: 10230 , loss: 3.494515 Accuracy: 0.752000\n",
      " Iteration: 10240 , loss: 3.504140 Accuracy: 0.780000\n",
      " Iteration: 10250 , loss: 3.484657 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 10260 , loss: 3.476842 Accuracy: 0.792000\n",
      " Iteration: 10270 , loss: 3.495267 Accuracy: 0.772000\n",
      " Iteration: 10280 , loss: 3.469525 Accuracy: 0.808000\n",
      " Iteration: 10290 , loss: 3.493662 Accuracy: 0.768000\n",
      " Iteration: 10300 , loss: 3.496813 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 10310 , loss: 3.469301 Accuracy: 0.804000\n",
      " Iteration: 10320 , loss: 3.477437 Accuracy: 0.784000\n",
      " Iteration: 10330 , loss: 3.485734 Accuracy: 0.816000\n",
      " Iteration: 10340 , loss: 3.526695 Accuracy: 0.776000\n",
      " Iteration: 10350 , loss: 3.483134 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 10360 , loss: 3.447755 Accuracy: 0.820000\n",
      " Iteration: 10370 , loss: 3.554926 Accuracy: 0.708000\n",
      " Iteration: 10380 , loss: 3.513202 Accuracy: 0.748000\n",
      " Iteration: 10390 , loss: 3.501510 Accuracy: 0.780000\n",
      " Iteration: 10400 , loss: 3.502850 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 10410 , loss: 3.511431 Accuracy: 0.740000\n",
      " Iteration: 10420 , loss: 3.506559 Accuracy: 0.764000\n",
      " Iteration: 10430 , loss: 3.475828 Accuracy: 0.792000\n",
      " Iteration: 10440 , loss: 3.511346 Accuracy: 0.768000\n",
      " Iteration: 10450 , loss: 3.480019 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 10460 , loss: 3.474782 Accuracy: 0.820000\n",
      " Iteration: 10470 , loss: 3.494808 Accuracy: 0.784000\n",
      " Iteration: 10480 , loss: 3.561866 Accuracy: 0.712000\n",
      " Iteration: 10490 , loss: 3.523890 Accuracy: 0.712000\n",
      " Iteration: 10500 , loss: 3.522277 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 10510 , loss: 3.482915 Accuracy: 0.800000\n",
      " Iteration: 10520 , loss: 3.509115 Accuracy: 0.756000\n",
      " Iteration: 10530 , loss: 3.525929 Accuracy: 0.752000\n",
      " Iteration: 10540 , loss: 3.483822 Accuracy: 0.808000\n",
      " Iteration: 10550 , loss: 3.528519 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 10560 , loss: 3.517235 Accuracy: 0.768000\n",
      " Iteration: 10570 , loss: 3.476226 Accuracy: 0.788000\n",
      " Iteration: 10580 , loss: 3.516000 Accuracy: 0.740000\n",
      " Iteration: 10590 , loss: 3.475528 Accuracy: 0.812000\n",
      " Iteration: 10600 , loss: 3.493214 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 10610 , loss: 3.510031 Accuracy: 0.776000\n",
      " Iteration: 10620 , loss: 3.473298 Accuracy: 0.788000\n",
      " Iteration: 10630 , loss: 3.510870 Accuracy: 0.788000\n",
      " Iteration: 10640 , loss: 3.471779 Accuracy: 0.808000\n",
      " Iteration: 10650 , loss: 3.520649 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 10660 , loss: 3.492072 Accuracy: 0.792000\n",
      " Iteration: 10670 , loss: 3.487781 Accuracy: 0.800000\n",
      " Iteration: 10680 , loss: 3.474322 Accuracy: 0.788000\n",
      " Iteration: 10690 , loss: 3.519597 Accuracy: 0.748000\n",
      " Iteration: 10700 , loss: 3.469222 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 10710 , loss: 3.489960 Accuracy: 0.800000\n",
      " Iteration: 10720 , loss: 3.510786 Accuracy: 0.744000\n",
      " Iteration: 10730 , loss: 3.507614 Accuracy: 0.756000\n",
      " Iteration: 10740 , loss: 3.487309 Accuracy: 0.788000\n",
      " Iteration: 10750 , loss: 3.500907 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.9125 and the number of correct results is: 219\n",
      " Iteration: 10760 , loss: 3.474661 Accuracy: 0.804000\n",
      " Iteration: 10770 , loss: 3.529982 Accuracy: 0.740000\n",
      " Iteration: 10780 , loss: 3.463146 Accuracy: 0.820000\n",
      " Iteration: 10790 , loss: 3.505599 Accuracy: 0.760000\n",
      " Iteration: 10800 , loss: 3.479101 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 10810 , loss: 3.503962 Accuracy: 0.752000\n",
      " Iteration: 10820 , loss: 3.454885 Accuracy: 0.796000\n",
      " Iteration: 10830 , loss: 3.473184 Accuracy: 0.804000\n",
      " Iteration: 10840 , loss: 3.473727 Accuracy: 0.812000\n",
      " Iteration: 10850 , loss: 3.505103 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 10860 , loss: 3.466434 Accuracy: 0.780000\n",
      " Iteration: 10870 , loss: 3.468326 Accuracy: 0.796000\n",
      " Iteration: 10880 , loss: 3.494839 Accuracy: 0.776000\n",
      " Iteration: 10890 , loss: 3.493067 Accuracy: 0.780000\n",
      " Iteration: 10900 , loss: 3.498743 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 10910 , loss: 3.499539 Accuracy: 0.776000\n",
      " Iteration: 10920 , loss: 3.512652 Accuracy: 0.772000\n",
      " Iteration: 10930 , loss: 3.463298 Accuracy: 0.812000\n",
      " Iteration: 10940 , loss: 3.474787 Accuracy: 0.784000\n",
      " Iteration: 10950 , loss: 3.493298 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 10960 , loss: 3.508008 Accuracy: 0.780000\n",
      " Iteration: 10970 , loss: 3.504417 Accuracy: 0.772000\n",
      " Iteration: 10980 , loss: 3.495930 Accuracy: 0.752000\n",
      " Iteration: 10990 , loss: 3.511565 Accuracy: 0.776000\n",
      " Iteration: 11000 , loss: 3.521171 Accuracy: 0.744000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 11010 , loss: 3.461371 Accuracy: 0.792000\n",
      " Iteration: 11020 , loss: 3.453784 Accuracy: 0.804000\n",
      " Iteration: 11030 , loss: 3.470979 Accuracy: 0.804000\n",
      " Iteration: 11040 , loss: 3.459162 Accuracy: 0.804000\n",
      " Iteration: 11050 , loss: 3.497544 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 11060 , loss: 3.482724 Accuracy: 0.780000\n",
      " Iteration: 11070 , loss: 3.508360 Accuracy: 0.752000\n",
      " Iteration: 11080 , loss: 3.484203 Accuracy: 0.796000\n",
      " Iteration: 11090 , loss: 3.483438 Accuracy: 0.800000\n",
      " Iteration: 11100 , loss: 3.499232 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 11110 , loss: 3.486627 Accuracy: 0.772000\n",
      " Iteration: 11120 , loss: 3.470705 Accuracy: 0.800000\n",
      " Iteration: 11130 , loss: 3.500395 Accuracy: 0.752000\n",
      " Iteration: 11140 , loss: 3.505078 Accuracy: 0.728000\n",
      " Iteration: 11150 , loss: 3.502233 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8708333333333333 and the number of correct results is: 209\n",
      " Iteration: 11160 , loss: 3.505829 Accuracy: 0.776000\n",
      " Iteration: 11170 , loss: 3.497264 Accuracy: 0.768000\n",
      " Iteration: 11180 , loss: 3.503245 Accuracy: 0.764000\n",
      " Iteration: 11190 , loss: 3.487716 Accuracy: 0.784000\n",
      " Iteration: 11200 , loss: 3.481273 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9166666666666666 and the number of correct results is: 220\n",
      " Iteration: 11210 , loss: 3.482293 Accuracy: 0.812000\n",
      " Iteration: 11220 , loss: 3.494791 Accuracy: 0.784000\n",
      " Iteration: 11230 , loss: 3.450129 Accuracy: 0.804000\n",
      " Iteration: 11240 , loss: 3.461827 Accuracy: 0.808000\n",
      " Iteration: 11250 , loss: 3.477575 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 11260 , loss: 3.496518 Accuracy: 0.812000\n",
      " Iteration: 11270 , loss: 3.478620 Accuracy: 0.772000\n",
      " Iteration: 11280 , loss: 3.501922 Accuracy: 0.780000\n",
      " Iteration: 11290 , loss: 3.492328 Accuracy: 0.768000\n",
      " Iteration: 11300 , loss: 3.480422 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 11310 , loss: 3.474939 Accuracy: 0.792000\n",
      " Iteration: 11320 , loss: 3.483306 Accuracy: 0.788000\n",
      " Iteration: 11330 , loss: 3.505254 Accuracy: 0.784000\n",
      " Iteration: 11340 , loss: 3.481083 Accuracy: 0.800000\n",
      " Iteration: 11350 , loss: 3.496413 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 11360 , loss: 3.479376 Accuracy: 0.812000\n",
      " Iteration: 11370 , loss: 3.445112 Accuracy: 0.828000\n",
      " Iteration: 11380 , loss: 3.449021 Accuracy: 0.832000\n",
      " Iteration: 11390 , loss: 3.505176 Accuracy: 0.764000\n",
      " Iteration: 11400 , loss: 3.506541 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 11410 , loss: 3.473501 Accuracy: 0.808000\n",
      " Iteration: 11420 , loss: 3.483185 Accuracy: 0.816000\n",
      " Iteration: 11430 , loss: 3.492643 Accuracy: 0.756000\n",
      " Iteration: 11440 , loss: 3.487607 Accuracy: 0.792000\n",
      " Iteration: 11450 , loss: 3.507339 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 11460 , loss: 3.497205 Accuracy: 0.764000\n",
      " Iteration: 11470 , loss: 3.436655 Accuracy: 0.836000\n",
      " Iteration: 11480 , loss: 3.505481 Accuracy: 0.780000\n",
      " Iteration: 11490 , loss: 3.477610 Accuracy: 0.796000\n",
      " Iteration: 11500 , loss: 3.511647 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 11510 , loss: 3.472627 Accuracy: 0.772000\n",
      " Iteration: 11520 , loss: 3.499913 Accuracy: 0.784000\n",
      " Iteration: 11530 , loss: 3.493684 Accuracy: 0.788000\n",
      " Iteration: 11540 , loss: 3.480717 Accuracy: 0.788000\n",
      " Iteration: 11550 , loss: 3.486211 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 11560 , loss: 3.498482 Accuracy: 0.780000\n",
      " Iteration: 11570 , loss: 3.479519 Accuracy: 0.792000\n",
      " Iteration: 11580 , loss: 3.513408 Accuracy: 0.764000\n",
      " Iteration: 11590 , loss: 3.521968 Accuracy: 0.760000\n",
      " Iteration: 11600 , loss: 3.471911 Accuracy: 0.844000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 11610 , loss: 3.475652 Accuracy: 0.784000\n",
      " Iteration: 11620 , loss: 3.515112 Accuracy: 0.736000\n",
      " Iteration: 11630 , loss: 3.492235 Accuracy: 0.784000\n",
      " Iteration: 11640 , loss: 3.470666 Accuracy: 0.792000\n",
      " Iteration: 11650 , loss: 3.463780 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 11660 , loss: 3.477265 Accuracy: 0.800000\n",
      " Iteration: 11670 , loss: 3.473133 Accuracy: 0.784000\n",
      " Iteration: 11680 , loss: 3.463408 Accuracy: 0.828000\n",
      " Iteration: 11690 , loss: 3.517837 Accuracy: 0.768000\n",
      " Iteration: 11700 , loss: 3.473040 Accuracy: 0.820000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 11710 , loss: 3.478330 Accuracy: 0.788000\n",
      " Iteration: 11720 , loss: 3.440902 Accuracy: 0.856000\n",
      " Iteration: 11730 , loss: 3.468408 Accuracy: 0.788000\n",
      " Iteration: 11740 , loss: 3.522220 Accuracy: 0.744000\n",
      " Iteration: 11750 , loss: 3.501131 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9166666666666666 and the number of correct results is: 220\n",
      " Iteration: 11760 , loss: 3.484516 Accuracy: 0.832000\n",
      " Iteration: 11770 , loss: 3.475609 Accuracy: 0.804000\n",
      " Iteration: 11780 , loss: 3.506531 Accuracy: 0.748000\n",
      " Iteration: 11790 , loss: 3.485734 Accuracy: 0.788000\n",
      " Iteration: 11800 , loss: 3.474719 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 11810 , loss: 3.502095 Accuracy: 0.768000\n",
      " Iteration: 11820 , loss: 3.475234 Accuracy: 0.804000\n",
      " Iteration: 11830 , loss: 3.456106 Accuracy: 0.804000\n",
      " Iteration: 11840 , loss: 3.484731 Accuracy: 0.776000\n",
      " Iteration: 11850 , loss: 3.496006 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 11860 , loss: 3.507180 Accuracy: 0.768000\n",
      " Iteration: 11870 , loss: 3.481271 Accuracy: 0.804000\n",
      " Iteration: 11880 , loss: 3.484912 Accuracy: 0.792000\n",
      " Iteration: 11890 , loss: 3.458943 Accuracy: 0.796000\n",
      " Iteration: 11900 , loss: 3.514378 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 11910 , loss: 3.484810 Accuracy: 0.772000\n",
      " Iteration: 11920 , loss: 3.484385 Accuracy: 0.820000\n",
      " Iteration: 11930 , loss: 3.491805 Accuracy: 0.788000\n",
      " Iteration: 11940 , loss: 3.486361 Accuracy: 0.788000\n",
      " Iteration: 11950 , loss: 3.504389 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 11960 , loss: 3.492673 Accuracy: 0.780000\n",
      " Iteration: 11970 , loss: 3.482500 Accuracy: 0.780000\n",
      " Iteration: 11980 , loss: 3.503612 Accuracy: 0.760000\n",
      " Iteration: 11990 , loss: 3.482184 Accuracy: 0.768000\n",
      " Iteration: 12000 , loss: 3.501590 Accuracy: 0.764000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 12010 , loss: 3.467648 Accuracy: 0.804000\n",
      " Iteration: 12020 , loss: 3.505734 Accuracy: 0.760000\n",
      " Iteration: 12030 , loss: 3.479411 Accuracy: 0.772000\n",
      " Iteration: 12040 , loss: 3.491762 Accuracy: 0.752000\n",
      " Iteration: 12050 , loss: 3.488028 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8833333333333333 and the number of correct results is: 212\n",
      " Iteration: 12060 , loss: 3.495198 Accuracy: 0.776000\n",
      " Iteration: 12070 , loss: 3.495727 Accuracy: 0.752000\n",
      " Iteration: 12080 , loss: 3.480917 Accuracy: 0.764000\n",
      " Iteration: 12090 , loss: 3.491823 Accuracy: 0.760000\n",
      " Iteration: 12100 , loss: 3.470794 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 12110 , loss: 3.470572 Accuracy: 0.788000\n",
      " Iteration: 12120 , loss: 3.484183 Accuracy: 0.772000\n",
      " Iteration: 12130 , loss: 3.509929 Accuracy: 0.748000\n",
      " Iteration: 12140 , loss: 3.467931 Accuracy: 0.792000\n",
      " Iteration: 12150 , loss: 3.476022 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 12160 , loss: 3.509757 Accuracy: 0.764000\n",
      " Iteration: 12170 , loss: 3.470748 Accuracy: 0.784000\n",
      " Iteration: 12180 , loss: 3.530020 Accuracy: 0.728000\n",
      " Iteration: 12190 , loss: 3.512565 Accuracy: 0.768000\n",
      " Iteration: 12200 , loss: 3.482561 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 12210 , loss: 3.537716 Accuracy: 0.736000\n",
      " Iteration: 12220 , loss: 3.472933 Accuracy: 0.816000\n",
      " Iteration: 12230 , loss: 3.465162 Accuracy: 0.816000\n",
      " Iteration: 12240 , loss: 3.495851 Accuracy: 0.784000\n",
      " Iteration: 12250 , loss: 3.462877 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 12260 , loss: 3.481684 Accuracy: 0.780000\n",
      " Iteration: 12270 , loss: 3.485175 Accuracy: 0.804000\n",
      " Iteration: 12280 , loss: 3.429410 Accuracy: 0.824000\n",
      " Iteration: 12290 , loss: 3.466969 Accuracy: 0.828000\n",
      " Iteration: 12300 , loss: 3.506059 Accuracy: 0.788000\n",
      "The postprocessing average accuracy is: 0.925 and the number of correct results is: 222\n",
      " Iteration: 12310 , loss: 3.483727 Accuracy: 0.752000\n",
      " Iteration: 12320 , loss: 3.446590 Accuracy: 0.824000\n",
      " Iteration: 12330 , loss: 3.492716 Accuracy: 0.768000\n",
      " Iteration: 12340 , loss: 3.488017 Accuracy: 0.752000\n",
      " Iteration: 12350 , loss: 3.465843 Accuracy: 0.792000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 12360 , loss: 3.467354 Accuracy: 0.788000\n",
      " Iteration: 12370 , loss: 3.472722 Accuracy: 0.792000\n",
      " Iteration: 12380 , loss: 3.467306 Accuracy: 0.792000\n",
      " Iteration: 12390 , loss: 3.475704 Accuracy: 0.784000\n",
      " Iteration: 12400 , loss: 3.469218 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 12410 , loss: 3.476518 Accuracy: 0.768000\n",
      " Iteration: 12420 , loss: 3.499231 Accuracy: 0.776000\n",
      " Iteration: 12430 , loss: 3.510822 Accuracy: 0.760000\n",
      " Iteration: 12440 , loss: 3.458578 Accuracy: 0.820000\n",
      " Iteration: 12450 , loss: 3.444449 Accuracy: 0.840000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 12460 , loss: 3.492013 Accuracy: 0.740000\n",
      " Iteration: 12470 , loss: 3.494102 Accuracy: 0.752000\n",
      " Iteration: 12480 , loss: 3.464364 Accuracy: 0.792000\n",
      " Iteration: 12490 , loss: 3.509297 Accuracy: 0.800000\n",
      " Iteration: 12500 , loss: 3.463168 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.9125 and the number of correct results is: 219\n",
      " Iteration: 12510 , loss: 3.469658 Accuracy: 0.792000\n",
      " Iteration: 12520 , loss: 3.511384 Accuracy: 0.756000\n",
      " Iteration: 12530 , loss: 3.476936 Accuracy: 0.764000\n",
      " Iteration: 12540 , loss: 3.437261 Accuracy: 0.804000\n",
      " Iteration: 12550 , loss: 3.469136 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 12560 , loss: 3.509603 Accuracy: 0.748000\n",
      " Iteration: 12570 , loss: 3.478864 Accuracy: 0.784000\n",
      " Iteration: 12580 , loss: 3.504276 Accuracy: 0.764000\n",
      " Iteration: 12590 , loss: 3.492069 Accuracy: 0.788000\n",
      " Iteration: 12600 , loss: 3.506205 Accuracy: 0.756000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 12610 , loss: 3.505640 Accuracy: 0.752000\n",
      " Iteration: 12620 , loss: 3.493624 Accuracy: 0.768000\n",
      " Iteration: 12630 , loss: 3.491383 Accuracy: 0.772000\n",
      " Iteration: 12640 , loss: 3.497578 Accuracy: 0.792000\n",
      " Iteration: 12650 , loss: 3.464859 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 12660 , loss: 3.492591 Accuracy: 0.780000\n",
      " Iteration: 12670 , loss: 3.486383 Accuracy: 0.780000\n",
      " Iteration: 12680 , loss: 3.464630 Accuracy: 0.792000\n",
      " Iteration: 12690 , loss: 3.456275 Accuracy: 0.824000\n",
      " Iteration: 12700 , loss: 3.477585 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 12710 , loss: 3.453850 Accuracy: 0.836000\n",
      " Iteration: 12720 , loss: 3.469878 Accuracy: 0.792000\n",
      " Iteration: 12730 , loss: 3.450360 Accuracy: 0.816000\n",
      " Iteration: 12740 , loss: 3.502389 Accuracy: 0.752000\n",
      " Iteration: 12750 , loss: 3.446467 Accuracy: 0.816000\n",
      "The postprocessing average accuracy is: 0.8958333333333334 and the number of correct results is: 215\n",
      " Iteration: 12760 , loss: 3.468971 Accuracy: 0.816000\n",
      " Iteration: 12770 , loss: 3.508744 Accuracy: 0.772000\n",
      " Iteration: 12780 , loss: 3.465139 Accuracy: 0.772000\n",
      " Iteration: 12790 , loss: 3.489518 Accuracy: 0.764000\n",
      " Iteration: 12800 , loss: 3.448050 Accuracy: 0.828000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 12810 , loss: 3.470105 Accuracy: 0.800000\n",
      " Iteration: 12820 , loss: 3.431567 Accuracy: 0.832000\n",
      " Iteration: 12830 , loss: 3.470741 Accuracy: 0.800000\n",
      " Iteration: 12840 , loss: 3.436786 Accuracy: 0.860000\n",
      " Iteration: 12850 , loss: 3.468251 Accuracy: 0.784000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 12860 , loss: 3.449744 Accuracy: 0.820000\n",
      " Iteration: 12870 , loss: 3.469463 Accuracy: 0.832000\n",
      " Iteration: 12880 , loss: 3.483901 Accuracy: 0.800000\n",
      " Iteration: 12890 , loss: 3.477800 Accuracy: 0.768000\n",
      " Iteration: 12900 , loss: 3.467522 Accuracy: 0.836000\n",
      "The postprocessing average accuracy is: 0.8791666666666667 and the number of correct results is: 211\n",
      " Iteration: 12910 , loss: 3.477633 Accuracy: 0.824000\n",
      " Iteration: 12920 , loss: 3.479684 Accuracy: 0.788000\n",
      " Iteration: 12930 , loss: 3.528225 Accuracy: 0.752000\n",
      " Iteration: 12940 , loss: 3.474698 Accuracy: 0.780000\n",
      " Iteration: 12950 , loss: 3.449882 Accuracy: 0.804000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 12960 , loss: 3.476413 Accuracy: 0.780000\n",
      " Iteration: 12970 , loss: 3.472230 Accuracy: 0.784000\n",
      " Iteration: 12980 , loss: 3.512721 Accuracy: 0.728000\n",
      " Iteration: 12990 , loss: 3.457237 Accuracy: 0.832000\n",
      " Iteration: 13000 , loss: 3.453202 Accuracy: 0.812000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 13010 , loss: 3.433955 Accuracy: 0.820000\n",
      " Iteration: 13020 , loss: 3.460346 Accuracy: 0.808000\n",
      " Iteration: 13030 , loss: 3.468561 Accuracy: 0.808000\n",
      " Iteration: 13040 , loss: 3.492783 Accuracy: 0.780000\n",
      " Iteration: 13050 , loss: 3.449624 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.9125 and the number of correct results is: 219\n",
      " Iteration: 13060 , loss: 3.471820 Accuracy: 0.800000\n",
      " Iteration: 13070 , loss: 3.447854 Accuracy: 0.840000\n",
      " Iteration: 13080 , loss: 3.501292 Accuracy: 0.756000\n",
      " Iteration: 13090 , loss: 3.465965 Accuracy: 0.816000\n",
      " Iteration: 13100 , loss: 3.488349 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 13110 , loss: 3.475576 Accuracy: 0.816000\n",
      " Iteration: 13120 , loss: 3.489356 Accuracy: 0.776000\n",
      " Iteration: 13130 , loss: 3.480432 Accuracy: 0.796000\n",
      " Iteration: 13140 , loss: 3.468503 Accuracy: 0.800000\n",
      " Iteration: 13150 , loss: 3.489464 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9041666666666667 and the number of correct results is: 217\n",
      " Iteration: 13160 , loss: 3.465010 Accuracy: 0.812000\n",
      " Iteration: 13170 , loss: 3.481017 Accuracy: 0.784000\n",
      " Iteration: 13180 , loss: 3.469476 Accuracy: 0.808000\n",
      " Iteration: 13190 , loss: 3.493730 Accuracy: 0.784000\n",
      " Iteration: 13200 , loss: 3.475111 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 13210 , loss: 3.462525 Accuracy: 0.800000\n",
      " Iteration: 13220 , loss: 3.462677 Accuracy: 0.800000\n",
      " Iteration: 13230 , loss: 3.468319 Accuracy: 0.764000\n",
      " Iteration: 13240 , loss: 3.485092 Accuracy: 0.788000\n",
      " Iteration: 13250 , loss: 3.457731 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 13260 , loss: 3.454288 Accuracy: 0.828000\n",
      " Iteration: 13270 , loss: 3.484979 Accuracy: 0.756000\n",
      " Iteration: 13280 , loss: 3.471568 Accuracy: 0.776000\n",
      " Iteration: 13290 , loss: 3.472126 Accuracy: 0.808000\n",
      " Iteration: 13300 , loss: 3.488837 Accuracy: 0.776000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 13310 , loss: 3.436560 Accuracy: 0.816000\n",
      " Iteration: 13320 , loss: 3.477843 Accuracy: 0.784000\n",
      " Iteration: 13330 , loss: 3.470549 Accuracy: 0.804000\n",
      " Iteration: 13340 , loss: 3.446395 Accuracy: 0.816000\n",
      " Iteration: 13350 , loss: 3.508677 Accuracy: 0.768000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 13360 , loss: 3.463469 Accuracy: 0.800000\n",
      " Iteration: 13370 , loss: 3.465458 Accuracy: 0.812000\n",
      " Iteration: 13380 , loss: 3.436693 Accuracy: 0.820000\n",
      " Iteration: 13390 , loss: 3.465708 Accuracy: 0.792000\n",
      " Iteration: 13400 , loss: 3.492320 Accuracy: 0.752000\n",
      "The postprocessing average accuracy is: 0.9208333333333333 and the number of correct results is: 221\n",
      " Iteration: 13410 , loss: 3.492897 Accuracy: 0.772000\n",
      " Iteration: 13420 , loss: 3.478245 Accuracy: 0.780000\n",
      " Iteration: 13430 , loss: 3.455956 Accuracy: 0.824000\n",
      " Iteration: 13440 , loss: 3.468736 Accuracy: 0.800000\n",
      " Iteration: 13450 , loss: 3.455570 Accuracy: 0.808000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      " Iteration: 13460 , loss: 3.508538 Accuracy: 0.760000\n",
      " Iteration: 13470 , loss: 3.470901 Accuracy: 0.816000\n",
      " Iteration: 13480 , loss: 3.445394 Accuracy: 0.820000\n",
      " Iteration: 13490 , loss: 3.474669 Accuracy: 0.780000\n",
      " Iteration: 13500 , loss: 3.489016 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.9 and the number of correct results is: 216\n",
      " Iteration: 13510 , loss: 3.471301 Accuracy: 0.792000\n",
      " Iteration: 13520 , loss: 3.496539 Accuracy: 0.812000\n",
      " Iteration: 13530 , loss: 3.477040 Accuracy: 0.792000\n",
      " Iteration: 13540 , loss: 3.507513 Accuracy: 0.744000\n",
      " Iteration: 13550 , loss: 3.424774 Accuracy: 0.860000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 13560 , loss: 3.466353 Accuracy: 0.804000\n",
      " Iteration: 13570 , loss: 3.470765 Accuracy: 0.804000\n",
      " Iteration: 13580 , loss: 3.481090 Accuracy: 0.752000\n",
      " Iteration: 13590 , loss: 3.486494 Accuracy: 0.768000\n",
      " Iteration: 13600 , loss: 3.475898 Accuracy: 0.780000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 13610 , loss: 3.514807 Accuracy: 0.712000\n",
      " Iteration: 13620 , loss: 3.453311 Accuracy: 0.828000\n",
      " Iteration: 13630 , loss: 3.496286 Accuracy: 0.760000\n",
      " Iteration: 13640 , loss: 3.482057 Accuracy: 0.792000\n",
      " Iteration: 13650 , loss: 3.492120 Accuracy: 0.772000\n",
      "The postprocessing average accuracy is: 0.8875 and the number of correct results is: 213\n",
      " Iteration: 13660 , loss: 3.493695 Accuracy: 0.748000\n",
      " Iteration: 13670 , loss: 3.466307 Accuracy: 0.776000\n",
      " Iteration: 13680 , loss: 3.486620 Accuracy: 0.772000\n",
      " Iteration: 13690 , loss: 3.487608 Accuracy: 0.772000\n",
      " Iteration: 13700 , loss: 3.473697 Accuracy: 0.760000\n",
      "The postprocessing average accuracy is: 0.9125 and the number of correct results is: 219\n",
      " Iteration: 13710 , loss: 3.497816 Accuracy: 0.764000\n",
      " Iteration: 13720 , loss: 3.426589 Accuracy: 0.856000\n",
      " Iteration: 13730 , loss: 3.441215 Accuracy: 0.808000\n",
      " Iteration: 13740 , loss: 3.493700 Accuracy: 0.768000\n",
      " Iteration: 13750 , loss: 3.463126 Accuracy: 0.820000\n",
      "The postprocessing average accuracy is: 0.9083333333333333 and the number of correct results is: 218\n",
      " Iteration: 13760 , loss: 3.491849 Accuracy: 0.752000\n",
      " Iteration: 13770 , loss: 3.461612 Accuracy: 0.824000\n",
      " Iteration: 13780 , loss: 3.472083 Accuracy: 0.788000\n",
      " Iteration: 13790 , loss: 3.463394 Accuracy: 0.808000\n",
      " Iteration: 13800 , loss: 3.469205 Accuracy: 0.796000\n",
      "The postprocessing average accuracy is: 0.875 and the number of correct results is: 210\n",
      " Iteration: 13810 , loss: 3.460618 Accuracy: 0.804000\n",
      " Iteration: 13820 , loss: 3.484403 Accuracy: 0.804000\n",
      " Iteration: 13830 , loss: 3.501625 Accuracy: 0.776000\n",
      " Iteration: 13840 , loss: 3.476521 Accuracy: 0.812000\n",
      " Iteration: 13850 , loss: 3.476576 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.9125 and the number of correct results is: 219\n",
      " Iteration: 13860 , loss: 3.454148 Accuracy: 0.804000\n",
      " Iteration: 13870 , loss: 3.492225 Accuracy: 0.756000\n",
      " Iteration: 13880 , loss: 3.420818 Accuracy: 0.844000\n",
      " Iteration: 13890 , loss: 3.451291 Accuracy: 0.824000\n",
      " Iteration: 13900 , loss: 3.476969 Accuracy: 0.800000\n",
      "The postprocessing average accuracy is: 0.8916666666666667 and the number of correct results is: 214\n",
      "\n",
      "Optimization of Split 3 Finished\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z=0\n",
    "\n",
    "#datasets_time1[0] = Start_time, #datasets_time1[1] = end_time\n",
    "datasets_time1 = np.array([[None]*5,[None]*5])\n",
    "splits_time = np.array([[None]*num_splits,[None]*num_splits])\n",
    "plot_data = np.array([[None]*num_splits,[None]*num_splits])\n",
    "\n",
    "all_max_acc = np.array([[0,0.0]]*num_splits)\n",
    "all_proc_acc = np.array([[],[]]*num_splits)\n",
    "run_his_maxac = 0\n",
    "\n",
    "while (z<5):    \n",
    "    \n",
    "    #Reads the data of each split based on the method read_data\n",
    "    (train_data, train_labels, test_data, test_labels, data_zeros) = read_data(z)\n",
    "    #Establishes the shapes of the data and labels which will be used in the neural network\n",
    "    _,shpeLabl = train_labels[0].shape\n",
    "    train_size,shpeData = train_data[0].shape\n",
    "    _,number_labels = train_labels[0].shape\n",
    "    \n",
    "    #Defines the number of iterations of the neural network\n",
    "    iterations = define_num_iterations(train_size,250)\n",
    "        \n",
    "    if(z==0):\n",
    "        print('Starting training of penn_Action \\n')\n",
    "        tb_logs_path = '/home/gomez/Documents/Thesis_doc/Test/Experiment1/penn'        \n",
    "    elif(z==1):\n",
    "        print('Starting training of Sub_Jhmdb \\n')\n",
    "        tb_logs_path = '/home/gomez/Documents/Thesis_doc/Test/Experiment1/subjhmdb'        \n",
    "    elif(z==2):\n",
    "        print('Starting training of Jhmdb \\n')\n",
    "        tb_logs_path = '/home/gomez/Documents/Thesis_doc/Test/Experiment1/jhmdb'        \n",
    "    elif(z==3):\n",
    "        print('Starting training of Florence_3d \\n')\n",
    "        tb_logs_path = '/home/gomez/Documents/Thesis_doc/Test/Experiment1/florence'        \n",
    "    elif(z==4):\n",
    "        print('Starting training of Bn_mocap \\n')\n",
    "        tb_logs_path = '/home/gomez/Documents/Thesis_doc/Test/Experiment1/bn_mocap'        \n",
    "    else:\n",
    "        print(\"this message shouldn't ever appear\")\n",
    "        break\n",
    "    \n",
    "    print('loaded data', z, 'well')\n",
    "    \n",
    "    print('shape of the data', shpeData, 'number of labels', shpeLabl, 'size of train data (',train_size,_,') \\n\\n')\n",
    "    \n",
    "    #Loading the data\n",
    "\n",
    "    datasets_time1[0][z] = datetime.datetime.utcnow()\n",
    "    \n",
    "    '''------------------------------------------------------------------------------------------------------------''' \n",
    "    '''                                    Initialization of the neural network                                    '''\n",
    "    '''------------------------------------------------------------------------------------------------------------'''\n",
    "\n",
    "    '''Placeholders: Input of the data and labels'''\n",
    "\n",
    "    #with tf.device('/gpu:0'):\n",
    "    #Modify the data according to the given shape above\n",
    "    with tf.name_scope('input'):        \n",
    "        x = tf.placeholder(tf.float32,[None,shpeData]) #[batch_size, shape_data_training_data]\n",
    "        y_ = tf.placeholder(tf.float32,[None,shpeLabl]) #[batch_size]     \n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "    '''FC1: Convolutional layer: (x*w in convolution) +b --> Reshaping to distribute in FC network'''\n",
    "\n",
    "    x_data = tf.reshape(x, [-1,shpeData,1]) #Data converted in 3d for 1d convolution (needed from TF)\n",
    "    w_conv1 = weight_variable([30,1,convNum], 'conv1', 'trunc') #Kernel size of 30 and from 1 input to convNum neurons\n",
    "    b_conv1 = bias_variable([convNum], 'conv1') # convNum biases to add to the relu operation\n",
    "\n",
    "    h_conv = tf.nn.relu(conv1d(x_data, w_conv1) + b_conv1)\n",
    "    h_conv_reshp = tf.reshape(h_conv,[-1,convNum])\n",
    "\n",
    "    print ('layer 1 operation results')\n",
    "    print('h_conv is:', h_conv)    \n",
    "    print('h_conv_ to FCN is:',h_conv_reshp)    \n",
    "\n",
    "\n",
    "    '''FC2: Fully connected layer (w*x+b)'''\n",
    "\n",
    "    #with tf.device('/gpu:0'):\n",
    "    W_fc1 = weight_variable([convNum,FulCon1Num], 'fc1','trunc') #weights converted from the dimensions\n",
    "    b_fc1 = bias_variable([FulCon1Num], 'fc1')\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv_reshp,W_fc1)+b_fc1)    \n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob) # Dropout trick \n",
    "\n",
    "    print('layer 2 operation results')\n",
    "    print('h_fc1 is:', h_fc1)\n",
    "    print('h_fc1_drop is:', h_fc1_drop)\n",
    "\n",
    "    '''FC3: Fully connected layer (w*x+b) + Dropout layer'''\n",
    "\n",
    "    #with tf.device('/gpu:0'):\n",
    "    W_fc2 = weight_variable([FulCon1Num,FulCon2Num], 'fc2', 'trunc') \n",
    "    b_fc2 = bias_variable([FulCon2Num], 'fc2') #Bias values going to the neurons\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop,W_fc2)+b_fc2) #Relu #2 -> Check if this was right -> Should be (before the h_pool2 was)\n",
    "    h_fc2_drop = tf.nn.dropout(h_fc2,keep_prob) # Dropout trick \n",
    "\n",
    "    print('layer 3 operation results')\n",
    "    print('h_fc2 is:', h_fc2)\n",
    "    print('h_fc2_drop is:', h_fc2_drop)\n",
    "\n",
    "    '''FC4: Classifier layer'''\n",
    "\n",
    "    W_fc3 = weight_variable([FulCon2Num,number_labels], 'fc3', 'trunc') #Modified here\n",
    "    b_fc3 = bias_variable([number_labels], 'fc3')\n",
    "    k = tf.constant(0.00000001, shape=[1]) #Constant value added to prevent underflow (probability of having zero terms)\n",
    "    h_fc3 = tf.matmul(h_fc2_drop, W_fc3) + b_fc3\n",
    "    y_conv = tf.nn.softmax(h_fc3) + k #Before just inside the parenthesis was the h_fc3 content (above)\n",
    "\n",
    "    print('layer 4 operation results')\n",
    "    print('h_fc3 is:', h_fc3)\n",
    "    print('y_conv is:', y_conv)\n",
    "\n",
    "    '''Training method'''\n",
    "\n",
    "    #with tf.device('/gpu:0'):\n",
    "    #Train and evaluate\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.arg_max(y_conv,1),tf.arg_max(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    tf.scalar_summary('cost', cost)\n",
    "    tf.scalar_summary('accuracy', accuracy)\n",
    "\n",
    "    '''Merging summaries and initializing variables'''\n",
    "\n",
    "    #with tf.device('/gpu:0'):\n",
    "    #Merging all summaries and initializing all of the variables\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    '''------------------------------------------------------------------------------------------------------------''' \n",
    "    '''                                   Initialization of the training process                                   '''\n",
    "    '''------------------------------------------------------------------------------------------------------------'''\n",
    "    # -------------------------------Preparing the data structures to plot the graphics-------------------------------\n",
    "    \n",
    "    '''#Average Accuracy test (maximum value)\n",
    "    acc_test_avg = np.array([[0,0.0]]*len(train_data))        \n",
    "    #Maximum and average Accuracy test (to plot graphs)\n",
    "    x_iter_avg, y_acc_avg = [np.array([]) for _ in range(2)]'''\n",
    "    \n",
    "    # ------------------------------------------ Initializing the procedure ------------------------------------------\n",
    "\n",
    "    k=0    \n",
    "    while k<len(train_data):\n",
    "        \n",
    "        #Average Accuracy test (maximum value)\n",
    "        acc_test_avg = np.array([[0,0.0]]*len(train_data))        \n",
    "        #Maximum and average Accuracy test (to plot graphs)\n",
    "        x_iter_avg, y_acc_avg = [np.array([]) for _ in range(2)]        \n",
    "        \n",
    "        splits_time[0][run_his_maxac] = datetime.datetime.utcnow()\n",
    "\n",
    "        print('\\n Optimization of Split', k+1 ,'Started\\n\\n')\n",
    "\n",
    "        #with tf.device('/cpu:0'):\n",
    "        #Merging all summaries and initializing all of the variables\n",
    "        summary_op = tf.merge_all_summaries()\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(init)\n",
    "            writer = tf.train.SummaryWriter(tb_logs_path,graph=tf.get_default_graph())         \n",
    "\n",
    "            #Data used in order to do the batching according to the size of the training_data\n",
    "            # The new data\n",
    "            for step in range(iterations):\n",
    "                #The batches used to train the data\n",
    "                batch_x = data.next_batch(train_data[k],step*batch_size,batch_size)                \n",
    "                batch_y = data.next_batch(train_labels[k],step*batch_size,batch_size)                             \n",
    "                _, summary = sess.run([train_step,summary_op], feed_dict={x:batch_x, y_:batch_y, keep_prob: drop_out_prob})\n",
    "                writer.add_summary(summary, step)\n",
    "                if step % display_step == 0:\n",
    "                    #Calculates batch accuracy\n",
    "                    train_acc, loss = sess.run([accuracy, cost], feed_dict={x:batch_x, y_:batch_y, keep_prob: drop_out_prob})\n",
    "                    if step % display_step*30 == 0:\n",
    "                        print(' Iteration: ' + str(step) + ' , loss: ' + '{:.6f}'.format(loss) + ' Accuracy: ' + '{:.6f}'.format(train_acc))\n",
    "                if step % (display_step * 5) == 0:\n",
    "                    #Calculates accuracy in averaged-sequences\n",
    "                    y_res = sess.run([h_fc3], feed_dict={x:test_data[k], y_:test_labels[k], keep_prob:drop_out_prob})\n",
    "                    'y_res produces a 3d array -> Convert to 2d'\n",
    "                    y_res = np.array(y_res)\n",
    "                    y_res_shp = y_res.reshape(-1,number_labels)                    \n",
    "\n",
    "                    #### Post-processing Average ####\n",
    "\n",
    "                    counter = 0\n",
    "                    for i in range(len(data_zeros[k])):    \n",
    "                        test_case = np.array(y_res_shp[data_zeros[k][i][0]:data_zeros[k][i][1]][:])                \n",
    "                        data2avg = np.mean(test_case,axis=0)\n",
    "                        data_avg = np.exp(data2avg)/np.sum(np.exp(data2avg))\n",
    "                        position = np.argmax(data_avg)                        \n",
    "                        if(position == data_zeros[k][i][2]):\n",
    "                            counter+=1\n",
    "                    accur = counter / data_zeros[k].shape[0]\n",
    "                    print('The postprocessing average accuracy is:', accur, 'and the number of correct results is:', counter)\n",
    "                    if(acc_test_avg[k][1]<accur):\n",
    "                        acc_test_avg[k][:] = [step,accur]\n",
    "                    y_acc_avg = np.append(y_acc_avg,accur)\n",
    "                    x_iter_avg = np.append(x_iter_avg,step)  \n",
    "\n",
    "        print('\\nOptimization of Split', k+1 ,'Finished\\n\\n')                \n",
    "        all_max_acc[run_his_maxac] = acc_test_avg[k][:]        \n",
    "        k+=1        \n",
    "        #Here you have to put also the history of y_acc_avg and x_iter_avg\n",
    "        splits_time[1][run_his_maxac] = datetime.datetime.utcnow()\n",
    "        plot_data[0][run_his_maxac] = x_iter_avg\n",
    "        plot_data[1][run_his_maxac] = y_acc_avg\n",
    "        run_his_maxac+=1                \n",
    "    datasets_time1[1][z] = datetime.datetime.utcnow()\n",
    "    z+=1    \n",
    "    ops.reset_default_graph()\n",
    "\n",
    "exp1_end = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy results of all of the data During Experiment 1\n",
    "------\n",
    "Reports in percentage of accuracy per data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penn action Results \n",
      "\n",
      "maximum accuracy obtained (avg) is 3550.0 in iteration 0.89138576779\n",
      "\n",
      "\n",
      "Sub-Jhmdb Results \n",
      "\n",
      "maximum accuracy obtained in split 1 (avg in post_processing) is 0.707865168539 in iteration 550.0\n",
      "maximum accuracy obtained in split 2 (avg in post_processing) is 0.7125 in iteration 200.0\n",
      "maximum accuracy obtained in split 3 (avg in post_processing) is 0.641304347826 in iteration 150.0\n",
      "Accuracy of the 3 splits at once (using avg post_processing) is 0.687223172122\n",
      "\n",
      "\n",
      "Jhmdb Results \n",
      "\n",
      "maximum accuracy obtained in split 1 (avg in post_processing) is 0.641791044776 in iteration 1700.0\n",
      "maximum accuracy obtained in split 2 (avg in post_processing) is 0.644444444444 in iteration 1250.0\n",
      "maximum accuracy obtained in split 3 (avg in post_processing) is 0.637735849057 in iteration 600.0\n",
      "Accuracy of the 3 splits together (using avg post_processing) is 0.641323779426\n",
      "\n",
      "\n",
      "Florence 3d Results \n",
      "\n",
      "maximum accuracy obtained in split 1 (avg in post_processing) is 0.793103448276 in iteration 100.0\n",
      "maximum accuracy obtained in split 2 (avg in post_processing) is 0.888888888889 in iteration 100.0\n",
      "maximum accuracy obtained in split 3 (avg in post_processing) is 0.952380952381 in iteration 100.0\n",
      "Accuracy of the 3 splits together (using avg_test_postprocessing) is 0.878124429849\n",
      "\n",
      "\n",
      "Bonn Mocap Results \n",
      "\n",
      "Bn_Mocap maximum accuracy obtained in split 1 (avg test_postprocessing) is 0.923076923077 in iteration 7250.0\n",
      "Bn_Mocap maximum accuracy obtained in split 2 (avg test_postprocessing) is 0.944206008584 in iteration 10450.0\n",
      "Bn_Mocap maximum accuracy obtained in split 3 (avg test_postprocessing) is 0.925 in iteration 12300.0\n",
      "Accuracy of the 3 splits together (using avg_test_postprocessing) is 0.93076097722\n",
      "\n",
      "\n",
      "-----------------------------------------------------------\n",
      "accuracy of all of the datasets together is: 0.805763625281\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Penn Action\n",
    "print('Penn action Results \\n')\n",
    "print('maximum accuracy obtained (avg) is', all_max_acc[0][0], 'in iteration', all_max_acc[0][1])\n",
    "print('\\n')\n",
    "#Sub-Jhmdb\n",
    "\n",
    "print('Sub-Jhmdb Results \\n')\n",
    "\n",
    "for i in range(1,4):\n",
    "    print('maximum accuracy obtained in split', i ,'(avg in post_processing) is', all_max_acc[i][1], 'in iteration', all_max_acc[i][0])\n",
    "\n",
    "mean_subJHMDB4 = np.mean([all_max_acc[1][1],all_max_acc[2][1],all_max_acc[3][1]])\n",
    "print('Accuracy of the 3 splits at once (using avg post_processing) is', mean_subJHMDB4)\n",
    "\n",
    "#Jhmdb\n",
    "print('\\n')\n",
    "print('Jhmdb Results \\n')\n",
    "for i in range(4,7):\n",
    "    print('maximum accuracy obtained in split', i-3 ,'(avg in post_processing) is', all_max_acc[i][1], 'in iteration', all_max_acc[i][0])\n",
    "\n",
    "mean_JHMDB4 = np.mean([all_max_acc[4][1],all_max_acc[5][1],all_max_acc[6][1]])\n",
    "print('Accuracy of the 3 splits together (using avg post_processing) is', mean_JHMDB4)\n",
    "print('\\n')\n",
    "\n",
    "#Florence_3d\n",
    "\n",
    "print('Florence 3d Results \\n')\n",
    "for i in range(7,10):\n",
    "    print('maximum accuracy obtained in split', i-6 ,'(avg in post_processing) is', all_max_acc[i][1], 'in iteration', all_max_acc[i][0])\n",
    "\n",
    "_,mean_florence3d = np.mean(all_max_acc[7:10],axis=0)\n",
    "print('Accuracy of the 3 splits together (using avg_test_postprocessing) is', mean_florence3d)\n",
    "print('\\n')\n",
    "\n",
    "#Bn_mocap\n",
    "\n",
    "print('Bonn Mocap Results \\n')\n",
    "for i in range(10,13):\n",
    "    print('Bn_Mocap maximum accuracy obtained in split', i-9 ,'(avg test_postprocessing) is', all_max_acc[i][1], 'in iteration', all_max_acc[i][0])\n",
    "\n",
    "_,mean_bn_mocap = np.mean(all_max_acc[10:13],axis=0)\n",
    "print('Accuracy of the 3 splits together (using avg_test_postprocessing) is', mean_bn_mocap)\n",
    "print('\\n')\n",
    "\n",
    "global_mean1 = (all_max_acc[0][1]+mean_subJHMDB4+mean_JHMDB4+mean_florence3d+mean_bn_mocap)/5\n",
    "\n",
    "print('-----------------------------------------------------------')\n",
    "print('accuracy of all of the datasets together is:', global_mean1)\n",
    "print('-----------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting of all of the data\n",
    "------\n",
    "Results of the accuracies of the data after post-processings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Penn Action\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAADDCAYAAABXs88PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncBERERFZGAMuIiIiIgv7/88Dh2utNVBQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd298097860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=1, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(211)\n",
    "plt.title('Penn_Action: Accuracy on Split avg')\n",
    "plt.plot(plot_data[0][0],plot_data[1][0],'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Sub-Jhmdb\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3lf0FFU1fQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd29808cf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcFOW1//HPAUQFDCMuoIAoImIkApqLRKJO1CjG7Zeo\nQYRoNLkxLlej16u4XcAEE01cY4wmLhg31FwX1Bg0yZ1ouLJEWWQ3iOwikhmIgorM+f3x1DA9Tc9M\nz0x3dXXP9/16zYuu6uqq0wunnj7PU0+buyMiIqWrTaEDEBGR/FKiFxEpcUr0IiIlToleRKTEKdGL\niJQ4JXoRkRKnRF9CzOx/zez8Fu5jjJk9kquYMux/qZkdE8exJLfM7GgzW5GyPNfMjipkTJIdJfqE\nMbOvmtkUM6sysw/N7HUzOyzPx6w2s94pq+K8uKLFxzKzd81sbi6CKXVmtoOZ3WpmK8xso5ktMbNb\nm7CLbe+Xu/d399ei/Y4xs981cuyLzWyGmX1iZg828ylIM7QrdABSy8x2AV4ALgCeBtoDRwKf5vnQ\nRXvVXNSi3ANoa2aHufubMR67rbtvjet4OXItcCjwZXdfa2b7AHG1ylcBPwZOAHaO6ZiCWvRJ0xdw\nd3/Kg0/d/U/uPhe2L3WYWa+oNZ76PvYxs2nRN4Jnzawsi+Na2vKOZvZw1OJ728wOTTnmUjO70sxm\nm9m/zOy3Zranmf0h2v4VM+ucsv13zOw9M1tnZtdmOPbOZjYxeuzfzeyQrF6pWucCzwF/iG7XPimz\nXc3sQTNbZWbrzeyZlPtOM7OZZrbBzN4xs+NTnt8xKdtte81TXu/zzWwZ8Odo/VNmtsbMKs2swsy+\nmPL4naIW9HvRe/JatO5FM7s4Ld7ZZnZqpidpZqdGpZJ/mtlfzKxfyn1Lzew/o8dXmtkTZta+ntfr\ny8Cz7r4WwN2Xu/ujafsabWbzotfsgfr2VfNamdkJhBPI8OgzMTPT9u7+nLtPAv5ZT2ySJ0r0ybIY\n2GpmE8xsWD1JOr31nb78HeC7wF7AVuCXzYjjFOBxoDPhG8av0u7/FnAs4cR0KiHJjgZ2A9oClwJE\nCe8eYCSwd3R/97R9nQo8CewKPAE8Z2Zto8f/yszuri9IM9sZOAN4LIp3hJmlfkt9lNByPAjYE7g9\netxg4GHgP929M6FF+14Dr0f6a3wU0I/QMiV6/vtHx3griqfGrcAgYEj0HK8ivC8PE96rmucygPAa\n/SHD8+wbPb9LCd9eXgZeSHuuZwLHA/sBAwifgUymAv9pZheaWf96tjkb+Hr0nA4Erq9nOwDcfTJw\nE/Cku+/i7oMa2l7ip0SfIO7+L+CrQDXwG+ADM3vezPZowm4ecfcF7r4ZuAE408zSW+yN+Zu7T/Yw\nEdIjQHor+5fu/qG7rwFeB6a5+xx33wI8S0hsAKcDL7j7lOi+G9g+ab7p7s9GJZDbgJ0ISRF3v9jd\nL2kgztOBT4DJwIuEk8xJAGbWjZCIL3D3je6+1d1fjx53PvCAu/8lOs4ad1+c5WvjwBh33+zun0aP\nn+Dum6LneCMwwMx2iV7384BL3f396Fva1Gi75wnfvvaP9juKkCg/z3DMbwMvuvtfotfpF4QT2BEp\n29zp7mvdvYpwch5YT/w3AT8jJPMZZrbSzM5J2+aX7r462td4YESWr40klBJ9wrj7Inc/3933AfoT\nWnl3NGEXK1JuLyPU+XdvYhjvp9zeBOyUVh5am3J7c4blTtHtvVPjcfdNwPr64o1OLCujx2XjHKCm\nzPUZ4SRTU77pCfzT3TdmeFxPYEmWx8hkZc0NM2tjZj8zs3+YWRWwlHAy2D362xF4N30HUbxPAaOi\nE8IIwkk1k70J72XNY53wuqV+O0p9DzZR+x6kH9fd/dfufiRQRkj8D5rZgZmeX3TcbN8PSSgl+gSL\nWpkTCAkf4GOgQ8ome2V4WM+U272Az4AP8xFfFtaQEo+ZdSCUb1Kl3m9AD2B1Yzs2s+7AMYREucbM\n1hBa+N8wsy6ERNjFzL6Q4eErCGWJTNJf424Ztkn9VnI2odR1jLuXAfsS+jyM8Lp/0sCxfkdoyR8L\nfOzu0+rZbjXhvUzVk7oJucmiPqB7gErgiyl3pX+GGn0/KOIO/dZAiT5BzOxAM7siSmKYWU9CS++N\naJNZwFFm1jPq8BydYTejzKxflFTHAU97y+eibmrpp8bvgZPN7Agz24FQ1kjf12Fm9v+iuvzlhMQ4\nNYt9nwMsIvQTDIj++hJGdoxw9/cJtex7zKzMzNqZ2ZHRYx8AzjOzr1mwd0qLdhZwVrT9lwl9AKnS\n49+FMCqq0sw6Aj8lSnrR6/4QcJuZ7RW1/odErwXuPpVQpruV+lvzEFr+J0XxtjOzK6PX6Y0GHpOR\nmV1mYTz8TmbW1szOJbT+30rZ7GIz6x6dMK8BJmax67XAvg2VCaPj7UQosbUzsx1r+mMkv5Tok+Vf\nwOHANDP7F/B/wBzgSgB3/xOh43IOMINQi01VU1N/mNAKaw9cluWxGzoZeD23G3ycu88HLiZ0sq4m\nlG3SW6HPA8MJrcqRwLdqhiya2a/N7J56dv8d4Ffuvs7dP6j5A+6ltnxzDvA5sJCQiC6L4ppBqJ3f\nAWwAKoB9osfcAPQhjAwZQ92O1UzP93fAcsIJZi7hPUt1JfA24f1aT6iPt0l7fH9Cx3FG0Te7UcDd\nwDpCP8QpKfX8ppzINxNOLGuifV1IeM2XpWzzOPAK8I/ob3x9oaXcfppwElxvZn+vZ/vrCWWlqwnv\n9SbguibELs1k2TT2zGwY4T9FG0In1s1p9/ckJJeyaJtr3P3l3IcruWZh7H4VsGs99WzJIzP7DvDv\n7p6IK0zNbCnwvZqOaikNjbboo064uwkjGA4mDGHrl7bZ9YQRA4cSSg31tcIkec4ClijJxy8qr10E\n3FfoWKS0ZVO6GQy84+7LomFhE4HT0rapBmo6vcoIX2MlIczs7OhClo1pf/MI5YzvFTrG1sbCBVof\nEEooTxQ4nFTqVC1BjZZuzOx04AR3/0G0PAoY7O6XpmzTjVDT25UwYuE4d894dZyIiMQrmxZ9pl70\n9LPDCOAhd+9J6Ciqt2NJRETilc2kZiupHZEAmcc5f4/ocnB3nxoN3drd3euM3zYzfS0UEWkGd2/u\nMOesWvQzCJdq94omNzoLmJS2zTLgOAAzOwjYMT3JpwSb+L8xY8YUPAbFqRgVp+Ks+WupRhO9hzHN\nlxBq8POAie6+wMzGmdnJ0WZXAv9uZrMI447Pzbw3ERGJW1bz0bv7Hwmz2KWuG5NyewFhMi4REUkY\nXRmbQXl5eaFDyIrizJ1iiBEUZ64VS5wtldWVsTk7mJnHeTwRkVJgZnieO2NFRKSIKdGLiJQ4JXoR\nkRKnRC8iUuKU6EVESpwSvYhIiVOiFxEpcUr0IiIlToleRKTEKdGLiJQ4JXoRkRKnRC8iUuKU6EVE\nSpwSvYhIiVOiFxEpcUr0IiIlToleRKTEKdGLiJQ4JXoRkRKnRF9kXnoJqqrqrquqCuuTpBjiLIYY\npTgk/bOkRF9khg6F666r/VBVVYXloUMLG1e6YoizGGKU4pD0z5K5e+MbmQ0D7iCcGB5w95vT7r8N\n+BrgQEdgD3fvkmE/ns3xpGHr18Mhh4AZtG8Pw4fDV74CgwZBjx5hfSF89BHMmQMzZ4a/GTNg3jzY\nZx9o2xZGjoQjjoCBA2HPPQsTI0BlZYhv1iyYNg1efRU+/hg6dYLjj4fDDw+v5cCB0Llz4eKU4rJy\nZUjsO+0Eu+8ODz0EffvmZt9mhrs3+392o4nezNoAi4FjgdXADOAsd19Yz/aXAAPd/fsZ7lOiz4H7\n74d774U334S77oLVq2uT69attUlq0KDw17dvSLT1eeml8AEtK6tdV1UFU6bASSdlfswHH4REWXPc\nmTNhxQo4+ODa4w4cCB07woABcOut4T9CTYLt0KF2u5pt99uv4ZNUU+N0rz1mzXFnzgwnygEDao/d\ntSucfDI8/zysXVu73Zw54b7U13LQINhrr/rjbM5rWQjFEmexqKoKr1v37vD003D66fCnP0F5OZx/\nPpx4IuywQ/P339JEj7s3+AcMAV5OWR4NXN3A9lOAY+u5z6VlKivd99jD/cwz3Zcudb/oorDO3b26\n2n3VKveXXnL/yU/cTz/dvXdv944d3YcMcf/hD93vu899+nT3zZvr7jN1P6nL1dXuS5a4//737tdf\n737SSe577+1eVuZeXu5++eXuv/ud+5w57p99tn2sF12UOc6lS92fecb9hhvcTz7ZvXt3986d3Y8+\n2v1HP3KfMMF99uy6+2wozs8/d58/3/2xx9yvvNL9uOPcd9vNfc893U84wX30aPcnn3RfvNh969bG\nY3QP+1ywwP3xx92vusr961933333sM/jj3e/+mr3iRPdFy2q3WdDMSZJscRZDNatcx80yP2CC9wv\nvLD2s7R8ufv997sPHeretWv4XM6b17xjRLmz0Xxd3182LfrTgRPc/QfR8ihgsLtfmmHbfYA3gB6e\nYcdq0bfcRRfBX/8aWl5lZbW1wPHj67bOUm3YALNn123ZLloE++9f20o94AB49lk480z4xS/Ct4AF\nC8K2nTrVbdEOGgS9ejXc+k6PK5s4163b/lvC8uXwxS/Wtqr79IGnnoJTT4Xbb4fevWH+fJg7F7p1\ny9z6zmWM7rBqVd1vCDNnwocfhnLaoEFw4IHw+uvw4x+Hb1wN7a+Qap7vlVeG9zypcSbZ6tXw9a/D\nsGGweTPcdFPmz9KiRTBhAjz8cChlnn9+KLlmWxqMo3RzBnB8WqL/N3e/LMO2VwHdM90X3e9jxozZ\ntlxeXk55eXlzY291FiyAIUNCyaZPn9r1zfnK/emnoX6emrDmzIF//SuUMY48srakssceTY81V6WB\njz+urfvXxLlgQVh/+um1cQ4Y0PR6ei7LF5WVdU+m06bB4sXQr1/dmn8h6/7u4cSZesKfMQPWrIFz\nzoEf/SjEKdlZtgyOPRa+971wks/ms/T55/DKK/Dgg6G0c8opcN55ocTTJmVoTEVFBRUVFduWx40b\nF0vp5o8py/WWboC3gCEN7Kt531vEq6tDueD22/Oz/4ZKGElSDHHWxLhwofsZZ7jfcUf4Sv+Vr4Qy\nWu/eoaz24x+7v/hiKLdVV9e/vxdf3P55VlaG9fXZssV97lz3Rx5xv+IK9699zX3XXd332sv9G99w\nv/baUB4bOdL9tdfc/+3f3Hv2dB8wwP3OO0M5Igma89zjsGiR+z77hNequdatC5+NQw5x33df97Fj\n3d97r/b+1OdOC0s32ST6tsA/gF5Ae2AWcFCG7Q4E3m1kX81/VVq55593P+ig7evguVAs9dpiiLOx\nGLOt+y9cmH3d/+OP3d94w/2ee9x/8IOQtDt0cD/gAPdvf9v9pz91/+Mf3d9/v+E4L7wwfM5Gjgz9\nJWecEfp7tmzJ/+tWnyS+53PmhBPmAw/kZn/V1e5vvul+8cWhX+m440Jf0+rVtc8174neQ4IeBiwC\n3gFGR+vGASenbDMGuKmR/eTmlWllNm8OrcBXXsnP/pPaakpXDHE2J8bqavcVK9xfeMH9xhvdv/nN\n0MLr1Mn9iCNCArjzztABP326+ymnuI8b5z5iRDj577yz+6GHup9/vvsvf+n+t7+5b9zYsjgrK93v\nvdd98ODQ+T56dGjFFkLNSejddwuf5GfMCB2rTzyRn/1v3hxO9Mcf796li/t554UTbksTfVbj6HNF\nnbHN89Ofhprvc88VOhKJU1VV3Q7f6dNDp97gweG6iZqO54MOCtdT5Mu8eWFM+KOPhr6h888Pnfa7\n7JKf423dGp5nal/C3/8eBhX85jfw/e8X5lqR118P/UL33x8GA+TbihWh8/Y3v4EVK/I8vDKXf6hF\n32QrV4avc0uWFDoSKaQk9E189pn7c8+5n3ZaGF773e+G+n5N/0Jzvs1s2uQ+bVr49nDBBe6HHx76\nMfr0Cd9gbrrJ/amnwrEmTAj9DEcfHconcZo8OQxrfvXVeI9b822GOEo3ufpTom+6kSNDx5m0Xkms\nU7//vvsvfuH+xS+GpDx+fOj8bSjO9evd//zn8LiRI8Njd97ZfeDAUKK4665w4tiwofY46ftYt879\nyCNDv8YPf+j+wQf5f67PPhuS/Ouv5/9YqVKfe0sTvUo3CfZ//wff/jYsXBjGskvrlOSrWN1DSemh\nh8L1DYceGq7Cvv76UHI85JDw+Z05MwxBTb0ieeDAcCV1Q2Wn+p775Mnwxhvw2GNwzTVwySX5KV89\n8QRcfnmI47DDcr//hqQ+97yPo88lJfrsbd0axl9fcQWcfXahoxFp3KZN4aK7X/0qJOGjjgqJqiax\n9+5dd6x4LixcGC74WrQoTLNxyim5q9/ffz+MGRNOKv3752afzdXSRK/ZKxPqoYfC5EgjRhQ6EpHs\ndOgQvmEMGgRLl4bkeNVVoeO2T5/cJ3kIF6S9+CLcfTeMHh2uUn377Zbv94474Cc/gYqKwif5XFCL\nPoGqqsIH+A9/CF+FRYpBc6aUyKXPP4f77oMbb4RvfSv829Srut3DNAYTJoQrV3v1ykuoTaYWfQm6\n8cYwfEtJXorJlCl1k3pZWVieMiWe47drBxdfHMo5O+4Y5ki69Vb47LPsHu8e6v1PPAGvvZacJJ8L\natEnzIIFobY5f37z5pgRkaAp9fvqarj00tC3MHlymE8+SdQZW0Lcwyx4J54YJpgSkZabPDmMnNl7\n7zDj6fLldUfybN0K3/lOuDDrjTeS+WMzSvQlZNKk0KE0e3bLfqRAROpKrd/XDEm97bbQgTx8eLjy\ndurU8MMhSaREXyI++SSMKb733jByQERyr7ISxo2DRx4Jvxuw887w7ruhJd+tW6Gjq58SfYnQfDYi\n8Vm4MNTkX301/G7AAQcUOqKGadRNCVi1KnQW3XZboSMRaR26dQvJfenSMGa+qqrQEeWXWvQJMGpU\nGMo1fnyhIxEpfYUe798cKt0UOc1nIxKvJM8dVB8l+iKm+WxEJBuq0RcxzWcjInFQi75ANJ+NiGRL\npZsidcUV8NFH4WfCREQaokRfhDSfjYg0hWr0OfLSS9uPpa2qCutzyT3MY3PddUryIhIPJfrI0KEh\n+dYk+5qxtUOH5vY4L7wQft394otzu18RkfqodJOiqgquvRYuuwzuuiv3F1BoPhsRaY6Wlm7aZXmQ\nYcAdhG8AD7j7zRm2+TYwBqgGZrv7qOYGVSidO4e6eb9+4fLojRvr/pDxrru2bP+33w5f+pKSvIjE\nq9EWvZm1ARYDxwKrgRnAWe6+MGWbPsCTwNfcfaOZ7e7uH2bYV6Jb9I89Bv/xH/C3v8HYsaHDdNGi\n8Av2s2fDbrvVTfyDBkGPHvX/mEHqFXirVsGAAeHnyVatSu4VeCKSPHkfdWNmQ4Ax7n5itDwa8NRW\nvZndDCxy9wcb2VdiE/3774dpSydMgG9+c/v5L6qrYcmSkPRT/7ZurZv4Bw2Cvn2hbdu6+7jkEuja\nNZRvkjynhogkTxyJ/nTgBHf/QbQ8Chjs7pembPMsodU/lFDeGefukzPsK7GJ/pxzYP36uqNsspn/\nYs2auol/1qxw0ujfPyT9Aw8Mv1I/d274HdhbblGSF5GmiaNGn2nn6dm6HdAHOArYB3jdzA52943p\nDxw7duy22+Xl5ZSXl2cba96sWhWuUJ0+ve76srLGSyx77RX+vvGN2nUbNoRST03yX7s2/F17rZK8\niDSuoqKCioqKnO0v29LNWHcfFi1nKt38GnjD3X8XLf8JuNrd30zbVyJb9PmcJrimfPNf/wU//7nK\nNiLSdHFcMDUD6GNmvcysPXAWMCltm+eAY6KAdgcOAN5tblBxmjIFKirgmmtyv+/UGv2++4Z/U8fq\ni4jEodFE7+5bgUuAV4B5wER3X2Bm48zs5GibycB6M5sH/Bm40t0r8xh3TmzdGn5O7JZb8jMX/JQp\ndVvwZWVhecqU3B9LRKQ+rfqCqfvvD6NsXn+9/iGSIiKFpknNmknTBItIsVCib6bLL4ePP9Y0wSKS\nfLFMgVBq5s+HRx8N/4qIlLpWN3ulpgkWkdam1SX6SZNg5UpNEywirUerKt188kn4Cb9774Uddih0\nNCIi8WhVLfrbbtM0wSLS+rSaUTc10wRPnw69exckBBGRZtHwyizlcz4bEZF80vDKLNTMZ7NwYaOb\nioiUnJKv0dfMZ3PzzfmZz0ZEJOlKPtE/9BDstBOcfXahIxERKYySrtFrPhsRKQXqjG3A5ZfDRx/B\nb38b2yFFRHJOnbH1qJnPZt68QkciIlJYJVmjT53PZs89Cx2NiEhhlWSi13w2IiK1Sq5088knoTZ/\n332az0ZEBEqwRX/bbXDIIZrPRkSkRkmNulm5snY+m/33z9thRERipeGVKUaOhH331Xw2IlJalOgj\nU6bA8OFhPhtNdSAipaSlib4kavSaz0ZEpH5ZJXozG2ZmC81ssZldneH+c83sAzN7K/o7P/eh1u/B\nBzWfjYhIfRot3ZhZG2AxcCywGpgBnOXuC1O2ORc4zN0vbWRfOSndvPQSDB0KZWW189k8+WSY7uCk\nk1q8exGRRImjdDMYeMfdl7n7FmAicFqmWJobRFMNHRqueq2qgnHj4Pjj4amnwnoREakrm0TfHViR\nsrwyWpfuW2Y2y8yeMrMeOYmuHmVlYWTNhRfCww9Du3Zhuawsn0cVESlO2VwZm6mlnl5/mQQ87u5b\nzOwC4GFCqWc7Y8eO3Xa7vLyc8vLyrAJNV1YGHTtCZSX8938ryYtI6aioqKCioiJn+8umRj8EGOvu\nw6Ll0YC7+831bN8G+Ke7b5d6czm8sqoK+vcPLfnp09WiF5HSFUeNfgbQx8x6mVl74CxCCz41iG4p\ni6cB85sbUDaqquDaa2Hz5jDVwfjxtTV7ERGpK6sLpsxsGHAn4cTwgLv/zMzGATPc/UUzuwk4FdgC\n/BO40N0XZ9hPzkbd7L8/fPWrsG4dmIUkP2WKRt2ISOlptVfGTp4Mt9wCf/5zTnYnIpJYrfbK2Nmz\nwyyVIiLSsKJN9HPmKNGLiGSjqBP9gAGFjkJEJPmKskb/6adhKGVlZZjjRkSklLXKGv3ChdC7t5K8\niEg2ijLRqyNWRCR7RZno1RErIpK9ok306ogVEclOUSZ6lW5ERLJXdIl+7VrYsgW6Z5ooWUREtlN0\nib6mbGOx/cyJiEhxK7pEr7KNiEjTFF2i14gbEZGmKcpErxE3IiLZK6opED77DDp3hvXroUOHHAYm\nIpJgrWoKhEWLoFcvJXkRkaYoqkSvso2ISNMVVaLXiBsRkaYrqkSvETciIk1XdIlepRsRkaYpmkS/\nbh1s2gQ9exY6EhGR4lI0ib6mbKOpD0REmqaoEr3KNiIiTZdVojezYWa20MwWm9nVDWx3hplVm9mh\nuQsx0IgbEZHmaTTRm1kb4G7gBOBgYISZ9cuwXSfgP4CpuQ4SNOJGRKS5smnRDwbecfdl7r4FmAic\nlmG7HwM3A5/mMD4APv88/CB4//653rOISOnLJtF3B1akLK+M1m1jZgOBHu7+hxzGts2iRdCjB3Ts\nmI+9i4iUtnZZbJNpnMu2mcnMzIDbgXMbeQwAY8eO3Xa7vLyc8vLyRgNQR6yItCYVFRVUVFTkbH+N\nzl5pZkOAse4+LFoeDbi73xwtfwH4B/ARIcF3A9YDp7r7W2n7atbslddcEyYyu+GGJj9URKToxTF7\n5Qygj5n1MrP2wFnApJo73X2ju+/p7r3dfT9CZ+wp6Um+JTTiRkSk+RpN9O6+FbgEeAWYB0x09wVm\nNs7MTs70EBoo3TSHSjciIs2X+B8eWb8eeveGqipdFSsirVPJ//DInDnwpS8pyYuINFdRJHqVbURE\nmi/xiV4dsSIiLZP4RK+pD0REWibRnbGffw5f+AJ88AF06pTHwEREEqykO2PfeQf23ltJXkSkJRKd\n6FW2ERFpucQneo24ERFpmUQneo24ERFpuUQnepVuRERaLrGJvrIy/O23X6EjEREpbolN9DVTH7RJ\nbIQiIsUhsWlUZRsRkdxIdKLXiBsRkZZLbKLXiBsRkdxI5BQIW7eGqQ/WrAn/ioi0ZiU5BcKSJdC1\nq5K8iEguJDLRq2wjIpI7iUz06ogVEcmdxCZ6tehFRHIjkYlepRsRkdxJ3KibDRuge3fYuFFXxYqI\nQAmOunn7bejfX0leRCRXskqnZjbMzBaa2WIzuzrD/ReY2Rwzm2lmr5lZv+YGpLKNiEhuNZrozawN\ncDdwAnAwMCJDIn/M3Q9x90HAz4HbmxuQRtyIiORWNi36wcA77r7M3bcAE4HTUjdw949SFjsB1c0N\nSCNuRERyq10W23QHVqQsryQk/zrM7CLgCmAH4JjmBFNdDXPnhumJRUQkN7JJ9Jl6ercbOuPu9wD3\nmNlZwA3AdzPtbOzYsdtul5eXU15evm353Xdht92grCyLqERESlRFRQUVFRU521+jwyvNbAgw1t2H\nRcujAXf3m+vZ3oBKd98uXTc2vPKZZ2DCBJg0KfsnICJS6uIYXjkD6GNmvcysPXAWUCcVm1mflMWT\ngcXNCUYjbkREcq/R0o27bzWzS4BXCCeGB9x9gZmNA2a4+4vAJWZ2HPAZUAmc25xg5syBs89uziNF\nRKQ+iboytndvePllOPDA2EISEUm8lpZuEpPoN26EvfYK/7ZtG1tIIiKJVzJTIMydCwcfrCQvIpJr\niUn06ogVEcmPxCR6XRErIpIfiUr0muNGRCT3EtEZW10droZ97z3o0iW2cEREikJJdMa+9x507qwk\nLyKSD4lI9CrbiIjkTyISvUbciIjkTyISvVr0IiL5k5hErxa9iEh+FHzUzUcfQdeusGEDtMtmdnwR\nkVam6EfdzJ0LBx2kJC8iki8FT/Qq24iI5FfBE71G3IiI5FfBE71G3IiI5FdBO2Pdw9QHS5bA7rvH\nFoaISFEp6s7YZcugUycleRGRfCpoolfZRkQk/wqe6NURKyKSXwVN9BpxIyKSfwVv0at0IyKSXwUb\ndbNpU+iE3bABdtghthBERIpOLKNuzGyYmS00s8VmdnWG+y83s3lmNsvMXjWzno3tc+5cOPBAJXkR\nkXxrNNGPZkJ1AAAH3ElEQVSbWRvgbuAE4GBghJn1S9vsLeAwdx8I/A/w88b2q7KNiEg8smnRDwbe\ncfdl7r4FmAiclrqBu//V3T+JFqcC3RvbqUbciIjEI5tE3x1YkbK8koYT+feAlxvbqUbciIjEI5vJ\ngTN1AGTswTWzUcBhwNH17Wzs2LG4w7Rp8NFH5UB5FiGIiLQeFRUVVFRU5Gx/jY66MbMhwFh3HxYt\njwbc3W9O2+444E7gKHdfX8++3N1ZvhwOPxzWrMnJcxARKWlxjLqZAfQxs15m1h44C5iUFsQg4F7g\n1PqSfCp1xIqIxKfRRO/uW4FLgFeAecBEd19gZuPM7ORos1uAjsDTZjbTzJ5raJ/qiBURiU9BLpga\nPhxOOQVGjYrt0CIiRasopylW6UZEJD6xt+g3bXK6dAlTH7RvH9uhRUSKVtG16OfNg759leRFROIS\ne6JX2UZEJF4FSfQacSMiEp/YE72mPhARiVfsnbFdujjz50PXrrEdVkSkqBVdZ2y7dkryIiJxij3R\nq2wjIhKv2BO9RtyIiMRLLXoRkRKnRC8iUuJiT/QHHQRVVfDSS3EfWUSkdYo90W/eDNddB0OHxn1k\nEZHWKfZx9Bdd5IwfD2VlsR1WRKSotXQcfeyJfulSZ999YzukiEjRK7oLpn7+81CjFxGReMSe6MeP\nDzV6JXsRkXgU5KcEq6pgyhQ46aTYDi0iUrSKrkYf5/FEREpB0dXoRUQkXkr0IiIlLqtEb2bDzGyh\nmS02s6sz3H+kmb1pZlvM7Fu5D1NERJqr0URvZm2Au4ETgIOBEWbWL22zZcC5wGM5j7AAKioqCh1C\nVhRn7hRDjKA4c61Y4mypbFr0g4F33H2Zu28BJgKnpW7g7svdfS5QEj2txfLmK87cKYYYQXHmWrHE\n2VLZJPruwIqU5ZXROhERKQLZJPpMQ3pKouUuItIaNDqO3syGAGPdfVi0PBpwd785w7YPAS+4+zP1\n7EsnCBGRZmjJOPp2WWwzA+hjZr2ANcBZwIgGtq83mJYEKiIizdNo6cbdtwKXAK8A84CJ7r7AzMaZ\n2ckAZvZlM1sBnAHca2Zv5zNoERHJXqxTIIiISPxiuzK2sYuu4mRmD5jZWjObk7JuVzN7xcwWmdlk\nM+ucct9dZvaOmc0ys4ExxdjDzP5iZvPN7G0zuzShce5oZtPMbGYU55ho/b5mNjWK8wkzaxetb29m\nE6M43zCzfeKIMyXeNmb2lplNSmqcZvaemc2OXtPp0bqkve+dzexpM1tgZvPM7PAExtg3eg3fiv7d\nYGaXJi3O6LiXm9lcM5tjZo9Fn7/cfTbdPe9/hBPKP4BewA7ALKBfHMeuJ56vAgOBOSnrbgauim5f\nDfwsun0i8FJ0+3BgakwxdgMGRrc7AYuAfkmLMzpeh+jftsDU6PhPAmdG638NXBDdvhC4J7o9nFAK\njPO9vxx4FJgULScuTuBdYNe0dYl634EJwHnR7XZA56TFmBZvG2A10DNpcQJ7R+95+5TP5Lm5/GzG\n9SIPAV5OWR4NXB33m50WUy/qJvqFQNfodjdgQXT7XmB4ynYLaraLOd7ngOOSHCfQAfg74SK7D4A2\n6e8/8Efg8Oh2W2BdjPH1AF4FyqlN9OsSGOdSYLe0dYl534FdgCUZ1icmxgyxHQ+8nsQ4CYl+GbAr\n4aQ5Cfh6Lv8PxVW6KYaLrvZ097UA7v4+sGe0Pj32VcQcu5ntS/gGMpXwwUtUnFE5ZCbwPiGRLgGq\n3L062iT1/d4Wp4eO/ioz6xJHnMDtwH8RXQdiZrsBlQmM04HJZjbDzL4frUvS+94b+NDMHorKIr8x\nsw4JizHdcODx6Hai4nT31cCtwPLomBuAt8jh/6G4En0xX3RV0NjNrBPwe+Ayd/+ogWMXLE53r3b3\nQYQW82DgoAZiSY/TiCFOMzsJWOvus1JisAzxFDTOyBHu/mXgG8DFZnZkA8cuxPveDjgU+JW7Hwp8\nTPiWnqQYaw9utgNwKvB0I8cuSJxmVkaYVqYXoXXfkVBGqi+WJn8240r0K4HUDoMehHpZkqw1s64A\nZtaN8LUJQuw9U7aLLfao8+X3wCPu/nxS46zh7huBvxK+ZpZZmBAvPZZtcZpZW+AL7l4ZQ3hDgVPN\n7F3gCeAY4A6gc8LirGll4u7rCCW7wSTrfV8JrHD3v0fL/0NI/EmKMdWJwJvu/mG0nLQ4jwPedfd/\nRi30Z4EjyOH/obgS/baLrsysPeGiq0kxHbs+6a25ScB3o9vfBZ5PWX8ObLtKuKrma18MHgTmu/ud\nKesSFaeZ7V4zasHMdiZ8aOcD/wucGW12blqc50a3zwT+ku8YAdz9Wnffx917Ez5/f3H3UUmL08w6\nRN/iMLOOhNry2yTofY/2v8LM+karjiVcY5OYGNOMIJzcayQtzuXAEDPbycyM2tczd5/NGDtDhhFG\njrwDjI7ruPXE8jjh7Php9CKfR+gI+VMU46tAWcr2dxNGDc0GDo0pxqHAVsIIpZmEmt0woEvC4vxS\nFNssYA5wXbR+P2AasJgwemCHaP2OwFPR52AqsG8B3v+jqe2MTVScUTw17/nbNf9XEvi+DyA04GYB\nzxBG3SQqxui4OxM63HdJWZfEOMcQOn/nAA8TRifm7LOpC6ZEREqcfkpQRKTEKdGLiJQ4JXoRkRKn\nRC8iUuKU6EVESpwSvYhIiVOiFxEpcUr0IiIl7v8DsIzmkudazpIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2980b4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYXXWd5/H3JxsBsiJ7iAEMEMFpEemYRxooQSEIElth\nTGwQl0EbTeOGJuO0k0Jbx2jb6kwEnhlBQYUIUSTQokGhcA2GHbLvJCYQSEIgLEmofOeP36nk5uZW\n1a2qW3c5+byep57cc++553zv9jm/8zu/c6KIwMzM8qtPrQswM7Pe5aA3M8s5B72ZWc456M3Mcs5B\nb2aWcw56M7Occ9DniKT7JH20h8uYJunHlaqpxPJXSjqrGuuyypJ0pqQ1BdNPSjqjljVZeRz0dUbS\nP0j6k6TnJT0n6Q+S3trL69wp6diCu6p5ckWP1yVphaQnK1FM3knqL+nbktZIekHScknf7sIidn1e\nEfGmiPh9ttxpkm7qYL0DJP1A0ipJWyQ9JGl8D16KdYGDvo5IGgzcCXwPGA6MAK4GtvXyqhv2rLms\nRXkIcGxvbxBLrLtvNddXIV8CTgFOjYghwDuAR6qw3n7AU8DpETEU+J/ArZJeX4V17/Mc9PXleCAi\n4tZItkXEbyPiSdi7q0PSqKw1Xvg5jpb0QLZHcLukYWWsV0XT+0m6MWvxPSHplIJ1rpR0laTHJL0o\n6f9JOlTSr7L550gaWjD/pVkr7llJXyqx7v0lzcye+6CkvyvrndrtMuCXwK+y27tflDRc0g2S/iZp\no6RfFDw2QdIjWetyqaRzCl7fWQXz7XrPC97vj0paDfwuu/9WSeslbZbUIunEgucPzFrQq7LP5PfZ\nfXdJ+lRRvY9JurDUi5R0YdZVsknSvZLGFDy2UtLns+dvlnSLpAHtvF+nArdHxDMAEfFURPykaFlT\nJc3P3rPr21tW23sl6VzSBuQD2Xdirw1HRLwcEV+JiDXZ9H8CK4Gqbpz3VQ76+rIEaJX0I0nj2wnp\n4tZ38fSlwIeBI4BW4P90o473ADcDQ0l7GN8vevx9wNmkDdOFpJCdCrwO6AtcCZAF3jXAPwFHZo+P\nKFrWhcDPSHswtwC/bGspS/q+pBntFSlpf+Ai4KdZvZMk9SuY5SfA/sAbgUOB72TPGwvcCHw+a12e\nAazq4P0ofo/PAMYA52bTvwLekK3j4ayeNt8G3gKMy17jF0mfy42kz6rttbyZ9B79qsTrPD57fVeS\n9l7uBu4seq0XA+cAxwBvJn0HSpkLfF7SFZLe1M48HwTelb2mE4B/bWc+ACLiN8DXgZ9FxOCIeEtH\n82ev6TDgOGB+Z/NaBUSE/+roj/TDuoG0m7sduAM4JHtsGnBTwbyjSKHRJ5u+D/h6weNvBF4F1Mk6\ndwLHFqxjTtEyXiqYXglMKpieBXy/YHoy8Ivs9peBmwseO4DUDXVWwbr+XPC4gHXAaWW+V5cAz2TP\nGwBsAiZkjx0OvAYMKfG864Bvt7PMlW31Fb/nBe/3qA5qGpa9n4Ozul4G3lRivgHAc8AbsulvATPa\nWea/AjOL3qe1wBntfCbTgWvaWZaAK4A/AK9ky/lQ0eu/vGD6PGBpdvtM4KlS71Xxd7OTz60fcE97\nNfqv8n9u0deZiFgcER+NiNcDbyK18r7bhUWsKbi9mhQoB3exjKcLbr8MDCzqHnqm4PYrJaYHZbeP\nLKwnIl4GNrZXb6QUWJs9rxwfAtq6ubYDt7O7+2YksCkiXijxvJHA8jLXUcrathuS+kj6hqRlkp4n\nhV+Q3vODgf2AFcULyOq9FbhEkoBJQHsjkI4kfZZtzw3S+1a4d1T4GbzM7s+geL0REddGxOmkjdLX\ngRsknVDq9WXrLffz6FT2Wn9C2uD/S6WWax1z0NexiFgC/IgU+AAvkVrFbY4o8bSRBbdHkfYKnuuN\n+sqwnoJ6JB1A6r4pVPi4gKNIrfoOSRoBnEUKyvWS1gPvB94t6SBSEB4kaUiJp68hdUuUUvweH15i\nnsKunA+SurrOiohhwNGkVrNI7/urHazrJtJeydmkvaYH2plvHemzLDSSPQO5yyIdA7oG2AycWPBQ\n8Xeo08+D8g/oX0/aAL4vIlrLfI71kIO+jkg6QdLnshBD0khSS+8v2SyPAmdIGpkd8JxaYjGXSBqT\nherVwG1ZC7BHpXXzebOACyS9XVJ/4CsllvVWSe/N+uU/SwrGuWUs+0PAYtJxgjdnf8cDfyN1YzxN\n6su+RtIwSf0knZ4993rgI5LeoeTIghbto8DEbP5TSccAChXXP5jUOt0s6UDgf5GFXva+/xD4D0lH\nZK3/cdl7QUTMJXXzfJv2W/OQWv7nZ/X2k3RV9j79pYPnlCTp00rj4QdK6ivpMlLr/+GC2T4laUS2\nwfzvwMwyFv0McHS2sW5v3deRjm1cmO3RWJU46OvLi8DbgAckvQj8GXgcuAogIn5LOnD5ODCPdKC0\nUJAC40ZSK2wA8Oky193RxiDaud3h8yJiAfAp0kHWdaRum+JW6B3AB0ityn+ioKUn6VpJ17Sz+EtJ\nxwaejYgNbX+k/ve27psPkfrpF5GC6NNZXfOAj5C6xLYALUDbML8vA6NJ/f3T2PPAaqnXexPpeMrf\ngCdJn1mhq4AnSJ/XRuAb7Pm7u4m0x/YT2pHt2V0CzACeBc4H3hMRr7VTU0deIW1Y1mfLuoL0nq8u\nmOdmYA6wLPv7WnulFdy+jbQR3CjpweIZlYZRfhw4GXgmG53zgqRJXajduknlNPaUTmz4LukLen1E\nTC96/D9I43EDOJB08PCgypdrlaY0dv95YHg7/dnWiyRdSjr4WRdnmEpaCXwsIu6tdS1WOf06myE7\nCDeD1I+4Dpgn6Y6IWNQ2T0R8rmD+yaSttjWGicByh3z1Zd1rnyT9vsx6TTldN2NJw6tWR8QOUn/d\nhA7mn0TaVbc6IemDBbvKhX/zSd0ZH6t1jfsapRO0NpC6UOrp99KwZ0lb+zpt0ZOGcBUO2VtLCv+9\nZP1wRwPe7asjEXEzqd/V6kREzKGdIZC1FBHHdj6XNZpyWvSljqK3t9WfCMyqwCgPMzOrkHJa9GvZ\nPSIBOh7nPJHU51iSJG8AzMy6ISK6O8y5rBb9PNKFskZlFzeaCMwunikbhzwsGxvcrlqfClzO37Rp\n02peg+t0ja7Tdbb99VSnQR9pTPNk0rja+aRrbiyUdLWkCwpmnUh5J1aYmVkVldN1Q0T8mnSxrcL7\nphVNX13BuszMrEJ8ZmwJTU1NtS6hLK6zchqhRnCdldYodfZUWWfGVmxlUlRzfWZmeSCJ6OWDsWZm\n1sAc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczyzkH\nfS9rbYWVK+HVV2tdiZntq8q6TLF1rrUVVqyABQtg/vz074IFsHgxDB0KffrAlClw+eUwcGCtqzWz\nfYmvXtlFr72WAr0wzOfPhyVL4NBD4aST4MQTd//7xjfC4MHw4IPwla/AQw/BF78IH/847L9/rV+N\nmTWCnl690kHfjtdeg2XL9gzzBQtSoB9xxJ5h3hbogwZ1vtyHH06B/9e/whe+AJ/4BBxwQO+/HjNr\nXA76Ctq5E772Nbj11hTyRx65dwt9zBg48MCer+uRR1Lgz52bAv+f/7l2gf/ii3DnnXDXXTBkyJ6v\n9/DDQd3+epn1TAQ88ADMmgVr16YGVdt3c/RoGDCg1hVWh4O+Ql58ES69FDZuhO98J32RqhG8jz2W\nAv9Pf4KrroIrrqjMhqQzL7yQwv222+C+++D00+G974Vt23bvvcyfn449tO21FG4AjjzSGwDrHTt3\npgbQrFnpb9AguPhiOO44WLRo9/fzqafg2GP3/m4ef3z+NgAO+gpYtQouvBD+/u/h2mtr8yV5/HH4\n6lfhD3+Az38ePvnJygf+li0we3YK9/vvhzPPTD+g97wHhg0r/Zxnn92z66rt323b9v6BnXgiHHWU\nNwDWdTt3wl/+kr6bP/952rO8+OL0d9JJpZ/z6qupK7X4u7lqFRxzzN7fzRNOgP32q+rLqhgHfQ/9\n8Y/pyzRlCnz607UPqSeeSIF///3wuc/Bpz5VXt9/e55/Hu64I/2Afv97eMc7dof70KHdX+5zz+09\nwmj+fHj55T03AGPGVH7PaMAAOPXUxv3RWrJzZ9qTnTUrhfvw4em7edFF6fvTXdu2pQ1AcQNl5UoY\nNWrP8O+NrslDDqn8XoWDvgduuAGmToWbboLx42tdzZ7mz0+Bf++98NnPwuTJafROOTZvhl/+Mv2A\n/vhHOOus9AO64ILUUupNGzfuDv624aXbtlV2HVu3pmMoF1yQXtc553jIaqNobU3h3tZyP+SQ3eE+\nZkzvrnv79j03APPnp+9rJUXA00/D6tVw9NF77lWcdFLaAHSngeKg74bW1jTEcfbs1E/d21+wnliw\nIAX+734Hn/lMCvxSYb1pUwr3226DP/8Zzj57d7iXu4FoJOvXwy9+kV7vY4/B+een13vuuQ79etPa\nmrokb7stfWaHHba7W+b442tdXe8otVexYEEaml24V9H27wkndPy9rUrQSxoPfJd0Ju31ETG9xDz/\nFZgG7AQei4hLSsxT86DfsgUmToQdO9LomoMOqmk5ZVu4EP7t32DOnNTFdOWVqYXSFu5z58K73pV+\nPOef37Punkbz9NO7Q/+RR+Dd707vw/jxPlehVlpbU1dhW7gfeeTulvtxx9W6utrZvh2WLt37uMKK\nFTBy5N7HFcaMSd/hXg96SX2AJcDZwDpgHjAxIhYVzDMa+Bnwjoh4QdLBEfFciWXVNOiXLUt902ef\nnUbW9O9fs1K6bfHiFPh33ZX6OM85J/2A3v3ufSvc2/PMM3D77SlgHnoIzjsvhct55zXe+Qo7dqRQ\nKAyE1atT90C9W7UqHZhvC/fRo2tdUX3bvn33eTuFG4Fly9L7uHx57wf9OGBaRJyXTU8ForBVL2k6\nsDgibuhkWTUL+nvvhUmToLk5DWFsdH/7WxopU42hmI1qw4YU+rNmwbx5qVunbaNYT6FfTiuvraV3\nzDHQt2+tK+7cYYelPmrrmR07UtifeGLvB/37gXMj4uPZ9CXA2Ii4smCe20mt/tNI3TtXR8RvSiyr\nJkF/7bUp4G+5JR2YtH3Ps8/u7ub661/TntBFF6VurmptLLsyGqTtwJ27ngx63nVTzkXNSi28OK37\nAaOBM4DXA3+QdFJEvFD8xObm5l23m5qaaGpqKrfWLtuxIx3AvO++dKTfu4/7rkMOSReUu/zyNDT0\njjvSqKvLL0/HNnpjRNIrr+x5gk/x+O6LLoJp07o/EsPyq6WlhZaWlootr9yum+aIGJ9Nl+q6uRb4\nS0TclE3/FpgSEQ8VLatqLfpNm9Ju+sCBcPPNPRszbvm1cWMK/Xvuqfww0P32S6Mp2lrpeTxj06qj\nGgdj+wKLSQdj1wN/BSZFxMKCec7N7vuwpIOBh4CTI2Jz0bKqEvQLF6YzXSdMgOnTG6NP08ysPT0N\n+k7/45GIaAUmA3OA+cDMiFgo6WpJF2Tz/AbYKGk+8DvgquKQr5a7706n9n/pS/Dv/+6QNzPLzQlT\nEfDd78I3v5lGWZx2Wq+sxsys6qpxMLbubduWLgL24IPpxKFRo2pdkZlZ/Wj4oN+wAd7/fjj44DSy\nxicNmZntqaH/c/DFi+Ftb4OmpnSBJIe8mdneGrqP/jOfSWc4fv3rFVukmVnd6fVRN/Vs+XIYO7bW\nVZiZ1beGD/o3vKHWVZiZ1beG7brZuTNdo+S553xhLzPLt32262bdOl+90cysHA0b9MuWudvGzKwc\nDRv07p83MyuPg97MLOcaOuh9fXkzs841dNC7RW9m1jkHvZlZzjVk0G/alMbRv+51ta7EzKz+NWTQ\ntw2tVLdPHzAz23c0ZNC728bMrHwOejOznHPQm5nlXMMGvcfQm5mVp2GD3i16M7PyNNxlil95BQ46\nCLZuhb59K1SYmVkd2+cuU7xiBYwa5ZA3MytXWUEvabykRZKWSJpS4vHLJG2Q9HD299HKl5r48sRm\nZl3Tr7MZJPUBZgBnA+uAeZLuiIhFRbPOjIgre6HGPbh/3sysa8pp0Y8FlkbE6ojYAcwEJpSYryrn\nqTrozcy6ppygHwGsKZhem91X7H2SHpV0q6SjKlJdCQ56M7Ou6bTrhtIt9eKhM7OBmyNih6RPADeS\nunr20tzcvOt2U1MTTU1NZRXaxmPozSzvWlpaaGlpqdjyOh1eKWkc0BwR47PpqUBExPR25u8DbIqI\nYSUe69Hwytdeg0GDYMsW2G+/bi/GzKyhVGN45TxgtKRRkgYAE0kt+MIiDi+YnAAs6G5BHVmzBg49\n1CFvZtYVnXbdRESrpMnAHNKG4fqIWCjpamBeRNwFXCnpQmAHsAn4cG8U6/55M7Oua6gzY6+7Dh58\nEH7wgwoWZWZW5/apM2Pdojcz6zoHvZlZzjnozcxyrmH66CNg8GBYuxaG7TVw08wsv/aZPvoNG2Dg\nQIe8mVlXNUzQu9vGzKx7HPRmZjnXMEHv69CbmXVPwwS9W/RmZt3joDczyzkHvZlZzjVE0L/4Irz0\nEhxxRK0rMTNrPA0R9MuXw7HHgqrynxWameVLwwS9u23MzLrHQW9mlnMNEfQeQ29m1n0NEfRu0ZuZ\ndZ+D3sws5+r+MsXbt6fLE2/dCv3791JhZmZ1LPeXKV61Co46yiFvZtZddR/07rYxM+sZB72ZWc45\n6M3Mcq6soJc0XtIiSUskTelgvosk7ZR0SqUK9Bh6M7Oe6TToJfUBZgDnAicBkySNKTHfIOBfgLmV\nLNAtejOznimnRT8WWBoRqyNiBzATmFBivq8C04FtlSpu505YuTJd0MzMzLqnnKAfAawpmF6b3beL\npJOBoyLiVxWsjXXrYOhQGDSokks1M9u39CtjnlKD9Hed9SRJwHeAyzp5DgDNzc27bjc1NdHU1NTu\nipcvh9Gjy6jQzCxHWlpaaGlpqdjyOj0zVtI4oDkixmfTU4GIiOnZ9BBgGbCVFPCHAxuBCyPi4aJl\ndenM2BtugPvvhxtvLP8FmZnlTU/PjC2nRT8PGC1pFLAemAhManswIl4ADi0o6D7gcxHxSHeLauMD\nsWZmPddpH31EtAKTgTnAfGBmRCyUdLWkC0o9hQ66brrCQW9m1nN1fVGzU0+FGTNg3LheLMrMrM7l\n+qJmbtGbmfVc3Qb9pk3Q2goHH1zrSszMGlvdBn1ba14V6e03M9t31XXQewy9mVnP1XXQu3/ezKzn\nHPRmZjnnoDczy7m6DXpfh97MrDLq8oSpV16B4cPhpZegb98qFGZmVsdyecLUihUwapRD3sysEuoy\n6N0/b2ZWOXUb9B5Db2ZWGXUb9G7Rm5lVhoPezCznHPRmZjlXd8MrX3sNDjwQtmyBgQOrVJiZWR3L\n3fDKNWvg0EMd8mZmlVJ3Qe9uGzOzynLQm5nlXF0GvcfQm5lVTl0GvVv0ZmaV46A3M8u5uhpeGQFD\nhqSRN8OGVa0sM7O6VpXhlZLGS1okaYmkKSUe/4SkxyU9Iun3ksZ0p5gNG2DAAIe8mVkldRr0kvoA\nM4BzgZOASSWC/KcR8XcR8RbgW8B3ulOMu23MzCqvnBb9WGBpRKyOiB3ATGBC4QwRsbVgchCwszvF\nOOjNzCqvXxnzjADWFEyvJYX/HiR9Evgc0B84qzvFOOjNzCqvnKAvdQBgryOqEXENcI2kicCXgQ+X\nWlhzc/Ou201NTTQ1Ne2aXr4czj67jIrMzHKspaWFlpaWii2v01E3ksYBzRExPpueCkRETG9nfgGb\nI2KvQ6qdjbp5+9th+nQ4/fQuvAIzs5yrxqibecBoSaMkDQAmArOLiig8l/UCYEl3inHXjZlZ5XXa\ndRMRrZImA3NIG4brI2KhpKuBeRFxFzBZ0juB7cBm4LKuFvLii+nviCO6+kwzM+tI3Zww9eijcMkl\n8OSTVSvHzKwh5OZ69O62MTPrHQ56M7Occ9CbmeVcXQW9r0NvZlZ5dRX0btGbmVVeXYy62b4dBg+G\nrVuhf/+qlWNm1hByMepm9WoYMcIhb2bWG+oi6Jctc7eNmVlvqYugd/+8mVnvcdCbmeWcg97MLOfq\nJug9ht7MrHfUfHjlzp0waFD6j8EHDapaKWZmDaPhh1euXw9Dhjjkzcx6S82D3v3zZma9q+ZB7zH0\nZma9q+ZB7xa9mVnvctCbmeWcg97MLOcc9GZmOVfToN+8GV57DQ45pJZVmJnlW02Dvq01r26fBmBm\nZp2pi6A3M7PeU1bQSxovaZGkJZKmlHj8s5LmS3pU0j2SRpazXI+hNzPrfZ0GvaQ+wAzgXOAkYJKk\nMUWzPQy8NSJOBn4OfKuclbtFb2bW+8pp0Y8FlkbE6ojYAcwEJhTOEBH3R8Sr2eRcYEQ5K3fQm5n1\nvnKCfgSwpmB6LR0H+ceAu8tZuYPezKz39StjnlJjYkpe21jSJcBbgTPbW1hzczMAO3bAhg1NjBzZ\nVEYJZmb7jpaWFlpaWiq2vE6vRy9pHNAcEeOz6alARMT0ovneCXwPOCMiNrazrF3Xo1+wAP7xH2Hx\n4p6/CDOzPKvG9ejnAaMljZI0AJgIzC4q4i3AdcCF7YV8MXfbmJlVR6dBHxGtwGRgDjAfmBkRCyVd\nLemCbLZvAgcCt0l6RNIvO1uug97MrDrK6aMnIn4NnFB037SC2+/q6oqXLfP/E2tmVg01OzPWLXoz\ns+pw0JuZ5Vyno24qurJs1E1rKxx4YLp65f77V231ZmYNqRqjbipuzRo4+GCHvJlZNdQk6Jcv94FY\nM7NqqVnQu3/ezKw6HPRmZjlXk6D3dejNzKrHLXozs5yr+vDKnTuDIUPgqadg+PCqrdrMrGE13PDK\nZ5+F/v0d8mZm1VL1oHe3jZlZddUk6D2G3sysetyiNzPLuaoHvYdWmplVl1v0ZmY556A3M8u5qo+j\n33//YOtW6FOzK+GbmTWWhhtHf8wxDnkzs2qqeuS628bMrLqqHvQeQ29mVl1u0ZuZ5ZyD3sws58oK\neknjJS2StETSlBKPny7pIUk7JL2vo2U56M3MqqvToJfUB5gBnAucBEySNKZottXAZcBPO1veqFHd\nqNLMzLqtXxnzjAWWRsRqAEkzgQnAorYZIuKp7LFOB+UPGNC9Qs3MrHvK6boZAawpmF6b3WdmZg2g\nnBZ9qbOxun06bXNz867bTU1NNDU1dXdRZma51NLSQktLS8WW1+klECSNA5ojYnw2PRWIiJheYt4f\nAndGxC/aWVZU85ILZmZ5UI1LIMwDRksaJWkAMBGY3VFN3S3GzMwqr9Ogj4hWYDIwB5gPzIyIhZKu\nlnQBgKRTJa0BLgKuk/REbxZtZmblq/rVK911Y2bWNQ139UozM6suB72ZWc456M3Mcs5Bb2aWcw56\nM7Occ9CbmeWcg97MLOcc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCzn\nHPRmZjnnoDczyzkHvZlZzjnozcxyzkFvZpZzDnozs5xz0JuZ5VxZQS9pvKRFkpZImlLi8QGSZkpa\nKukvkl5f+VLNzKw7Og16SX2AGcC5wEnAJEljimb7GLApIo4Dvgt8s9KFVlNLS0utSyiL66ycRqgR\nXGelNUqdPVVOi34ssDQiVkfEDmAmMKFongnAjdntWcDZlSux+hrlw3edldMINYLrrLRGqbOnygn6\nEcCagum12X0l54mIVuB5SQdVpEIzM+uRcoJeJe6LTuZRiXnMzKwGFNFxHksaBzRHxPhseioQETG9\nYJ67s3kekNQXWB8Rh5ZYlsPfzKwbIqJUo7ss/cqYZx4wWtIoYD0wEZhUNM+dwGXAA8DFwL2VLtTM\nzLqn06CPiFZJk4E5pK6e6yNioaSrgXkRcRdwPfBjSUuBjaSNgZmZ1YFOu27MzKyxVe3M2M5Ouqom\nSddLekbS4wX3DZc0R9JiSb+RNLTgsf+dnQz2qKSTq1TjUZLulbRA0hOSrqzTOveT9ICkR7I6p2X3\nHy1pblbnLZL6ZffX9OQ6SX0kPSxpdr3WKWmVpMey9/Sv2X319rkPlXSbpIWS5kt6Wx3WeHz2Hj6c\n/btF0pX1Vme23s9KelLS45J+mn3/KvfdjIhe/yNtUJYBo4D+wKPAmGqsu516/gE4GXi84L7pwBez\n21OAb2S3zwP+M7v9NmBulWo8HDg5uz0IWAyMqbc6s/UdkP3bF5ibrf9nwMXZ/dcCn8huXwFck93+\nADCzyp/9Z4GfALOz6bqrE1gBDC+6r64+d+BHwEey2/2AofVWY1G9fYB1wMh6qxM4MvvMBxR8Jy+r\n5HezWm/yOODugumpwJRqf9hFNY1iz6BfBByW3T4cWJjdvg74QMF8C9vmq3K9vwTeWc91AgcAD5JO\nstsA9Cn+/IFfA2/LbvcFnq1ifUcB9wBN7A76Z+uwzpXA64ruq5vPHRgMLC9xf93UWKK2c4A/1GOd\npKBfDQwnbTRnA++q5G+oWl035Zx0VWuHRsQzABHxNNA2PLS49r9R5dolHU3aA5lL+uLVVZ1Zd8gj\nwNOkIF0OPB8RO7NZCj/vWp5c9x3gC2TneEh6HbC5DusM4DeS5kn6b9l99fS5Hws8J+mHWbfI/5V0\nQJ3VWOwDwM3Z7bqqMyLWAd8GnsrWuQV4mAr+hqoV9OWcdFWvalq7pEGky0p8OiK2drDumtUZETsj\n4i2kFvNY4I0d1FKTk+sknQ88ExGPFtSgEvXUtM7M2yPiVODdwKcknd7BumvxufcDTgG+HxGnAC+R\n9tLrqcbdK5f6AxcCt3Wy7prUKWkY6TIyo0it+wNJ3Ujt1dLl72a1gn4tUHjA4ChSf1k9eUbSYQCS\nDiftNkGqfWTBfFWrPTv4Mgv4cUTcUa91tomIF4D7SbuZw5QuiFdcy646lU6uGxIRm6tQ3mnAhZJW\nALcAZ5EuwDe0zupsa2USEc+SuuzGUl+f+1pgTUQ8mE3/nBT89VRjofOAhyLiuWy63up8J7AiIjZl\nLfTbgbdTwd9QtYJ+10lXkgaQxtnPrtK621PcmpsNfDi7/WHgjoL7PwS7zhJ+vm23rwpuABZExPcK\n7qurOiXHuYRUAAABN0lEQVQd3DZqQdL+pC/tAuA+0slzkA4sFdZ5WXa73ZPrKi0ivhQRr4+IY0nf\nv3sj4pJ6q1PSAdleHJIOJPUtP0Edfe7Z8tdIOj6762xgfj3VWGQSaePept7qfAoYJ2mgJLH7/azc\nd7OKB0PGk0aOLAWmVmu97dRyM2nruC17kz9COhDy26zGe4BhBfPPII0aegw4pUo1nga0kkYoPULq\nsxsPHFRndf6XrLZHgceB/5HdfwzpTOklpNED/bP79wNuzb4Hc4Gja/D5n8nug7F1VWdWT9tn/kTb\nb6UOP/c3kxpwjwK/II26qasas/XuTzrgPrjgvnqscxrp4O/jpCsB96/kd9MnTJmZ5Zz/K0Ezs5xz\n0JuZ5ZyD3sws5xz0ZmY556A3M8s5B72ZWc456M3Mcs5Bb2aWc/8ftL8WGK5Nt4IAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd29c3b0940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title('Sub_Jhmdb: Accuracy on Split 0')\n",
    "plt.plot(plot_data[0][1],plot_data[1][1],'b-')\n",
    "plt.figure()\n",
    "plt.title('Sub_Jhmdb: Accuracy on Split 1')\n",
    "plt.plot(plot_data[0][2],plot_data[1][2],'x-')\n",
    "plt.figure()\n",
    "plt.title('Sub_Jhmdb: Accuracy on Split 2')\n",
    "plt.plot(plot_data[0][3],plot_data[1][3],'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Jhmdb\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAACQCAYAAADk1Lu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2a1330748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAACQCAYAAADk1Lu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd29af48400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAACQCAYAAADk1Lu5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnCshHvSdc66EeNB3zrkS8v9JQx3X79WQ+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2980d1c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.title('Jhmdb: Accuracy on Split 0')\n",
    "plt.plot(plot_data[0][4],plot_data[1][4],'b-')\n",
    "plt.figure(2)\n",
    "plt.subplot(211)\n",
    "plt.title('Jhmdb: Accuracy on Split 1')\n",
    "plt.plot(plot_data[0][5],plot_data[1][5],'b-')\n",
    "plt.figure(3)\n",
    "plt.subplot(211)\n",
    "plt.title('Jhmdb: Accuracy on Split 2')\n",
    "plt.plot(plot_data[0][6],plot_data[1][6],'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Florence 3d\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACQCAYAAAAGCKDAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2a145d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACQCAYAAAAGCKDAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXMZ5Re+ccxnnFb1zzmWcV/TOOZdx/w+l54aMm8L2JwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2a13483c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACQCAYAAAAGCKDAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOueB3jnn6pwHeuecq3P/D0+u11rdKg4lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd29c3dabe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(7,10):\n",
    "    plt.figure(k+1)\n",
    "    plt.subplot(211)    \n",
    "    plt.title('Florence_3d: Accuracy on Split '+ str(k+1))\n",
    "    plt.plot(plot_data[0][k],plot_data[1][k],'b-')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Bonn mocap\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACQCAYAAAABZryQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2a03952e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACQCAYAAAABZryQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAsUdgOM4ToHiDsBxHKdAcQfgOI5ToPx/is/IpbWXkxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd28416c940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAACQCAYAAAABZryQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx3EqKW4AHMdxKiluABzHcSop/w8OCqBFnwCzxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd29808c898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in range(10,13):\n",
    "    plt.figure(k+1)\n",
    "    plt.subplot(211)    \n",
    "    plt.title('Bn_Mocap: Accuracy on Split '+ str(k+1))\n",
    "    plt.plot(plot_data[0][k],plot_data[1][k],'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp4_end = datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time used in experiment 1 (default data) was 6.2501154 minutes\n",
      "experiment 1 in Penn_action: 1.0083141166666667 minutes\n",
      "experiment 1 in Sub_jhmdb: 0.22812346666666666 minutes\n",
      "experiment 1 in Jhmdb: 0.6207598666666667 minutes\n",
      "experiment 1 in Florence3d: 0.11236838333333334 minutes\n",
      "experiment 1 in Bn_mocap: 4.1221645 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nCORRECT THE NEXT EXPERIMENTS (change number): \\n\\nprint('The total time used in experiment 2 (-1 FCN: 2FCN) was', (exp2_end - exp2_start).total_seconds()/60, 'minutes')\\n\\nprint('experiment 2 in Penn_action:',(exp2Penn_end-exp2Penn_start).total_seconds()/60, 'minutes')\\nprint('experiment 2 in Sub_jhmdb:',(exp2SubJ_end-exp2SubJ_start).total_seconds()/60, 'minutes')\\nprint('experiment 2 in Jhmdb:',(exp2Jhmdb_end-exp2Jhmdb_start).total_seconds()/60, 'minutes')\\nprint('experiment 2 in Florence3d:',(exp2Flor_end-exp2Flor_start).total_seconds()/60, 'minutes')\\nprint('experiment 2 in Bn_mocap:',(exp2BnM_end-exp2BnM_start).total_seconds()/60, 'minutes')\\n\\nprint('The total time used in experiment 3 (+1 FCN: 4FCN) was', (exp3_end - exp3_start).total_seconds()/60, 'minutes')\\n\\nprint('experiment 3 in Penn_action:',(exp3Penn_end-exp3Penn_start).total_seconds()/60, 'minutes')\\nprint('experiment 3 in Sub_jhmdb:',(exp3SubJ_end-exp3SubJ_start).total_seconds()/60, 'minutes')\\nprint('experiment 3 in Jhmdb:',(exp3Jhmdb_end-exp3Jhmdb_start).total_seconds()/60, 'minutes')\\nprint('experiment 3 in Florence3d:',(exp3Flor_end-exp3Flor_start).total_seconds()/60, 'minutes')\\nprint('experiment 3 in Bn_mocap:',(exp3BnM_end-exp3BnM_start).total_seconds()/60, 'minutes')\\n\\nprint('The total time used in experiment 4 (+2 FCN: 5FCN) was', (exp4_end - exp4_start).total_seconds()/60, 'minutes')\\n\\nprint('experiment 4 in Penn_action:',(exp4Penn_end-exp4Penn_start).total_seconds()/6sorry0, 'minutes')\\nprint('experiment 4 in Sub_jhmdb:',(exp4SubJ_end-exp4SubJ_start).total_seconds()/60, 'minutes')\\nprint('experiment 4 in Jhmdb:',(exp4Jhmdb_end-exp4Jhmdb_start).total_seconds()/60, 'minutes')\\nprint('experiment 4 in Florence3d:',(exp4Flor_end-exp4Flor_start).total_seconds()/60, 'minutes')\\nprint('experiment 4 in Bn_mocap:',(exp4BnM_end-exp4BnM_start).total_seconds()/60, 'minutes')\\n\\nglobal_end = datetime.datetime.utcnow()\\nprint('The total time used for all of the experiments was', (global_end - global_start).total_seconds()/3600, 'hours')\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = []\n",
    "print('The total time used in experiment 1 (default data) was', (exp1_end - exp1_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "print('experiment 1 in Penn_action:',(datasets_time1[1][0]-datasets_time1[0][0]).total_seconds()/60, 'minutes')\n",
    "print('experiment 1 in Sub_jhmdb:',(datasets_time1[1][1]-datasets_time1[0][1]).total_seconds()/60, 'minutes')\n",
    "print('experiment 1 in Jhmdb:',(datasets_time1[1][2]-datasets_time1[0][2]).total_seconds()/60, 'minutes')\n",
    "print('experiment 1 in Florence3d:',(datasets_time1[1][3]-datasets_time1[0][3]).total_seconds()/60, 'minutes')\n",
    "print('experiment 1 in Bn_mocap:',(datasets_time1[1][4]-datasets_time1[0][4]).total_seconds()/60, 'minutes')\n",
    "\n",
    "'''\n",
    "\n",
    "CORRECT THE NEXT EXPERIMENTS (change number): \n",
    "\n",
    "print('The total time used in experiment 2 (-1 FCN: 2FCN) was', (exp2_end - exp2_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "print('experiment 2 in Penn_action:',(exp2Penn_end-exp2Penn_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 2 in Sub_jhmdb:',(exp2SubJ_end-exp2SubJ_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 2 in Jhmdb:',(exp2Jhmdb_end-exp2Jhmdb_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 2 in Florence3d:',(exp2Flor_end-exp2Flor_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 2 in Bn_mocap:',(exp2BnM_end-exp2BnM_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "print('The total time used in experiment 3 (+1 FCN: 4FCN) was', (exp3_end - exp3_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "print('experiment 3 in Penn_action:',(exp3Penn_end-exp3Penn_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 3 in Sub_jhmdb:',(exp3SubJ_end-exp3SubJ_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 3 in Jhmdb:',(exp3Jhmdb_end-exp3Jhmdb_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 3 in Florence3d:',(exp3Flor_end-exp3Flor_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 3 in Bn_mocap:',(exp3BnM_end-exp3BnM_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "print('The total time used in experiment 4 (+2 FCN: 5FCN) was', (exp4_end - exp4_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "print('experiment 4 in Penn_action:',(exp4Penn_end-exp4Penn_start).total_seconds()/6sorry0, 'minutes')\n",
    "print('experiment 4 in Sub_jhmdb:',(exp4SubJ_end-exp4SubJ_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 4 in Jhmdb:',(exp4Jhmdb_end-exp4Jhmdb_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 4 in Florence3d:',(exp4Flor_end-exp4Flor_start).total_seconds()/60, 'minutes')\n",
    "print('experiment 4 in Bn_mocap:',(exp4BnM_end-exp4BnM_start).total_seconds()/60, 'minutes')\n",
    "\n",
    "global_end = datetime.datetime.utcnow()\n",
    "print('The total time used for all of the experiments was', (global_end - global_start).total_seconds()/3600, 'hours')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3,6):\n",
    "    example+str(i) = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
